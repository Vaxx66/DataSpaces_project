{"cells":[{"cell_type":"raw","metadata":{"id":"d-Mv4D7-E05V"},"source":["<script>\n","  function code_toggle() {\n","    if (code_shown){\n","      $('div.input').hide('500');\n","      $('#toggleButton').val('Show Code')\n","    } else {\n","      $('div.input').show('500');\n","      $('#toggleButton').val('Hide Code')\n","    }\n","    code_shown = !code_shown\n","  }\n","\n","  $( document ).ready(function(){\n","    code_shown=false;\n","    $('div.input').hide()\n","  });\n","</script>\n","<form action=\"javascript:code_toggle()\"><input type=\"submit\" id=\"toggleButton\" value=\"Show Code\"></form>"]},{"cell_type":"markdown","metadata":{"id":"mcVZmrfdlcux"},"source":["# Indian Liver Patient (ILPD) Dataset\n","Data Spaces (01RLPOV), A.A. 2021/22  <br /> \n","Politecnico di Torino - Corso di Laurea Magistrale in Ingegneria Informatica <br /> \n","Elisa Cenedese - s255202 <br /> \n"]},{"cell_type":"markdown","metadata":{"id":"jykReSd3oKSj"},"source":["## Table of Contents\n","\n","* [1. Introduction](#introduction)\n","    * [1.1 Dataset description](#dataset_descr)\n","    * [1.2 Check for missing values](#check_missing_values)\n","    * [1.3 Check for outliers](#check_outliers)\n","    * [1.4 Split dataset](#split_dataset)\n","* [2. Exploratory data analysis](#exploratory_data_analysis)\n","    * [2.1 Statistical quantitative description of features](#stat_features_descr)\n","    * [2.2 Box plots](#box_plots)\n","    * [2.3 Correlation analysis](#corr_analysis)\n","* [3. Preprocessing steps](#preprocessing_steps)\n","    * [3.1 Feature scaling](#scaling)\n","    * [3.2 Rebalancing](#rebalancing)\n","    * [3.3 Dimensionality reduction methods](#dim_reduction_methods)\n","       * [3.3.1 Principal component analysis](#pca)\n","       * [3.3.2 Empirical feature selection](#empirical_feature_selection)\n","* [4. Classification](#classification)\n","    * [4.1 Metrics](#metrics)\n","    * [4.2 Cross validation](#cv)\n","    * [4.3 Support vector machines](#svm)\n","    * [4.4 K nearest neighbors](#knn)\n","    * [4.5 Logistic regression](#l_regr)\n","    * [4.6 Decision Tree](#decision_tree)\n","    * [4.7 Random forest](#random_forest)\n","  "]},{"cell_type":"code","execution_count":309,"metadata":{"id":"l86AIQJkpO3z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1661109442611,"user_tz":-120,"elapsed":1895,"user":{"displayName":"Elisa C","userId":"11182657622104819579"}},"outputId":"8c3516d2-e8a7-4ca0-97a1-42c6f06aaf7e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["#Mount drive\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":310,"metadata":{"id":"wjUmVeG1pR6R","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1661109449673,"user_tz":-120,"elapsed":7068,"user":{"displayName":"Elisa C","userId":"11182657622104819579"}},"outputId":"fa86ee7e-2297-438c-88a5-aa39b6ff0700"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: chart_studio in /usr/local/lib/python3.7/dist-packages (1.1.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from chart_studio) (1.15.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from chart_studio) (2.23.0)\n","Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from chart_studio) (5.5.0)\n","Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from chart_studio) (1.3.3)\n","Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly->chart_studio) (8.0.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->chart_studio) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->chart_studio) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->chart_studio) (2022.6.15)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->chart_studio) (2.10)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: kaleido in /usr/local/lib/python3.7/dist-packages (0.2.1)\n"]}],"source":["#Install\n","!pip install chart_studio\n","!pip install -U kaleido"]},{"cell_type":"code","execution_count":311,"metadata":{"id":"7vkbnOiDpYpG","executionInfo":{"status":"ok","timestamp":1661109449674,"user_tz":-120,"elapsed":27,"user":{"displayName":"Elisa C","userId":"11182657622104819579"}}},"outputs":[],"source":["%matplotlib inline\n","\n","#Imports\n","import pandas as pd\n","import os\n","import seaborn as sns\n","import numpy as np\n","import matplotlib\n","import matplotlib.pyplot as plt\n","import itertools\n","import math\n","import pickle\n","from numpy import mean\n","from numpy import std\n","#plot libaries\n","import plotly\n","import plotly.express as px\n","import plotly.graph_objects as go\n","import plotly.io as pio\n","import plotly.figure_factory as ff\n","from plotly.subplots import make_subplots\n","import yaml\n","import pprint\n","\n","from imblearn.over_sampling import SMOTENC\n","from matplotlib.colors import ListedColormap\n","from sklearn.compose import ColumnTransformer\n","from sklearn.model_selection import StratifiedKFold, GridSearchCV, cross_val_score, RandomizedSearchCV\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import plot_confusion_matrix\n","from sklearn import metrics\n","from sklearn.decomposition import PCA\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import make_scorer, f1_score\n","from imblearn.pipeline import Pipeline\n","from imblearn.over_sampling import SMOTE\n","from sklearn import tree, svm, linear_model, ensemble, neighbors \n","from sklearn.svm import LinearSVC\n","from sklearn import preprocessing\n","from sklearn.base import clone\n","#from plotly.offline import init_notebook_mode\n","#init_notebook_mode(connected=True)\n","# online plotly\n","import chart_studio\n","chart_studio.tools.set_credentials_file(username='elisa_c', api_key='ixjDGQPn6k6yG1D96Wnr')\n","#chart_studio.tools.set_config_file(world_readable=False, sharing='secret')\n","import chart_studio.plotly as py\n","from scipy.cluster import hierarchy as hc"]},{"cell_type":"code","execution_count":312,"metadata":{"id":"kvKw141nphNl","executionInfo":{"status":"ok","timestamp":1661109449675,"user_tz":-120,"elapsed":26,"user":{"displayName":"Elisa C","userId":"11182657622104819579"}}},"outputs":[],"source":["#Paths\n","DATA_FILE_NAME = \"indian_liver_patient_dataset.csv\"\n","\n","ROOT_DIRPATH = os.path.join(\n","    '/content',\n","    'drive',\n","    'MyDrive',\n","    'DataSpaces',\n","    'DataSpaces_project',\n",")\n","\n","DATA_DIRPATH = os.path.join(\n","    ROOT_DIRPATH,\n","    'data',\n",")\n","\n","MODELS_DIRPATH = os.path.join(\n","    ROOT_DIRPATH,\n","    'models',\n",")\n","\n","data_file_path = os.path.join(DATA_DIRPATH, DATA_FILE_NAME)\n","\n","if not os.path.exists(MODELS_DIRPATH):\n","    os.makedirs(MODELS_DIRPATH)"]},{"cell_type":"code","execution_count":313,"metadata":{"id":"ovTSV__gpzLH","executionInfo":{"status":"ok","timestamp":1661109449675,"user_tz":-120,"elapsed":26,"user":{"displayName":"Elisa C","userId":"11182657622104819579"}}},"outputs":[],"source":["def read_dataset(dirpath: str, file_type: str, sheet_name_=None):\n","  if file_type == \"xlsx\":\n","    dataset_df = pd.read_excel(dirpath, sheet_name= sheet_name_)\n","  elif file_type == \"csv\":\n","    with open(dirpath) as in_fp:\n","      dataset_df = pd.read_csv(in_fp, sep=',', header=0)\n","  else:\n","    raise Exception(\"Unrecognised dataset format\")\n","  return dataset_df"]},{"cell_type":"code","execution_count":314,"metadata":{"id":"VHBE5iBLqUDA","executionInfo":{"status":"ok","timestamp":1661109449676,"user_tz":-120,"elapsed":26,"user":{"displayName":"Elisa C","userId":"11182657622104819579"}}},"outputs":[],"source":["def show_dict(dict_: dict):\n","    pprint.pprint(dict_, width=1)"]},{"cell_type":"code","execution_count":315,"metadata":{"id":"r5EhM1iMryCk","executionInfo":{"status":"ok","timestamp":1661109449677,"user_tz":-120,"elapsed":27,"user":{"displayName":"Elisa C","userId":"11182657622104819579"}}},"outputs":[],"source":["def print_formatted_list(str_, list):\n","  print(str_ + \":\")\n","  for value in list:\n","    print(\"  - \" + str(value))\n","  print()"]},{"cell_type":"code","execution_count":316,"metadata":{"id":"xvJtnTKir4nZ","executionInfo":{"status":"ok","timestamp":1661109449677,"user_tz":-120,"elapsed":26,"user":{"displayName":"Elisa C","userId":"11182657622104819579"}}},"outputs":[],"source":["def prepare_bar_plot(df, title, template_):\n","  colors = plotly.colors.DEFAULT_PLOTLY_COLORS\n","  data_series = df.value_counts() # return series\n","  data = [go.Bar(x=data_series.index, y=data_series.values, marker = dict(color = colors[:len(data_series.index)]))]\n","  layout = go.Layout(\n","      #paper_bgcolor='rgba(0,0,0,0)',\n","      #plot_bgcolor='rgba(0,0,0,0)',\n","      title=title,\n","      template = template_,\n","      autosize=False,\n","      width=400,\n","      height=400,\n","      yaxis=dict(\n","          title='#Patients',\n","      ),\n","  )\n","  fig = go.Figure(data=data, layout=layout)\n","  return fig, data_series"]},{"cell_type":"code","source":["def prepare_bar_plots(df1, df2, title, template_):\n","\n","  colors = plotly.colors.DEFAULT_PLOTLY_COLORS\n","  data_series1 = df1.value_counts() # return series \n","  data_series2 = df2.value_counts() # return series \n","\n","  fig = make_subplots(rows=1, cols=2,  subplot_titles=(\"Train\", \"Test\"))\n","\n","  fig.add_trace(\n","      go.Bar(x=data_series1.index, y=data_series1.values, marker = dict(color = colors[:len(data_series1.index)])),\n","      row=1, col=1\n","  )\n","\n","  fig.add_trace(\n","      go.Bar(x=data_series2.index, y=data_series2.values, marker = dict(color = colors[:len(data_series2.index)])),\n","      row=1, col=2\n","  )\n","\n","  fig.update_layout(title=title,\n","      template = template_,\n","      autosize=True,\n","      showlegend=False,\n","      width=400,\n","      height=400,\n","      yaxis=dict(\n","          title='#Patients',\n","      ))\n","  \n","  return fig, data_series1, data_series2"],"metadata":{"id":"GR9f14FFu-fn","executionInfo":{"status":"ok","timestamp":1661109449678,"user_tz":-120,"elapsed":27,"user":{"displayName":"Elisa C","userId":"11182657622104819579"}}},"execution_count":317,"outputs":[]},{"cell_type":"code","execution_count":318,"metadata":{"id":"Ha9zE_ezzrCR","executionInfo":{"status":"ok","timestamp":1661109449678,"user_tz":-120,"elapsed":26,"user":{"displayName":"Elisa C","userId":"11182657622104819579"}}},"outputs":[],"source":["def prepare_histogram_plot(X, features_names, class_names, config_dict, template_, per_feature=True):\n","  start_pos = 0\n","  data = []\n","  num_steps = len(features_names)\n","\n","  for count_class, target in enumerate(class_names):\n","    trace_list = []\n","    for count, feature in enumerate(features_names):\n","      if count != start_pos:\n","        trace_list.append(go.Histogram(x=X[feature].loc[X[config_dict['TARGET_COLUMN_NAME']] == target], name = target, visible = False))\n","      else: \n","        if per_feature and (count_class == 0 or count_class == 1):\n","            visibility_ =  True\n","        else:\n","            visibility_ =  'legendonly'\n","        trace_list.append(go.Histogram(x=X[feature].loc[X[config_dict['TARGET_COLUMN_NAME']] == target], name = target, visible = visibility_))\n","    data = data + trace_list\n","\n","  trace_list_all_classes = []\n","  for count, feature in enumerate(features_names):\n","      if count != start_pos:\n","        trace_list_all_classes.append(go.Histogram(x=X[feature], name = 'all', visible = False))\n","      else: \n","        if per_feature:\n","          visibility_ =  'legendonly'\n","        else:\n","           visibility_ = True\n","        trace_list_all_classes.append(go.Histogram(x=X[feature], name = 'all', visible = visibility_))\n","\n","  data = data + trace_list_all_classes\n","\n","  steps = []\n","\n","  for i in range(num_steps):\n","      # Hide all traces\n","      step = dict(\n","          method = 'restyle',  \n","          args = ['visible', [False] * len(data)],\n","          label = features_names[i],\n","      )\n","\n","      # Enable the traces we want to see\n","      for count, class_name in enumerate(class_names):\n","        #print(i+count*len(features_names))\n","        if per_feature and (count == 0 or count == 1):\n","          visibility_ =  True\n","        else:\n","          visibility_ =  'legendonly'\n","        step['args'][1][i+count*len(features_names)] = visibility_\n","     \n","      if per_feature:\n","        visibility_ = 'legendonly'\n","      else:\n","        visibility_ = True\n","      step['args'][1][i+(count+1)*len(features_names)] = visibility_\n","      \n","      # Add step to step list\n","      steps.append(step)\n","\n","  sliders = [dict(\n","      active = start_pos, # from where to start the slider\n","      currentvalue = dict(\n","          prefix = \"Feature: \", \n","          xanchor= 'center',\n","      ),\n","      pad = {\"t\": 50},\n","      steps = steps,\n","      len=1,\n","  )]\n","\n","  layout = dict(\n","      #paper_bgcolor='rgba(0,0,0,0)',\n","      #plot_bgcolor='rgba(0,0,0,0)',\n","      sliders=sliders,\n","      template = template_,  \n","      yaxis=dict(\n","          title='#Samples',\n","          automargin=True,\n","      ),\n","      #font=dict(\n","      #    color=font_color\n","      #)\n","  )\n","\n","  return go.Figure(data=data, layout=layout)"]},{"cell_type":"code","execution_count":319,"metadata":{"id":"LQRqX9YQ-XLg","executionInfo":{"status":"ok","timestamp":1661109449679,"user_tz":-120,"elapsed":27,"user":{"displayName":"Elisa C","userId":"11182657622104819579"}}},"outputs":[],"source":["def prepare_box_plot(X, features_names, class_names, config_dict, title, template_):\n","  active_pos = 0\n","  data = []\n","  num_steps = len(features_names)\n","\n","  for target in class_names:\n","    trace_list = []\n","    for count, feature in enumerate(features_names):\n","      if count != active_pos:\n","        trace_list.append(go.Box(y=X[feature].loc[X[config_dict['TARGET_COLUMN_NAME']] == target], name = target, visible = False))\n","      else:\n","         trace_list.append(go.Box(y=X[feature].loc[X[config_dict['TARGET_COLUMN_NAME']] == target], name = target, visible = True))\n","    data = data + trace_list\n","\n","  steps = []\n","\n","  for i in range(num_steps):\n","      # Hide all traces\n","      step = dict(\n","          method = 'restyle',  \n","          args = ['visible', [False] * len(data)],\n","          label = features_names[i],\n","      )\n","      # Enable the two traces we want to see\n","      for count, class_name in enumerate(class_names):\n","        #print(i+count*len(features_names))\n","        step['args'][1][i+count*len(features_names)] = True\n","        \n","      # Add step to step list\n","      steps.append(step)\n","\n","  sliders = [dict(\n","      active = active_pos,\n","      currentvalue = dict(\n","          prefix = \"Feature: \", \n","          xanchor= 'center',\n","      ),\n","      pad = {\"t\": 50},\n","      steps = steps,\n","      len=1,\n","  )]\n","\n","  layout = dict(\n","      #paper_bgcolor='rgba(0,0,0,0)',\n","      #plot_bgcolor='rgba(0,0,0,0)',\n","      sliders=sliders,\n","      title=title,\n","      template = template_,  \n","      yaxis=dict(\n","          title='Feature value',\n","          automargin=True,\n","      ),\n","      #font=dict(\n","      #    color=font_color\n","      #)\n","  )\n","\n","  return go.Figure(data=data, layout=layout)"]},{"cell_type":"code","execution_count":320,"metadata":{"id":"wpLKsvHuJF_Z","executionInfo":{"status":"ok","timestamp":1661109449680,"user_tz":-120,"elapsed":28,"user":{"displayName":"Elisa C","userId":"11182657622104819579"}}},"outputs":[],"source":["def prepare_dendogram(X, title_, template_):\n","  colors = plotly.colors.DEFAULT_PLOTLY_COLORS\n","  feature_names = X.columns\n","  inverse_correlation = 1 - abs(X.corr())\n","\n","  fig = ff.create_dendrogram(inverse_correlation.values, orientation='left', labels=feature_names, colorscale=colors, linkagefun=lambda x: hc.linkage(x, 'average'))\n","  \n","  fig['layout'].update(dict(\n","      title= title_,\n","      template= template_,\n","      width=800, \n","      height=600,\n","      margin=go.layout.Margin(l=180, r=50),\n","      xaxis=dict(\n","          title='distance',\n","      ),\n","      yaxis=dict(\n","          title='features',\n","          automargin=True,\n","      ),\n","  ))\n","  return fig"]},{"cell_type":"code","execution_count":321,"metadata":{"id":"I-R34w6CITbB","executionInfo":{"status":"ok","timestamp":1661109449680,"user_tz":-120,"elapsed":27,"user":{"displayName":"Elisa C","userId":"11182657622104819579"}}},"outputs":[],"source":["def prepare_heatmap(X, template_):\n","  corr = X.corr()\n","  trace = go.Heatmap(z=corr.values.tolist(), x=corr.columns, y=corr.columns)\n","  data=[trace]\n","  layout = go.Layout(\n","      title='Heatmap of pairwise correlation of the columns',\n","      autosize=False,\n","      template = template_,\n","      width=650,\n","      height=500,\n","      yaxis=go.layout.YAxis(automargin=True),\n","      xaxis=dict(tickangle=40),\n","      margin=go.layout.Margin(l=80, r=80, b=80, t=80)\n","  )\n","\n","  return go.Figure(data=data, layout=layout)"]},{"cell_type":"code","execution_count":322,"metadata":{"id":"8ihO0qZXKln8","executionInfo":{"status":"ok","timestamp":1661109449681,"user_tz":-120,"elapsed":28,"user":{"displayName":"Elisa C","userId":"11182657622104819579"}}},"outputs":[],"source":["def prepare_pairplot(X, config_dict, combinations, features_names, title, template_):\n","  trace_list = []\n","  combinations_names = []\n","  start_pos = 0\n","  index_vals = X[config_dict['TARGET_COLUMN_NAME']].astype('category').cat.codes\n","\n","  #combinations = list(itertools.combinations(range(len(features_list)), 2))\n","  num_steps = len(combinations)\n","\n","  for couple in combinations:\n","    tuple_ = (features_names[couple[0]], features_names[couple[1]])\n","    combinations_names.append(str(tuple_))\n","\n","  for count, couple in enumerate(combinations):\n","    #print(features_names[couple[0]], features_names[couple[1]])\n","    if count == start_pos:\n","      visibility_ = True\n","    else:\n","      visibility_ = False\n"," \n","    trace_list.append(go.Splom(dimensions=[dict(label=features_names[couple[0]],\n","                                                values=X[features_names[couple[0]]]),\n","                                          dict(label=features_names[couple[1]],\n","                                          values=X[features_names[couple[1]]])],\n","                              diagonal_visible=False, # remove plots on diagonal\n","                              text=X[config_dict['TARGET_COLUMN_NAME']],\n","                              marker=dict(color=index_vals,\n","                                          showscale=False, # colors encode categorical variables\n","                                          line_color='white', line_width=0.5),\n","                              visible = visibility_))\n","\n","  steps = []\n","  \n","  for i in range(num_steps):\n","      # Hide all traces\n","      step = dict(\n","          method = 'restyle',  \n","          args = ['visible', [False] * len(trace_list)],\n","          label = combinations_names[i],\n","      )\n","\n","      # Enable the traces we want to see\n","      step['args'][1][i] = True\n","        \n","      # Add step to step list\n","      steps.append(step)\n","  \n","  sliders = [dict(\n","      active = start_pos, # from where to start the slider\n","      currentvalue = dict(\n","            prefix = \"Features couple: \", \n","            xanchor= 'center',\n","      ),\n","      pad = {\"t\": 50},\n","      steps = steps,\n","      len=1,\n","    )]\n","\n","  layout = dict(\n","        #paper_bgcolor='rgba(0,0,0,0)',\n","        #plot_bgcolor='rgba(0,0,0,0)',\n","        sliders=sliders,\n","        title=title,\n","        template = template_,  \n","        #font=dict(\n","        #    color=font_color\n","        #)\n","        width=600,\n","        height=600,\n","  )\n","\n","  return go.Figure(data=trace_list, layout=layout)"]},{"cell_type":"code","execution_count":323,"metadata":{"id":"5g69h7I4Rgaa","executionInfo":{"status":"ok","timestamp":1661109450199,"user_tz":-120,"elapsed":545,"user":{"displayName":"Elisa C","userId":"11182657622104819579"}}},"outputs":[],"source":["def prepare_PCA_explained_variance_plot(pca, template_):\n","  #explained_variance_ratio_ is the percentage of variance explained by each of the selected components.\n","  '''\n","  fig = plt.figure()\n","  plt.plot(np.cumsum(pca.explained_variance_ratio_), label=\"Cumulative variance\")\n","  plt.plot(pca.explained_variance_ratio_, label=\"Component variance\")\n","  plt.legend()\n","  plt.xlabel('Principal component')\n","  plt.ylabel('Explained variance ratio')\n","  '''\n","  cum_explained_variance_ratio = np.cumsum(pca.explained_variance_ratio_)\n","\n","  found_explained_variance_ratio = 0.0\n","  found_pc_id = 0\n","  for pc_id, value in enumerate(cum_explained_variance_ratio):\n","    if value >= 0.95:\n","      found_explained_variance_ratio = value\n","      found_pc_id = pc_id +1\n","      break\n","\n","  trace_cum_var_exp = go.Scatter(\n","    x=list(range(1, len(pca.explained_variance_ratio_) + 1)), \n","    y=pca.explained_variance_ratio_,\n","    name=\"Component explained variance\",\n","  )\n","  trace_ind_var_exp = go.Scatter(\n","      x=list(range(1, len(cum_explained_variance_ratio) + 1)),\n","      y=cum_explained_variance_ratio,\n","      name=\"Cumulative explained variance\",\n","    )\n","  data = [trace_cum_var_exp, trace_ind_var_exp]\n","  layout = go.Layout(\n","      template = template_,\n","      title='Individual and Cumulative Explained Variance',\n","      autosize=True,\n","      yaxis=dict(\n","          title='Explained variance ratio',\n","      ),\n","      xaxis=dict(\n","          title=\"Principal component\",\n","          dtick=1,\n","      )\n","  )\n","  \n","  fig = go.Figure(data=data, layout=layout)\n","\n","  fig.add_vline(x=found_pc_id, line_width=2, line_dash=\"dash\", line_color=\"green\")\n","  fig.add_hline(y=found_explained_variance_ratio, line_width=2, line_dash=\"dash\", line_color=\"green\")\n","      \n","  return fig"]},{"cell_type":"code","execution_count":324,"metadata":{"id":"qQ_5sTpGRkoy","executionInfo":{"status":"ok","timestamp":1661109450202,"user_tz":-120,"elapsed":36,"user":{"displayName":"Elisa C","userId":"11182657622104819579"}}},"outputs":[],"source":["def prepare_biplot(pca, X_pca_trasformed, y, features_names, template_):\n","  loadings = pca.components_.T * np.sqrt(pca.explained_variance_)\n","\n","  fig = px.scatter(X_pca_trasformed, x=0, y=1, color=y)\n","\n","  for i, feature in enumerate(features_names):\n","      fig.add_shape(\n","          type='line',\n","          x0=0, y0=0,\n","          x1=loadings[i, 0],\n","          y1=loadings[i, 1]\n","      )\n","      fig.add_annotation(\n","          x=loadings[i, 0],\n","          y=loadings[i, 1],\n","          ax=0, ay=0,\n","          xanchor=\"center\",\n","          yanchor=\"bottom\",\n","          text=feature,\n","      )\n","\n","  fig.update_layout( # customize font and legend orientation & position\n","    template = template_,\n","    width=700,\n","    height=700,\n","    legend_title_text='Class'\n","  )\n","\n","  return fig"]},{"cell_type":"code","execution_count":365,"metadata":{"id":"sNDcUcY25dAV","executionInfo":{"status":"ok","timestamp":1661109872145,"user_tz":-120,"elapsed":730,"user":{"displayName":"Elisa C","userId":"11182657622104819579"}}},"outputs":[],"source":["def save(classifier, filepath):\n","  with open(filepath, \"wb\") as open_file:\n","    pickle.dump(classifier, open_file)\n","\n","def load(filepath):\n","  with open(filepath, 'rb') as open_file:\n","      loaded_classifier = pickle.load(open_file)\n","  return loaded_classifier\n","\n","def plot_PRC(clf_names, y_preds, y):\n","    fig = plt.figure(figsize=(6,6))\n","    ax = fig.gca()\n","    ax.set_xlim([-0.1, 1.1])\n","    ax.set_ylim([-0.1, 1.1])\n","    ax.grid(True)\n","    ax.set_aspect('equal')\n","    ax.legend(loc='lower right')\n","    ax.set_title(\"Precision-Recall Curves\")\n","    for i, y_pr in enumerate(y_preds):\n","        metrics.PrecisionRecallDisplay.from_predictions(y, y_pr, name=clf_names[i], ax=ax)\n","    box = ax.get_position()\n","    ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n","    ax.legend(bbox_to_anchor=(1.04,1), loc=\"upper left\")\n","    fig.show()\n","\n","def plot_confusion_matrix(model, X, y, title='Confusion matrix'):\n","    fig = plt.figure()\n","    ax = fig.gca()\n","    ax.set_title(title)\n","    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n","             rotation_mode=\"anchor\")\n","    metrics.ConfusionMatrixDisplay.from_estimator(model, X, y, ax=ax)\n","    fig.show()\n","    #fig.savefig(filepath)\n","\n","def make_meshgrid(x, y, h=.02):\n","    x_min, x_max = x.min() - 1, x.max() + 1\n","    y_min, y_max = y.min() - 1, y.max() + 1\n","    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n","    return xx, yy\n","\n","def plot_contours(ax, clf, xx, yy, **params):\n","    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n","    Z = Z.reshape(xx.shape)\n","    out = ax.contourf(xx, yy, Z, **params)\n","    return out\n","\n","def plot_2D_svm_decision_boundary(X_train, y_train, X_test, y_test, model, features_pair, title, apply_PCA=False):\n","   \n","    X_train_ = X_train[features_pair]\n","    X_test_ = X_test[features_pair]\n","\n","    scaler = StandardScaler()\n","    X_train_scaled = scaler.fit_transform(X_train_)\n","    X_test_scaled = scaler.transform(X_test_)\n","\n","    if apply_PCA:\n","      x_label = \"PC1\"\n","      y_label = \"PC2\"\n","      pca = PCA()\n","      X_train_scaled = pca.fit_transform(X_train_scaled)\n","      X_test_scaled = pca.transform(X_test_scaled)\n","    else:\n","      x_label = features_pair[0]\n","      y_label = features_pair[1]\n","\n","    sm = SMOTE(sampling_strategy='not majority', random_state=config_dict['GENERAL']['SEED'])\n","    X_train_augm, y_train_augm = sm.fit_resample(X_train_scaled, y_train)\n","\n","    clf = model.fit(X_train_augm, y_train_augm)\n","\n","    fig, ax = plt.subplots()\n","    # title for the plots\n","    #title = ('Decision surface of linear SVC ')\n","    # Set-up grid for plotting.\n","    X0, X1 = X_train_scaled[:, 0], X_train_scaled[:, 1]\n","    xx, yy = make_meshgrid(X0, X1)\n","\n","    plot_contours(ax, clf, xx, yy, cmap=plt.cm.coolwarm, alpha=0.8)\n","    ax.scatter(X0, X1, c=y_train, cmap=plt.cm.coolwarm, s=20, edgecolors='k')\n","    ax.set_ylabel(y_label)\n","    ax.set_xlabel(x_label)\n","    ax.set_xticks(())\n","    ax.set_yticks(())\n","    ax.set_title(title)\n","    plt.show()\n","\n","def plot_augmented_data(X_train, y_train, features_pair, scaler, balancer):\n","  fig, (ax1, ax2) = plt.subplots(1, 2)\n","\n","  X_train_scaled = scaler.fit_transform(X_train)\n","\n","  features_to_display_idx = [i for i, f in enumerate(scaler.get_feature_names_out()) if f in features_pair]\n","\n","  X_train_augm, y_train_augm = balancer.fit_resample(X_train_scaled, y_train)\n","\n","  X_train_scaled_ = X_train_scaled[:, features_to_display_idx]\n","  X_train_augm_ = X_train_augm[:, features_to_display_idx]\n","\n","  ax1.scatter(X_train_augm_[:, 0], X_train_augm_[:, 1], c=y_train_augm.values.ravel(), alpha=0.8, edgecolor=\"k\")\n","  title = f\"Resampling with SMOTE\"\n","  ax1.set_title(title)\n","  ax1.set_xlabel(features_pair[0])\n","  ax1.set_ylabel(features_pair[1])\n","  sns.despine(ax=ax1, offset=10)\n","\n","  ax2.scatter(X_train_scaled_[:, 0], X_train_scaled_[:, 1], c=y_train.values.ravel(), alpha=0.8, edgecolor=\"k\")\n","  title = f\"Original data\"\n","  ax2.set_title(title)\n","  ax2.set_xlabel(features_pair[0])\n","  ax2.set_ylabel(features_pair[1])\n","  sns.despine(ax=ax2, offset=10)\n","\n","  fig.tight_layout()\n","\n","\n","\n","def plot_logistic_curve(logistic_classifier, feature, X, y):\n","  \n","    print(logistic_classifier.best_model.named_steps['scaler'].get_feature_names_out())\n","    feature_id = [i for i, f in enumerate(logistic_classifier.best_model.named_steps['scaler'].get_feature_names_out()) if f==feature][0]\n","    print(feature_id)\n","    X_scaled = logistic_classifier.best_model.named_steps['scaler'].transform(X)\n","    print(X_scaled[:,feature_id])\n","    trained_model = logistic_classifier.best_model.named_steps[logistic_classifier.name]\n","    plt.figure()\n","    m = trained_model.coef_[0,feature_id]\n","    b = trained_model.intercept_[0]\n","    x_v = X_scaled[:,feature_id]\n","    max_x_v = max(x_v)\n","    min_x_v = min(x_v)\n","    x_v = x_v * (max_x_v-min_x_v) + min_x_v\n","    rescale_factor = max_x_v-min_x_v\n","    #generate values for curve overlay\n","   \n","    lgs_curve = lambda x: 1/(1 + math.e**((int(max_x_v)+10)*(m*(x-rescale_factor)+b)))         \n","    x_values = np.linspace(int(min_x_v)-10, int(max_x_v)+10, int(max_x_v)+10)\n","    y_values = lgs_curve(x_values)\n","        \n","    print(x_v.shape)\n","    print(y.values.ravel().shape)\n","\n","    plt.plot(x_values, y_values)\n","    plt.scatter(x_v, y.values.ravel(), c='r', s=2)\n","    plt.xlabel(feature)\n","    plt.ylabel(\"Probability of Liver disease\")\n","\n","def plot_decision_tree(decision_tree_classifier, feature_names, target_name, max_depth=None):\n","\n","  trained_model = decision_tree_classifier.best_model.named_steps[decision_tree_classifier.name]\n","  plt.figure(figsize=(40,40))\n","  tree.plot_tree(trained_model, fontsize=10, feature_names=feature_names, \n","                 class_names=[f\"Liver disease=False\", f\"Liver disease=True\"], \n","                 label='all', filled=True, rounded=True, max_depth=max_depth)\n","  plt.show()\n","\n","class Classifier:\n","\n","  def __init__(self, name, model, class_general_conf, params_grid, class_balancer, feature_scaler):\n","    self.name = name\n","    self.model = model\n","    self.score_metric = class_general_conf['score_metric']\n","    self.cv_inner = class_general_conf['cv_inner']\n","    self.cv_outer = class_general_conf['cv_outer']\n","    self.seed = class_general_conf['seed']\n","    self.params_grid = params_grid\n","    self.class_balancer = class_balancer\n","    self.feature_scaler = feature_scaler\n","    self.pipeline = None\n","    self.apply_PCA = False\n","    self.num_components = 0\n","\n","    self.ncv_global_mean_score = 0.0\n","    self.ncv_global_std_score = 0.0\n","    self.ncv_test_outer_results = []\n","    self.ncv_train_outer_results = []\n","    self.ncv_best_hyperparams = []\n","    self.ncv_inner_results = []\n","    self.ncv_trained = False\n","\n","    self.trained = False\n","    self.best_model = None\n","    self.best_param = {}\n","    self.y_pred = []\n","\n","  def cv(self, X_train, X_test, y_train, y_test, apply_PCA=False, num_components=None):\n","    if apply_PCA:\n","        self.pipeline = Pipeline([\n","                ('scaler', self.feature_scaler), \n","                ('class_balancer', self.class_balancer),\n","                ('pca', PCA(n_components=num_components, random_state=self.seed)), \n","                (self.name, self.model)\n","                ])\n","        self.apply_PCA = True\n","        self.num_components = num_components\n","    else:\n","        self.pipeline = Pipeline([\n","                ('scaler', self.feature_scaler), \n","                ('class_balancer', self.class_balancer),\n","                (self.name, self.model)\n","                ])\n","    \n","    cv_inner = StratifiedKFold(n_splits=self.cv_inner, shuffle=True, random_state=self.seed)\n","    #scorer = make_scorer(self.score_metric, average = 'weighted')\n","    search = GridSearchCV(estimator=self.pipeline, param_grid=self.params_grid, cv=cv_inner,\n","                          scoring=self.score_metric, refit=True, verbose=4)\n","\n","    # execute search\n","    search.fit(X_train, y_train.values.ravel())\n","    # get the best performing model fit on the whole training set \n","    self.best_model = search.best_estimator_ \n","    self.best_param = search.best_params_\n","    best_score = search.best_score_\n","\n","    self.trained = True\n","\n","    print('>> Predicting on test dataset...')\n","    self.y_pred = search.predict(X_test)\n","\n","    self.print_results(X_train, X_test, y_train, y_test)\n","  \n","  def print_results(self, X_train, X_test, y_train, y_test):\n","\n","    if self.trained == False:\n","      print(\"Train model before. Invoce cv()\")\n","      return\n","  \n","    print('Best hyperparameters:')\n","    print(display(pd.DataFrame(self.best_param, index=[0])))\n","    print()\n","\n","    print(\"Test classification report\")\n","    print(classification_report(y_test, self.y_pred))\n","\n","    plot_confusion_matrix(self.best_model, X_test, y_test,\n","                          f\"Confusion matrix with {self.name}{' + PCA' if self.apply_PCA else ''}\")\n","    \n","\n","  def print_nested_cv_results(self):\n","    if self.ncv_trained == False:\n","      print(\"Nested cv not already performed. Invoke nested_cv() first.\")\n","      return\n","\n","    num_it = len(self.ncv_inner_results) \n","\n","    for i in range(0, num_it):\n","\n","        print('\\n--------------------------------------------\\n')\n","        print(f\"Inner CV (Hyperparameters and model selection): \")\n","        print(f\"  F1-score = {self.ncv_inner_results[i]}\")\n","        print(f\"  Best hyperparams = {self.ncv_best_hyperparams[i]}\")\n","        print(f\"Outer CV (Quality of model selection assessment): \")\n","        print(f\"  F1-score = {self.ncv_test_outer_results[i]}\")\n","        print('\\n--------------------------------------------\\n')\n","\n","    global_mean_score = mean(self.ncv_test_outer_results)\n","    global_std_score = std(self.ncv_test_outer_results)\n","    global_train_score = mean(self.ncv_train_outer_results)\n","    global_train_std = std(self.ncv_train_outer_results)\n","\n","    print('\\n--------------------------------------------\\n')\n","    print(f\"Mean training F1-score = {str(global_train_score)} ({str(global_train_std)})\")\n","    print(f\"Mean validation F1-score = {str(global_mean_score)} ({str(global_std_score)})\")\n","    \n","    print(\"List of best hyperparameters to check stability: \")\n","    \n","    best_hyperparams_dict = {}\n","    for best_hyps in self.ncv_best_hyperparams:\n","      for k,v in best_hyps.items():\n","        if k not in best_hyperparams_dict:\n","            best_hyperparams_dict[k] = [v]\n","        else:\n","            best_hyperparams_dict[k].append(v)\n","    print(display(pd.DataFrame.from_dict(best_hyperparams_dict)))\n","\n","        \n","  def nested_cv(self, X, y, apply_PCA=False, num_components=None):\n","    if self.ncv_trained == True:\n","      print(\"Nested cv already performed\")\n","      self.print_nested_cv_results()\n","      return\n","\n","    if apply_PCA:\n","        self.pipeline = Pipeline([\n","                ('scaler', self.feature_scaler), \n","                ('class_balancer', self.class_balancer),\n","                ('pca', PCA(n_components=num_components, random_state=self.seed)), \n","                (self.name, self.model)\n","                ])\n","        self.apply_PCA = True\n","        self.num_components = num_components\n","    else:\n","        self.pipeline = Pipeline([\n","                ('scaler', self.feature_scaler), \n","                ('class_balancer', self.class_balancer),\n","                (self.name, self.model)\n","                ])\n","        \n","    ##apply nested cross validation\n","    # https://machinelearningmastery.com/nested-cross-validation-for-machine-learning-with-python/\n","    # the k-fold cross-validation procedure for model hyperparameter optimization is nested \n","    # inside the k-fold cross-validation procedure for model selection. \n","    # configure the outer cross-validation procedure to assess model performance\n","    cv_outer = StratifiedKFold(n_splits=self.cv_outer, shuffle=True, random_state=self.seed)\n","\n","    for train_ix, test_ix in cv_outer.split(X, y):  # k outer folds, k = 10\n","        X_train, X_test = X.iloc[train_ix, :], X.iloc[test_ix, :]\n","        y_train, y_test = y.iloc[train_ix], y.iloc[test_ix]\n","        \n","        print(\"Computing inner cross validation for grid search of best hyperparameters...\")\n","        # configure the inner cross-validation procedure for grid search of best hyperparameters.  \n","        # selecting the best model (including parameters). \n","        cv_inner = StratifiedKFold(n_splits=self.cv_inner, shuffle=True, random_state=self.seed)\n","        #scorer = make_scorer(self.score_metric, average = 'weighted')\n","        '''\n","        search = RandomizedSearchCV(estimator=self.pipeline, param_distributions=self.params_grid, \n","                                    n_iter=20, cv=cv_inner, scoring=scorer, refit=True, verbose=2)\n","        '''\n","        search = GridSearchCV(estimator=self.pipeline, param_grid=self.params_grid, cv=cv_inner,\n","                              scoring=self.score_metric, refit=True, verbose=4)\n","        # refit = True --> configure the hyperparameter search to refit a final model\n","        # with the entire training dataset using the best hyperparameters found during the search.\n","\n","        # execute search\n","        search.fit(X_train, y_train.values.ravel())\n","        # get the best performing model fit on the whole training set\n","        # This model can then be used to make predictions on the holdout data \n","        # from the outer loop and estimate the performance of the model.\n","        best_model = search.best_estimator_ \n","        best_param = search.best_params_\n","        best_score = search.best_score_\n","        \n","        # evaluate the performance of the model on the hold out data.\n","        #  you are not assessing just the quality of the model, but the quality of the procedure for model selection\n","        y_test_pred = search.predict(X_test)\n","        test_score = f1_score(y_test, y_test_pred)\n","        y_train_pred = search.predict(X_train)\n","        train_score = f1_score(y_train, y_train_pred)\n","\n","        self.ncv_inner_results.append(best_score)\n","        self.ncv_test_outer_results.append(test_score)\n","        self.ncv_train_outer_results.append(train_score)\n","        self.ncv_best_hyperparams.append(best_param)\n","    \n","        print('\\n--------------------------------------------\\n')\n","        print(f\"Inner CV (Hyperparameters and model selection): \")\n","        print(f\"  F1-score = {best_score}\")\n","        print(f\"  Best hyperparams = {best_param}\")\n","        print(f\"Outer CV (Quality of model selection assessment): \")\n","        print(f\"  F1-score = {test_score}\")\n","        print('\\n--------------------------------------------\\n')\n","\n","    self.ncv_global_mean_score = mean(self.ncv_test_outer_results)\n","    self.ncv_global_std_score = std(self.ncv_test_outer_results)\n","    global_train_score = mean(self.ncv_train_outer_results)\n","    global_train_std = std(self.ncv_train_outer_results)\n","\n","    print('\\n--------------------------------------------\\n')\n","    print(f\"Mean training F1-score = {str(global_train_score)} ({str(global_train_std)})\")\n","    print(f\"Mean validation F1-score = {str(self.ncv_global_mean_score)} ({str(self.ncv_global_std_score)})\")\n","    \n","    print(\"List of best hyperparameters to check stability: \")\n","    \n","    best_hyperparams_dict = {}\n","    for best_hyps in self.ncv_best_hyperparams:\n","      for k,v in best_hyps.items():\n","        if k not in best_hyperparams_dict:\n","            best_hyperparams_dict[k] = [v]\n","        else:\n","            best_hyperparams_dict[k].append(v)\n","    print(display(pd.DataFrame.from_dict(best_hyperparams_dict)))\n","\n","    self.ncv_trained = True\n","\n","    return self.ncv_global_mean_score, self.ncv_global_std_score"]},{"cell_type":"code","execution_count":326,"metadata":{"id":"04ZGPPIJp81X","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1661109450205,"user_tz":-120,"elapsed":36,"user":{"displayName":"Elisa C","userId":"11182657622104819579"}},"outputId":"858977ea-e5f1-4c8f-bb13-87066308f2b4"},"outputs":[{"output_type":"stream","name":"stdout","text":["{'GENERAL': {'BOOLEAN_FEATURES': ['Gender'],\n","             'NUMERIC_FEATURES': ['Age',\n","                                  'TB',\n","                                  'DB',\n","                                  'AAP',\n","                                  'SGPT',\n","                                  'SGOT',\n","                                  'TP',\n","                                  'ALB',\n","                                  'AGR'],\n","             'PERFORM_NCV': True,\n","             'SEED': 42,\n","             'SHOW_METHOD': 1,\n","             'TARGET_COLUMN_NAME': 'CLASS'}}\n"]}],"source":["config_dict = {}\n","\n","config_dict['GENERAL'] = {\n","    'SEED': 42,\n","    'TARGET_COLUMN_NAME': \"CLASS\",\n","    'NUMERIC_FEATURES': ['Age','TB','DB','AAP','SGPT','SGOT','TP','ALB','AGR'],\n","    'BOOLEAN_FEATURES': ['Gender'],\n","    'SHOW_METHOD': 1, # 0 for colab, 1 for plotly, 2 for static png figures\n","    'PERFORM_NCV': True\n","}\n","\n","if config_dict['GENERAL']['SHOW_METHOD'] > 0:\n","  template_ =  'plotly_white'\n","else:\n","  template_ = 'plotly_dark'\n","\n","show_dict(config_dict)"]},{"cell_type":"markdown","metadata":{"id":"s1LsvtusoVG5"},"source":["## 1. Introduction<a class=\"anchor\" id=\"introduction\"></a>\n","The dataset used in this project was collected from north east of Andhra Pradesh, India and contains 583 *Liver Patient* records.\n","The data source is available on the UCI ML Repository at the following link:\n","https://archive.ics.uci.edu/ml/datasets/ILPD+%28Indian+Liver+Patient+Dataset%29# <br/>\n","\n","Patients with liver disease are continuously increasing particularly due to the large consumption of alcohol, intake of dangerous gases, use of drugs and use of contaminated food.\n","Automatic classification algorithms my help doctors in speed up the diagnosis and increase patients survival rate.\n","The aim of the project is therefore to analyze the presented dataset and compare some ML classification methods capable of distinguishing between *Liver* and *No Liver* patients.\n","\n","The report is divided into 5 main chapters of which the first 2 are dedicated to an exploratory analysis of the data, the two centrals (3 - 4) concern the classification phase and the last one is dedicated to the conclusions."]},{"cell_type":"markdown","metadata":{"id":"1xuGcEY_oVZ7"},"source":["###1.1 Dataset description<a class=\"anchor\" id=\"dataset_descr\"></a>\n","The dataset contains 416 instances with liver disease (71.36%) and 167 instances without the disease (28.64%); this means that we are dealing with a binary classification task, where the two categorical class labels are respectively *Liver Patient* and *No Liver Patient*.\n","\n","Attributes description:\n","\n","| Attribute Name  | Description  | Data Type  | Attribute Type | \n","|---|---|---|---|\n","| Age  |  Age of the patient (Any patient whose age exceeded 89 is listed as being of age \"90\") | Integer | Numeric |\n","| Gender | Gender of the patient  | String -> Integer| Binary |\n","| TB | Total Bilirubin | Real number |  Numeric |\n","| DB | Direct Bilirubin  | Real number | Numeric  |\n","| AAP | Alkphos Alkaline Phosphotase   | Integer  |  Numeric |\n","| SGPT  | Sgpt Alamine Aminotransferase  |  Integer | Numeric | \n","| SGOT |  Sgot Aspartate Aminotransferase |  Integer | Numeric | \n","| TP |  Total Proteins | Real number | Numeric  |\n","| ALB | Albumin  | Real number  | Numeric|\n","| AGR | A/G Ratio Albumin and Globulin Ratio  | Real number |Numeric |\n","\n","As we can see from the table above, the features report clinical informations of the patients. They are 10 in total, 9 of which are numeric and 1 is binary.\n","\n","Before performing the exploratory data analysis and the classification, the following preprocessing steps are applied to the data:\n","1. Change class label values for *No Liver Patient* from 2 to 0, to follow the more common naming convention for binary classification (0 for negative class and 1 for positive class).\n","2. Use the Label Encoding technique to encode the **Gender** categorical feature  (\"Female\"/\"Male\") respectively with the integer values 0 and 1, to convert them into a machine-readable form.\n","\n","\n","\n"]},{"cell_type":"code","execution_count":327,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":784},"executionInfo":{"elapsed":3106,"status":"ok","timestamp":1661109453282,"user":{"displayName":"Elisa C","userId":"11182657622104819579"},"user_tz":-120},"id":"C15NV5JlqeBX","outputId":"862de288-1639-4363-ed20-cdbf1f05dfab"},"outputs":[{"output_type":"stream","name":"stdout","text":["Label encoding for Gender feature:\n","{'Female': 0, 'Male': 1}\n","\n","Some Dataset records:\n"]},{"output_type":"display_data","data":{"text/plain":["   Age  Gender    TB   DB  AAP  SGPT  SGOT   TP  ALB   AGR  CLASS\n","0   65       0   0.7  0.1  187    16    18  6.8  3.3  0.90      1\n","1   62       1  10.9  5.5  699    64   100  7.5  3.2  0.74      1\n","2   62       1   7.3  4.1  490    60    68  7.0  3.3  0.89      1\n","3   58       1   1.0  0.4  182    14    20  6.8  3.4  1.00      1\n","4   72       1   3.9  2.0  195    27    59  7.3  2.4  0.40      1"],"text/html":["\n","  <div id=\"df-813f7149-f8d2-493a-af85-099fcca04695\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Age</th>\n","      <th>Gender</th>\n","      <th>TB</th>\n","      <th>DB</th>\n","      <th>AAP</th>\n","      <th>SGPT</th>\n","      <th>SGOT</th>\n","      <th>TP</th>\n","      <th>ALB</th>\n","      <th>AGR</th>\n","      <th>CLASS</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>65</td>\n","      <td>0</td>\n","      <td>0.7</td>\n","      <td>0.1</td>\n","      <td>187</td>\n","      <td>16</td>\n","      <td>18</td>\n","      <td>6.8</td>\n","      <td>3.3</td>\n","      <td>0.90</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>62</td>\n","      <td>1</td>\n","      <td>10.9</td>\n","      <td>5.5</td>\n","      <td>699</td>\n","      <td>64</td>\n","      <td>100</td>\n","      <td>7.5</td>\n","      <td>3.2</td>\n","      <td>0.74</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>62</td>\n","      <td>1</td>\n","      <td>7.3</td>\n","      <td>4.1</td>\n","      <td>490</td>\n","      <td>60</td>\n","      <td>68</td>\n","      <td>7.0</td>\n","      <td>3.3</td>\n","      <td>0.89</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>58</td>\n","      <td>1</td>\n","      <td>1.0</td>\n","      <td>0.4</td>\n","      <td>182</td>\n","      <td>14</td>\n","      <td>20</td>\n","      <td>6.8</td>\n","      <td>3.4</td>\n","      <td>1.00</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>72</td>\n","      <td>1</td>\n","      <td>3.9</td>\n","      <td>2.0</td>\n","      <td>195</td>\n","      <td>27</td>\n","      <td>59</td>\n","      <td>7.3</td>\n","      <td>2.4</td>\n","      <td>0.40</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-813f7149-f8d2-493a-af85-099fcca04695')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-813f7149-f8d2-493a-af85-099fcca04695 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-813f7149-f8d2-493a-af85-099fcca04695');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","Number of samples = 583 | Number of features = 10\n","\n","Liver Patient (class label = 1): 416 instances (71.36%)\n","No Liver Patient (class label = 0): 167 instances (28.64%)\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["<IPython.lib.display.IFrame at 0x7f891ae91bd0>"],"text/html":["\n","        <iframe\n","            width=\"400px\"\n","            height=\"400px\"\n","            src=\"https://plotly.com/~elisa_c/193.embed\"\n","            frameborder=\"0\"\n","            allowfullscreen\n","        ></iframe>\n","        "]},"metadata":{},"execution_count":327}],"source":["dataset_df = read_dataset(data_file_path, file_type= \"csv\")\n","dataset_df.loc[dataset_df['CLASS'] == 2, 'CLASS'] = 0\n","\n","le = preprocessing.LabelEncoder()\n","dataset_df['Gender'] = le.fit_transform(dataset_df['Gender'])\n","le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n","print(\"Label encoding for Gender feature:\")\n","print(f\"{le_name_mapping}\\n\")\n","\n","print(\"Some Dataset records:\")\n","display(dataset_df.head())\n","\n","X = dataset_df.drop(columns=[config_dict['GENERAL']['TARGET_COLUMN_NAME']])\n","y = dataset_df[config_dict['GENERAL']['TARGET_COLUMN_NAME']] # dataframe containing class column\n","\n","features_names = X.columns.values\n","#print_formatted_list(\"Feature names\", features_names)\n","class_names = list(set(y))\n","#print_formatted_list(\"Class names\", class_names)\n","\n","fig, data_series = prepare_bar_plot(y, title = \"Distribution of samples per class\", template_=template_)\n","print(f'\\nNumber of samples = {dataset_df.shape[0]} | Number of features = {len(features_names)}\\n')\n","for value in zip(data_series.values, data_series.index):\n","    if(value[1] == 1):\n","      class_name = \"Liver Patient\"\n","    else:\n","      class_name = \"No Liver Patient\"\n","    print(\"%s (class label = %s): %d instances (%.2f%%)\" % (class_name, value[1], value[0], (value[0]/y.shape[0])*100))\n","print()\n","\n","'''\n","if config_dict['GENERAL']['SHOW_METHOD'] == 0:\n","  fig.show()\n","elif config_dict['GENERAL']['SHOW_METHOD'] == 1:\n","  py.iplot(fig, filename = 'bar_plot')\n","elif config_dict['GENERAL']['SHOW_METHOD'] == 2:\n","  fig.show(renderer='svg')\n","'''\n","py.iplot(fig, filename = 'bar_plot_per_class')"]},{"cell_type":"markdown","source":["From the bar char above we can see that the distribution of the samples among the two classes is unbalanced (71.36% of records are *Liver Patients*). We will see in chapter [3.2](#Rebalancing) how to deal with an unbalanced dataset."],"metadata":{"id":"gQfV-lgsiA0Y"}},{"cell_type":"markdown","metadata":{"id":"FsIpDTxXorMz"},"source":["###1.2 Check for missing values<a class=\"anchor\" id=\"check_missing_values\"></a>\n","We can observe below that there are 4 missing values for the attribute **AGR** in the dataset. The min value is close for the two classes, while the max value is a little bit larger for the positive class. The mean value shows than on average there are no substantial differences between the two classes for that attribute."]},{"cell_type":"code","execution_count":328,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":338},"executionInfo":{"elapsed":25,"status":"ok","timestamp":1661109453282,"user":{"displayName":"Elisa C","userId":"11182657622104819579"},"user_tz":-120},"id":"8efsbdpTyjGd","outputId":"b94b24e7-f643-4b02-ea6c-2c3939461c75"},"outputs":[{"output_type":"stream","name":"stdout","text":["Missing values per feature:\n","Age       0\n","Gender    0\n","TB        0\n","DB        0\n","AAP       0\n","SGPT      0\n","SGOT      0\n","TP        0\n","ALB       0\n","AGR       4\n","dtype: int64\n","\n"]},{"output_type":"display_data","data":{"text/plain":["   CLASS  min(AGR)  max(AGR)  mean(AGR)\n","0      0      0.37       1.9   1.029576\n","1      1      0.30       2.8   0.914179"],"text/html":["\n","  <div id=\"df-1e8f1189-7d0c-4159-a677-ee33d4d9e7b6\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>CLASS</th>\n","      <th>min(AGR)</th>\n","      <th>max(AGR)</th>\n","      <th>mean(AGR)</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0.37</td>\n","      <td>1.9</td>\n","      <td>1.029576</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0.30</td>\n","      <td>2.8</td>\n","      <td>0.914179</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1e8f1189-7d0c-4159-a677-ee33d4d9e7b6')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-1e8f1189-7d0c-4159-a677-ee33d4d9e7b6 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-1e8f1189-7d0c-4159-a677-ee33d4d9e7b6');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}],"source":["# check for null values in the dataset\n","print(\"Missing values per feature:\")\n","print(X.isna().sum())\n","print()\n","aggregate_df = dataset_df.groupby('CLASS', as_index=False)['AGR'].min().rename(columns={'AGR': 'min(AGR)'})\n","aggregate_df['max(AGR)'] = dataset_df.groupby('CLASS', as_index=False)['AGR'].max().rename(columns={'AGR': 'max(AGR)'})['max(AGR)']\n","aggregate_df['mean(AGR)'] = dataset_df.groupby('CLASS', as_index=False)['AGR'].mean().rename(columns={'AGR': 'mean(AGR)'})['mean(AGR)']\n","display(aggregate_df)"]},{"cell_type":"markdown","source":["The patients with missing values are only 4. The choice is to put as value for the **AGR** attribute the mean computed per class to which the patient belongs."],"metadata":{"id":"0BO0pcYRn87m"}},{"cell_type":"code","execution_count":329,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1661109453284,"user":{"displayName":"Elisa C","userId":"11182657622104819579"},"user_tz":-120},"id":"rjMfXzivmhYC","outputId":"79e7de33-27fe-4bce-a03b-7ccf1ac2c75e"},"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 583 entries, 0 to 582\n","Data columns (total 10 columns):\n"," #   Column  Non-Null Count  Dtype  \n","---  ------  --------------  -----  \n"," 0   Age     583 non-null    int64  \n"," 1   Gender  583 non-null    int64  \n"," 2   TB      583 non-null    float64\n"," 3   DB      583 non-null    float64\n"," 4   AAP     583 non-null    int64  \n"," 5   SGPT    583 non-null    int64  \n"," 6   SGOT    583 non-null    int64  \n"," 7   TP      583 non-null    float64\n"," 8   ALB     583 non-null    float64\n"," 9   AGR     583 non-null    float64\n","dtypes: float64(5), int64(5)\n","memory usage: 45.7 KB\n"]}],"source":["dataset_df['AGR'].fillna(dataset_df.groupby('CLASS')['AGR'].transform('mean').round(2), inplace = True)\n","X = dataset_df.drop(columns=[config_dict['GENERAL']['TARGET_COLUMN_NAME']])\n","X.info()"]},{"cell_type":"markdown","metadata":{"id":"x2HfW8lBorf0"},"source":["###1.3 Checking for outliers<a class=\"anchor\" id=\"check_outliers\"></a>\n","\n","The interactive histogram below shows the distribution of each feature for *Liver Patients* and *No Liver Patients*.\n","\n","Concerning the **Gender** we can see that the Female patients are less then the Male patients and this distribution is quite preserved on both the 2 classes (*Liver* / *No Liver*).\n","\n","For both class labels the **Age** values ​​range from children to the elderly, although the largest number of patients is concentrated in the range between 30 and 60 and the mean Age is around 40.\n","\n","The five features **TB**, **DB**, **AAP**, **SGPT**, **SGOT** have some data more shifted to the right (larger values) for patients with liver disease, infact the median and especially the mean, are larger with respect to those of the group without the disease. In addition, is possible to observe that some diseased patients have very high values for those features. We do not consider these ​​as outliers as they are possible values ​​in patients with advanced disease and can help us to discriminate between the two classes.\n","It is also possible to observe that many patients labeled as diseased have still \"normal\" values.\n"]},{"cell_type":"code","execution_count":330,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":547},"executionInfo":{"elapsed":3003,"status":"ok","timestamp":1661109456274,"user":{"displayName":"Elisa C","userId":"11182657622104819579"},"user_tz":-120},"id":"3w2JF1sJze8p","outputId":"97e1a6dc-7f82-4a37-d46b-422464ddf548"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<IPython.lib.display.IFrame at 0x7f891e8467d0>"],"text/html":["\n","        <iframe\n","            width=\"100%\"\n","            height=\"525px\"\n","            src=\"https://plotly.com/~elisa_c/195.embed\"\n","            frameborder=\"0\"\n","            allowfullscreen\n","        ></iframe>\n","        "]},"metadata":{},"execution_count":330}],"source":["fig = prepare_histogram_plot(dataset_df, features_names, class_names, config_dict['GENERAL'], template_)\n","'''\n","if config_dict['GENERAL']['SHOW_METHOD'] == 0:\n","  fig.show()\n","elif config_dict['GENERAL']['SHOW_METHOD'] == 1:\n","  py.iplot(fig, filename = 'bar_plot')\n","elif config_dict['GENERAL']['SHOW_METHOD'] == 2:\n","  fig.show(renderer='svg')\n","'''\n","py.iplot(fig, filename = 'bar_plot_per_feature')"]},{"cell_type":"code","source":["#grouped_df = dataset_df.groupby(['CLASS','Gender']).size().reset_index(name='Counts')\n","#display(grouped_df)\n","no_liver_group_patients = dataset_df.loc[dataset_df[\"CLASS\"] == 0]\n","no_liver_group_patients = no_liver_group_patients[\"Gender\"].value_counts(normalize=True).round(4) * 100\n","no_liver_group_patients = no_liver_group_patients.to_frame().reset_index()\n","no_liver_group_patients.columns = [\"Gender\", \"%\"]\n","print(\"No liver Patients:\")\n","display(no_liver_group_patients)\n","print()\n","liver_group_patients = dataset_df.loc[dataset_df[\"CLASS\"] == 1]\n","liver_group_patients = liver_group_patients[\"Gender\"].value_counts(normalize=True).round(4) * 100\n","liver_group_patients = liver_group_patients.to_frame().reset_index()\n","liver_group_patients.columns = [\"Gender\", \"%\"]\n","print(\"Liver Patients:\")\n","display(liver_group_patients)"],"metadata":{"id":"Rm188XXdRQ5X","colab":{"base_uri":"https://localhost:8080/","height":259},"executionInfo":{"status":"ok","timestamp":1661109456275,"user_tz":-120,"elapsed":21,"user":{"displayName":"Elisa C","userId":"11182657622104819579"}},"outputId":"178c9ebc-dd78-4268-a34e-8891404a81ab"},"execution_count":331,"outputs":[{"output_type":"stream","name":"stdout","text":["No liver Patients:\n"]},{"output_type":"display_data","data":{"text/plain":["   Gender      %\n","0       1  70.06\n","1       0  29.94"],"text/html":["\n","  <div id=\"df-73a4397a-28ca-41f6-b9eb-7bfbf46d4a07\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Gender</th>\n","      <th>%</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>70.06</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>29.94</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-73a4397a-28ca-41f6-b9eb-7bfbf46d4a07')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-73a4397a-28ca-41f6-b9eb-7bfbf46d4a07 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-73a4397a-28ca-41f6-b9eb-7bfbf46d4a07');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","Liver Patients:\n"]},{"output_type":"display_data","data":{"text/plain":["   Gender      %\n","0       1  77.88\n","1       0  22.12"],"text/html":["\n","  <div id=\"df-77efdb8b-d563-43cc-b09e-325ed6044f36\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Gender</th>\n","      <th>%</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>77.88</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>22.12</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-77efdb8b-d563-43cc-b09e-325ed6044f36')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-77efdb8b-d563-43cc-b09e-325ed6044f36 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-77efdb8b-d563-43cc-b09e-325ed6044f36');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}]},{"cell_type":"markdown","source":[" | Class|Gender |  %| \n"," |---|---|---|\n"," |No Liver Patient| 1  | 70.06  | \n"," |No  Liver PAtient | 0 | 29.94  | \n"," |Liver Patient| 1  | 77.88  | \n"," |Liver PAtient | 0 | 22.12  | \n"],"metadata":{"id":"koxHADgcACXa"}},{"cell_type":"markdown","metadata":{"id":"hufQ4_MYo26v"},"source":["###1.5 Split dataset<a class=\"anchor\" id=\"split_dataset\"></a>\n","The data is splitted into 2 separated datasets with stratification, in order to mantain the distribution of samples among the 2 classes. The training dataset $X_{train}$ is used to train the classification model, while the test dataset $X_{test}$ is used to test the performance of the trained model on \"new\" data. This prevent any leakage of information from the test dataset into the preprocessing and training phase and allows to provide an unbiased evaluation of the final model.\n","The sizes of the obtained datasets are reported below:\n","\n","|   | Train  |  Test | Tot|  \n","|---|---|---|---|\n","| %  | 80  | 20  | 100|\n","|  Number of samples | 466  | 117  | 583| \n","  "]},{"cell_type":"code","execution_count":332,"metadata":{"id":"ZDsWeeXF8r7s","executionInfo":{"status":"ok","timestamp":1661109456276,"user_tz":-120,"elapsed":14,"user":{"displayName":"Elisa C","userId":"11182657622104819579"}}},"outputs":[],"source":["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=config_dict['GENERAL']['SEED'], stratify=y, shuffle=True)"]},{"cell_type":"markdown","source":["The bar chart shows the distribution of the samples among the two classes for the training and test datasets. From the chart is possible to notice that the distribution of the original data is preserved after the splitting."],"metadata":{"id":"6heZiyTd-aMf"}},{"cell_type":"code","source":["fig, data_series_train, data_series_test = prepare_bar_plots(y_train, \n","                                                             y_test, \n","                                                             \"Distribution of patients per classs\", \n","                                                             template_)\n","\n","py.iplot(fig, filename = 'bar_plot_train_test')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":422},"id":"O2CJgRP4v5Go","executionInfo":{"status":"ok","timestamp":1661109459054,"user_tz":-120,"elapsed":2791,"user":{"displayName":"Elisa C","userId":"11182657622104819579"}},"outputId":"018c5074-1f35-4b35-c71a-4b0d0b6218e4"},"execution_count":333,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<IPython.lib.display.IFrame at 0x7f89219acd50>"],"text/html":["\n","        <iframe\n","            width=\"400px\"\n","            height=\"400px\"\n","            src=\"https://plotly.com/~elisa_c/229.embed\"\n","            frameborder=\"0\"\n","            allowfullscreen\n","        ></iframe>\n","        "]},"metadata":{},"execution_count":333}]},{"cell_type":"code","source":["print(f'Train dataset length: {X_train.shape[0]}\\n')\n","for value in zip(data_series_train.values, data_series_train.index):\n","    print(\"%s: %d instances (%.2f%%)\" % (value[1], value[0], (value[0]/y_train.shape[0])*100))\n","print()\n","\n","print(f'Test dataset length: {X_test.shape[0]}\\n')\n","for value in zip(data_series_test.values, data_series_test.index):\n","    print(\"%s: %d instances (%.2f%%)\" % (value[1], value[0], (value[0]/y_test.shape[0])*100))\n","print()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t3_obZCfxkDW","executionInfo":{"status":"ok","timestamp":1661109459055,"user_tz":-120,"elapsed":22,"user":{"displayName":"Elisa C","userId":"11182657622104819579"}},"outputId":"3a0ae199-5618-4793-cb23-f7bf685d5aa0"},"execution_count":334,"outputs":[{"output_type":"stream","name":"stdout","text":["Train dataset length: 466\n","\n","1: 333 instances (71.46%)\n","0: 133 instances (28.54%)\n","\n","Test dataset length: 117\n","\n","1: 83 instances (70.94%)\n","0: 34 instances (29.06%)\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"MSFSzNp79Aw3"},"source":["##2. Exploratory data analysis<a class=\"anchor\" id=\"exploratory_data_analysis\"></a>\n","\n","The chapter aims to investigate the correlation among the features and their ranges of values, in order to decide to make or not some preprocessing step. The analysis is done by considering only the training data to prevent any data leakage from the test dataset in the decision making."]},{"cell_type":"markdown","metadata":{"id":"gSTlRGtH9P9e"},"source":["###2.1 Statistical quantitative description of features<a class=\"anchor\" id=\"stat_features_descr\"></a>\n","\n","The table below shows a descriptive statistic for each feature of the training dataset, regardless of class label. Only numeric features are included in this quantitative analysis.\n","\n","For numeric data, the result’s index includes:\n","- count: number of samples\n","- mean: the mean of the attribute among all samples\n","- std: the standard deviation of the attribute\n","- min: the minimum value of the attribute\n","- 25%: the lower percentile\n","- 50%: the median\n","- 75%: the upper percentile\n","- max: the maximum value of the attribute\n","\n","We can observe that the range of values of the features vary greatly, for this reason is important to standardize the data before applying ML methods, to make sure that all the features equally contribute during training process. We will see this process in chapter [3.1](#Feature scaling). "]},{"cell_type":"code","execution_count":335,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":300},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1661109459056,"user":{"displayName":"Elisa C","userId":"11182657622104819579"},"user_tz":-120},"id":"-tKWSrB29OR7","outputId":"dc1a41f8-ff09-45f5-a3b0-a3536fe4ed38"},"outputs":[{"output_type":"display_data","data":{"text/plain":["              Age          TB          DB          AAP         SGPT  \\\n","count  466.000000  466.000000  466.000000   466.000000   466.000000   \n","mean    44.519313    2.976180    1.372961   294.019313    83.150215   \n","std     16.000694    4.959016    2.558393   252.866027   193.080002   \n","min      4.000000    0.400000    0.100000    75.000000    10.000000   \n","25%     33.000000    0.800000    0.200000   176.250000    23.000000   \n","50%     45.000000    1.000000    0.300000   208.500000    35.000000   \n","75%     57.000000    2.600000    1.275000   298.000000    60.000000   \n","max     90.000000   30.500000   17.100000  2110.000000  2000.000000   \n","\n","              SGOT          TP         ALB         AGR  \n","count   466.000000  466.000000  466.000000  466.000000  \n","mean    103.881974    6.483906    3.153219    0.951288  \n","std     223.780425    1.078439    0.789283    0.315742  \n","min      10.000000    3.000000    1.000000    0.300000  \n","25%      25.000000    5.700000    2.600000    0.750000  \n","50%      41.000000    6.550000    3.100000    0.955000  \n","75%      83.750000    7.200000    3.800000    1.100000  \n","max    2946.000000    9.600000    5.500000    2.800000  "],"text/html":["\n","  <div id=\"df-2c452c4d-7d1e-4c21-b403-d219b140ce19\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Age</th>\n","      <th>TB</th>\n","      <th>DB</th>\n","      <th>AAP</th>\n","      <th>SGPT</th>\n","      <th>SGOT</th>\n","      <th>TP</th>\n","      <th>ALB</th>\n","      <th>AGR</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>466.000000</td>\n","      <td>466.000000</td>\n","      <td>466.000000</td>\n","      <td>466.000000</td>\n","      <td>466.000000</td>\n","      <td>466.000000</td>\n","      <td>466.000000</td>\n","      <td>466.000000</td>\n","      <td>466.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>44.519313</td>\n","      <td>2.976180</td>\n","      <td>1.372961</td>\n","      <td>294.019313</td>\n","      <td>83.150215</td>\n","      <td>103.881974</td>\n","      <td>6.483906</td>\n","      <td>3.153219</td>\n","      <td>0.951288</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>16.000694</td>\n","      <td>4.959016</td>\n","      <td>2.558393</td>\n","      <td>252.866027</td>\n","      <td>193.080002</td>\n","      <td>223.780425</td>\n","      <td>1.078439</td>\n","      <td>0.789283</td>\n","      <td>0.315742</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>4.000000</td>\n","      <td>0.400000</td>\n","      <td>0.100000</td>\n","      <td>75.000000</td>\n","      <td>10.000000</td>\n","      <td>10.000000</td>\n","      <td>3.000000</td>\n","      <td>1.000000</td>\n","      <td>0.300000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>33.000000</td>\n","      <td>0.800000</td>\n","      <td>0.200000</td>\n","      <td>176.250000</td>\n","      <td>23.000000</td>\n","      <td>25.000000</td>\n","      <td>5.700000</td>\n","      <td>2.600000</td>\n","      <td>0.750000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>45.000000</td>\n","      <td>1.000000</td>\n","      <td>0.300000</td>\n","      <td>208.500000</td>\n","      <td>35.000000</td>\n","      <td>41.000000</td>\n","      <td>6.550000</td>\n","      <td>3.100000</td>\n","      <td>0.955000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>57.000000</td>\n","      <td>2.600000</td>\n","      <td>1.275000</td>\n","      <td>298.000000</td>\n","      <td>60.000000</td>\n","      <td>83.750000</td>\n","      <td>7.200000</td>\n","      <td>3.800000</td>\n","      <td>1.100000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>90.000000</td>\n","      <td>30.500000</td>\n","      <td>17.100000</td>\n","      <td>2110.000000</td>\n","      <td>2000.000000</td>\n","      <td>2946.000000</td>\n","      <td>9.600000</td>\n","      <td>5.500000</td>\n","      <td>2.800000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2c452c4d-7d1e-4c21-b403-d219b140ce19')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-2c452c4d-7d1e-4c21-b403-d219b140ce19 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-2c452c4d-7d1e-4c21-b403-d219b140ce19');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}],"source":["display(X_train[config_dict['GENERAL']['NUMERIC_FEATURES']].describe())"]},{"cell_type":"markdown","source":["Below is reported the quantitative description, per class. In the next section the box plots are shown to better visualize the different statistics of the features with respect to the class label."],"metadata":{"id":"sveevD_tw-xW"}},{"cell_type":"code","execution_count":336,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":635},"executionInfo":{"elapsed":392,"status":"ok","timestamp":1661109459435,"user":{"displayName":"Elisa C","userId":"11182657622104819579"},"user_tz":-120},"id":"hpe4w3wCFzW_","outputId":"e6d7ee0c-2ea6-4689-99d4-4007eecb67c4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Quantitative description (class 1):\n"]},{"output_type":"display_data","data":{"text/plain":["              Age          TB          DB          AAP         SGPT  \\\n","count  333.000000  333.000000  333.000000   333.000000   333.000000   \n","mean    46.069069    3.687988    1.750150   321.027027   102.405405   \n","std     15.272565    5.672341    2.921767   278.417455   224.982732   \n","min      7.000000    0.400000    0.100000    75.000000    12.000000   \n","25%     34.000000    0.800000    0.200000   185.000000    25.000000   \n","50%     46.000000    1.300000    0.500000   228.000000    40.000000   \n","75%     58.000000    3.300000    1.600000   316.000000    74.000000   \n","max     90.000000   30.500000   17.100000  2110.000000  2000.000000   \n","\n","              SGOT          TP         ALB         AGR  \n","count   333.000000  333.000000  333.000000  333.000000  \n","mean    129.072072    6.452553    3.080480    0.924715  \n","std     259.551387    1.070765    0.768983    0.323926  \n","min      11.000000    3.000000    1.000000    0.300000  \n","25%      28.000000    5.700000    2.600000    0.700000  \n","50%      50.000000    6.600000    3.000000    0.900000  \n","75%     104.000000    7.100000    3.700000    1.100000  \n","max    2946.000000    9.600000    5.500000    2.800000  "],"text/html":["\n","  <div id=\"df-cfe63639-06d6-4b09-9ec1-4115f4c8f20f\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Age</th>\n","      <th>TB</th>\n","      <th>DB</th>\n","      <th>AAP</th>\n","      <th>SGPT</th>\n","      <th>SGOT</th>\n","      <th>TP</th>\n","      <th>ALB</th>\n","      <th>AGR</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>333.000000</td>\n","      <td>333.000000</td>\n","      <td>333.000000</td>\n","      <td>333.000000</td>\n","      <td>333.000000</td>\n","      <td>333.000000</td>\n","      <td>333.000000</td>\n","      <td>333.000000</td>\n","      <td>333.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>46.069069</td>\n","      <td>3.687988</td>\n","      <td>1.750150</td>\n","      <td>321.027027</td>\n","      <td>102.405405</td>\n","      <td>129.072072</td>\n","      <td>6.452553</td>\n","      <td>3.080480</td>\n","      <td>0.924715</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>15.272565</td>\n","      <td>5.672341</td>\n","      <td>2.921767</td>\n","      <td>278.417455</td>\n","      <td>224.982732</td>\n","      <td>259.551387</td>\n","      <td>1.070765</td>\n","      <td>0.768983</td>\n","      <td>0.323926</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>7.000000</td>\n","      <td>0.400000</td>\n","      <td>0.100000</td>\n","      <td>75.000000</td>\n","      <td>12.000000</td>\n","      <td>11.000000</td>\n","      <td>3.000000</td>\n","      <td>1.000000</td>\n","      <td>0.300000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>34.000000</td>\n","      <td>0.800000</td>\n","      <td>0.200000</td>\n","      <td>185.000000</td>\n","      <td>25.000000</td>\n","      <td>28.000000</td>\n","      <td>5.700000</td>\n","      <td>2.600000</td>\n","      <td>0.700000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>46.000000</td>\n","      <td>1.300000</td>\n","      <td>0.500000</td>\n","      <td>228.000000</td>\n","      <td>40.000000</td>\n","      <td>50.000000</td>\n","      <td>6.600000</td>\n","      <td>3.000000</td>\n","      <td>0.900000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>58.000000</td>\n","      <td>3.300000</td>\n","      <td>1.600000</td>\n","      <td>316.000000</td>\n","      <td>74.000000</td>\n","      <td>104.000000</td>\n","      <td>7.100000</td>\n","      <td>3.700000</td>\n","      <td>1.100000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>90.000000</td>\n","      <td>30.500000</td>\n","      <td>17.100000</td>\n","      <td>2110.000000</td>\n","      <td>2000.000000</td>\n","      <td>2946.000000</td>\n","      <td>9.600000</td>\n","      <td>5.500000</td>\n","      <td>2.800000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cfe63639-06d6-4b09-9ec1-4115f4c8f20f')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-cfe63639-06d6-4b09-9ec1-4115f4c8f20f button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-cfe63639-06d6-4b09-9ec1-4115f4c8f20f');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","Quantitative description (class 0):\n"]},{"output_type":"display_data","data":{"text/plain":["              Age          TB          DB          AAP        SGPT  \\\n","count  133.000000  133.000000  133.000000   133.000000  133.000000   \n","mean    40.639098    1.193985    0.428571   226.398496   34.939850   \n","std     17.146578    1.107123    0.573476   154.385828   27.197304   \n","min      4.000000    0.500000    0.100000    90.000000   10.000000   \n","25%     27.000000    0.700000    0.200000   162.000000   20.000000   \n","50%     38.000000    0.800000    0.200000   188.000000   28.000000   \n","75%     55.000000    1.100000    0.400000   215.000000   37.000000   \n","max     85.000000    7.300000    3.600000  1580.000000  181.000000   \n","\n","             SGOT          TP         ALB         AGR  \n","count  133.000000  133.000000  133.000000  133.000000  \n","mean    40.812030    6.562406    3.335338    1.017820  \n","std     36.922349    1.097559    0.812702    0.284675  \n","min     10.000000    3.700000    1.400000    0.370000  \n","25%     21.000000    5.900000    2.900000    0.900000  \n","50%     30.000000    6.500000    3.300000    1.000000  \n","75%     43.000000    7.400000    4.000000    1.200000  \n","max    285.000000    9.200000    5.000000    1.850000  "],"text/html":["\n","  <div id=\"df-6334f75d-d060-47d2-b430-d336a8d3d012\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Age</th>\n","      <th>TB</th>\n","      <th>DB</th>\n","      <th>AAP</th>\n","      <th>SGPT</th>\n","      <th>SGOT</th>\n","      <th>TP</th>\n","      <th>ALB</th>\n","      <th>AGR</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>133.000000</td>\n","      <td>133.000000</td>\n","      <td>133.000000</td>\n","      <td>133.000000</td>\n","      <td>133.000000</td>\n","      <td>133.000000</td>\n","      <td>133.000000</td>\n","      <td>133.000000</td>\n","      <td>133.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>40.639098</td>\n","      <td>1.193985</td>\n","      <td>0.428571</td>\n","      <td>226.398496</td>\n","      <td>34.939850</td>\n","      <td>40.812030</td>\n","      <td>6.562406</td>\n","      <td>3.335338</td>\n","      <td>1.017820</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>17.146578</td>\n","      <td>1.107123</td>\n","      <td>0.573476</td>\n","      <td>154.385828</td>\n","      <td>27.197304</td>\n","      <td>36.922349</td>\n","      <td>1.097559</td>\n","      <td>0.812702</td>\n","      <td>0.284675</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>4.000000</td>\n","      <td>0.500000</td>\n","      <td>0.100000</td>\n","      <td>90.000000</td>\n","      <td>10.000000</td>\n","      <td>10.000000</td>\n","      <td>3.700000</td>\n","      <td>1.400000</td>\n","      <td>0.370000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>27.000000</td>\n","      <td>0.700000</td>\n","      <td>0.200000</td>\n","      <td>162.000000</td>\n","      <td>20.000000</td>\n","      <td>21.000000</td>\n","      <td>5.900000</td>\n","      <td>2.900000</td>\n","      <td>0.900000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>38.000000</td>\n","      <td>0.800000</td>\n","      <td>0.200000</td>\n","      <td>188.000000</td>\n","      <td>28.000000</td>\n","      <td>30.000000</td>\n","      <td>6.500000</td>\n","      <td>3.300000</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>55.000000</td>\n","      <td>1.100000</td>\n","      <td>0.400000</td>\n","      <td>215.000000</td>\n","      <td>37.000000</td>\n","      <td>43.000000</td>\n","      <td>7.400000</td>\n","      <td>4.000000</td>\n","      <td>1.200000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>85.000000</td>\n","      <td>7.300000</td>\n","      <td>3.600000</td>\n","      <td>1580.000000</td>\n","      <td>181.000000</td>\n","      <td>285.000000</td>\n","      <td>9.200000</td>\n","      <td>5.000000</td>\n","      <td>1.850000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6334f75d-d060-47d2-b430-d336a8d3d012')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-6334f75d-d060-47d2-b430-d336a8d3d012 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-6334f75d-d060-47d2-b430-d336a8d3d012');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}],"source":["X_train_class = X_train.copy()\n","X_train_class[config_dict['GENERAL']['TARGET_COLUMN_NAME']] = y_train\n","\n","liver_patients = X_train_class.loc[X_train_class[config_dict['GENERAL']['TARGET_COLUMN_NAME']] == 1].drop(columns=[config_dict['GENERAL']['TARGET_COLUMN_NAME']])\n","no_liver_patients = X_train_class.loc[X_train_class[config_dict['GENERAL']['TARGET_COLUMN_NAME']] == 0].drop(columns=[config_dict['GENERAL']['TARGET_COLUMN_NAME']])\n","print(\"Quantitative description (class 1):\")\n","display(liver_patients[config_dict['GENERAL']['NUMERIC_FEATURES']].describe()) # per class\n","print()\n","print(\"Quantitative description (class 0):\")\n","display(no_liver_patients[config_dict['GENERAL']['NUMERIC_FEATURES']].describe()) # per class"]},{"cell_type":"markdown","metadata":{"id":"AQ8bEMrf-B6c"},"source":["###2.2 Box plots<a class=\"anchor\" id=\"box_plots\"></a>\n","\n","One whisker box is plotted per numeric feature to visualize whether each feature presents different characteristics depending on the target class.\n","Before MinMax Scaler is applied to scale each feature to have the same range [0, 1]. \n","\n","A box plot visualizes the following main statistics:\n","- median\n","- the first quartile (Q1) and the third quartile (Q3) building the interquartile range (IQR)\n","- the lower fence (Q1 - 1.5 IQR) and the upper fence (Q3 + 1.5 IQR)\n","- the maximum and the minimum value\n","\n","Concerning the features **TB**, **DB**, **AAP**, **SGPT**, **SGOT**, the median and especially the mean are higher in the *Liver Patient* class. In addition, is possible to observe how, for class *Liver Patient*, there is a good number of samples whose values are very different from the median and tend to have much greater values.\n","Those set of features could be good candidate to discriminate among classes.\n","\n","As regards the features **TP**, **ALB**, **AGR**, median and mean do not change a lot among the 2 classes. The only observation is that *Liver Patients* tend to have some slighly lower values, beshid  some \"outliers\".\n","\n","\n","\n"]},{"cell_type":"code","execution_count":337,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":547},"executionInfo":{"elapsed":3606,"status":"ok","timestamp":1661109463037,"user":{"displayName":"Elisa C","userId":"11182657622104819579"},"user_tz":-120},"id":"6KRHA1Z3Bs4D","outputId":"ad65edcd-2882-4f25-c5a1-a607577bde3c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<IPython.lib.display.IFrame at 0x7f891c8d6710>"],"text/html":["\n","        <iframe\n","            width=\"100%\"\n","            height=\"525px\"\n","            src=\"https://plotly.com/~elisa_c/201.embed\"\n","            frameborder=\"0\"\n","            allowfullscreen\n","        ></iframe>\n","        "]},"metadata":{},"execution_count":337}],"source":["X_train_class_scaled = X_train_class.copy()\n","X_train_class_scaled[features_names] = MinMaxScaler().fit_transform(X_train_class_scaled[features_names])\n","fig = prepare_box_plot(X_train_class_scaled, config_dict['GENERAL']['NUMERIC_FEATURES'], class_names, config_dict['GENERAL'], \"Box plots per class\", template_)\n","\n","'''\n","if config_dict['GENERAL']['SHOW_METHOD'] == 0:\n","  fig.show()\n","elif config_dict['GENERAL']['SHOW_METHOD'] == 1:\n","  py.iplot(fig, filename = 'bo_plot_scaled')\n","elif config_dict['GENERAL']['SHOW_METHOD'] == 2:\n","  fig.show(renderer='svg')\n","'''\n","py.iplot(fig, filename = 'box_plot_scaled')"]},{"cell_type":"markdown","metadata":{"id":"dYRkUMumIHoM"},"source":["###2.3 Correlation analysis<a class=\"anchor\" id=\"corr_analysis\"></a>\n","To understand if there is some correlation among features the correlation matrix is shown as heatmap plot, in which high positive correlations are coloured more to the yellow and lower ones more to the purple. Negative correlations tend to be coloured in blue.\n","\n","The correlation matrix C is simply a square matrix which display in each entry the correlation coefficient between two variable $X_i$ and $X_j$.\n","The correlation coefficient is the Pearson's correlation coefficient that is obtained in the following way:\n","\n","  $c_{ij} = \\dfrac{Cov(X_i,X_j)}{\\sigma_{X_i} \\sigma_{X_j}}$\n","\n","where the numerator is the covariance of the two variables and the denominator is the product of their standard deviations.\n","\n","From the C matrix is possible to see that the feature pairs with higher correlation are the following:\n","\n","| Feature pair| Pearson's correlation coefficient|\n","|---|---|\n","| (TB, DB) | 0.98 |\n","| (SGPT, SGOT) | 0.88 | \n","| (TP, ALB) | 0.80 |\n","| (AGR, ALB) | 0.68 | \n","\n","while there is no feature pairs with high negative correlation.\n","\n","**TB** and **DB**, as shown in the matrix, are highly correlated, in fact Total Bilirubin is nothing more than the sum of Direct and Indirect Bilirubin. Direct Bilirubin in particular can indicate liver problems if present in high values. Concerning **SGOT** and **SGPT**, both are transaminases and elevated levels may be an indication of liver cell injury or damage. Albumina (**ALB**) is known to be about 60% of total proteins (**TP**), while **AGR** is computed as the ratio between Albumina and Globulina. This can help to explain the positive correlation between **TP** and **ALB** and between **ALB** and **ABR**. \n"]},{"cell_type":"code","execution_count":338,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":522},"executionInfo":{"elapsed":3434,"status":"ok","timestamp":1661109466464,"user":{"displayName":"Elisa C","userId":"11182657622104819579"},"user_tz":-120},"id":"UXJo_6aZIM3u","outputId":"be60931d-f8a2-41d0-b166-e89e72c1f49c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<IPython.lib.display.IFrame at 0x7f891c92eb90>"],"text/html":["\n","        <iframe\n","            width=\"650px\"\n","            height=\"500px\"\n","            src=\"https://plotly.com/~elisa_c/203.embed\"\n","            frameborder=\"0\"\n","            allowfullscreen\n","        ></iframe>\n","        "]},"metadata":{},"execution_count":338}],"source":["fig = prepare_heatmap(X_train, template_)\n","\n","'''\n","if config_dict['GENERAL']['SHOW_METHOD'] == 0:\n","  fig.show()\n","elif config_dict['GENERAL']['SHOW_METHOD'] == 1:\n","  py.iplot(fig, filename = 'heatmap')\n","elif config_dict['GENERAL']['SHOW_METHOD'] == 2:\n","  fig.show(renderer='svg')\n","'''\n","py.iplot(fig, filename = 'heatmap')"]},{"cell_type":"markdown","source":["Below, the pair plots confirm the presence of linear dipendence for the couples (**TB**, **DB**), (**SGPT**, **SGOT**), (**ALB**, **TP**) and (**AGR**, **ALB**)."],"metadata":{"id":"QrSAZpvnmmUM"}},{"cell_type":"code","execution_count":339,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":622},"executionInfo":{"elapsed":3922,"status":"ok","timestamp":1661109470382,"user":{"displayName":"Elisa C","userId":"11182657622104819579"},"user_tz":-120},"id":"XSAPT5AGKTdb","outputId":"76fe006f-2847-4eca-c308-c92de59a3e37"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<IPython.lib.display.IFrame at 0x7f891aed4090>"],"text/html":["\n","        <iframe\n","            width=\"600px\"\n","            height=\"600px\"\n","            src=\"https://plotly.com/~elisa_c/205.embed\"\n","            frameborder=\"0\"\n","            allowfullscreen\n","        ></iframe>\n","        "]},"metadata":{},"execution_count":339}],"source":["combinations = list(itertools.combinations(range(len(config_dict['GENERAL']['NUMERIC_FEATURES'])), 2))\n","fig = prepare_pairplot(X_train_class, config_dict['GENERAL'], combinations, config_dict['GENERAL']['NUMERIC_FEATURES'], \"Pair plots\", template_)\n","\n","'''\n","if config_dict['GENERAL']['SHOW_METHOD'] == 0:\n","  fig.show()\n","elif config_dict['GENERAL']['SHOW_METHOD'] == 1:\n","  py.iplot(fig, filename = 'pair_plot1')\n","elif config_dict['GENERAL']['SHOW_METHOD'] == 2:\n","  fig.show(renderer='svg')'''\n","\n","py.iplot(fig, filename = 'pair_plot')"]},{"cell_type":"markdown","source":["In chapter 3.3.2 is introduced an empirical dimensionality reduction technique which helps to visually identify strongly correlated features and eventually remove the duplicates."],"metadata":{"id":"PRfmVXdnubtT"}},{"cell_type":"markdown","metadata":{"id":"hyKccHFUQPW5"},"source":["##3. Preprocessing steps<a class=\"anchor\" id=\"preprocessing_steps\"></a>"]},{"cell_type":"markdown","source":["###3.1 Feature scaling<a class=\"anchor\" id=\"scaling\"></a>\n","As previously mentioned, since the range of the features vary greatly, is important to scale them before applying ML techniques. The numeric features are scaled using standardization (or z-score normalization) which consists in removing the mean and scaling to unit variance:\n","\n","$ z = \\frac{x-\\mu}{\\sigma} $\n","\n","when $\\mu$ is the mean and $\\sigma$ is the standard deviation.\n","\n","Centering and scaling happen independently on each feature by computing the relevant statistics on training data and then the values are stored and used to transform the test data.\n","The categorical feature **Gender** is left unchanged during this process."],"metadata":{"id":"hN_whXikiGzW"}},{"cell_type":"markdown","metadata":{"id":"FnoGqiCGQTvj"},"source":["###3.2 Rebalancing<a class=\"anchor\" id=\"rebalancing\"></a>\n","The distribution of the dataset is skewed toward the positive class *Liver Patients* (see chapter 1.1). This may result in ML models with poor predictive performance, specifically for the minority class, since the model may tend to classify points as belonging to the majority class.\n","\n","In this case of study, the majority class, which corresponds to *Liver Patients*, is the one we are most interested in, since is important to detect all the patients which truly have a liver disease (minimize the False Negative) as soon as possible. False postives can be instead recognised and discarded in the next screening tests.\n","\n","To deal with the problem of data imbalancing, some techniques can be applied to generate new synthetic samples such as:\n","- Random Oversampling: Randomly duplicate examples in the minority class\n","- Random Undersampling: Randomly delete examples in the majority class\n","- Synthetic Minority Over-sampling Technique (SMOTE)\n","\n","The method chosen in this context is Synthetic Minority Over-sampling Technique for Nominal and Continuous (SMOTE-NC), an extension of SMOTE for datasets containing numerical and categorical features.\n","SMOTE is one of the most popular algorithms used to generate synthetic samples and allows to create new ones from the minor class instead of creating copies. \n","\n","SMOTE works, by first selecting at random an example from the minority class. Then k (usually k=5) of the nearest neighbors for that example are found. At this point, a randomly selected neighbor is chosen and a synthetic example is created at a randomly selected point between the two examples in feature space.\n","\n","As regards the categorical features, SMOTE-NC slightly changes the way a new sample is generated by performing something specific. In detail, the category of a new generated sample is chosen by picking the most frequent category of the nearest neighbors.\n","\n"]},{"cell_type":"code","execution_count":340,"metadata":{"id":"LVikOTOCJkNE","executionInfo":{"status":"ok","timestamp":1661109470384,"user_tz":-120,"elapsed":7,"user":{"displayName":"Elisa C","userId":"11182657622104819579"}}},"outputs":[],"source":["config_dict['CLASSIFICATION'] = {}\n","\n","config_dict['CLASSIFICATION']['SCALER'] = {\n","    'StandardScaler' : ColumnTransformer(\n","            remainder='passthrough',\n","            transformers=[\n","                (\"standardscaler\", StandardScaler(), config_dict['GENERAL']['NUMERIC_FEATURES']),\n","            ],\n","            verbose_feature_names_out=False)\n","}\n","\n","config_dict['CLASSIFICATION']['BALANCER'] = { \n","    'SMOTENC' : SMOTENC(categorical_features=None, random_state=config_dict['GENERAL']['SEED'], sampling_strategy='not majority')\n","} \n","\n","feature_scaler = config_dict['CLASSIFICATION']['SCALER']['StandardScaler']\n","feature_scaler1 = clone(feature_scaler)\n","_ = feature_scaler1.fit_transform(X_train) # to retreive the categorical features indices (order of columns is modified by the scaler)\n","\n","#set categorical features indices\n","class_balancer = config_dict['CLASSIFICATION']['BALANCER']['SMOTENC'].set_params(categorical_features=[i for i, f in enumerate(feature_scaler1.get_feature_names_out()) if f in config_dict['GENERAL']['BOOLEAN_FEATURES']])"]},{"cell_type":"markdown","source":["The pair plots below show the training data after and before the rebalancing with SMOTE-NC. New samples are generated for the minority class (in blue), while the majority class (in yellow) is left unchanged.\n","The second plot shows that the **Gender** feature remains binary after the data augmentation process.\n"],"metadata":{"id":"3qxcAUTBnkHV"}},{"cell_type":"code","execution_count":341,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":297},"executionInfo":{"elapsed":2197,"status":"ok","timestamp":1661109472575,"user":{"displayName":"Elisa C","userId":"11182657622104819579"},"user_tz":-120},"id":"80Tg4ivjJaTw","outputId":"253dbd47-1aa4-49d3-f28e-9c244e5476ce"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 2 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["plot_augmented_data(X_train, y_train, ['SGPT','DB'], feature_scaler, class_balancer)"]},{"cell_type":"code","source":["plot_augmented_data(X_train, y_train, ['DB','Gender'], feature_scaler, class_balancer)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":297},"id":"u2KOjpyfoEP0","executionInfo":{"status":"ok","timestamp":1661109473709,"user_tz":-120,"elapsed":1139,"user":{"displayName":"Elisa C","userId":"11182657622104819579"}},"outputId":"aa954142-8508-48e0-cfdf-75cc8c498244"},"execution_count":342,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 2 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"kPp9EL9uRIXu"},"source":["###3.3 Dimensionality reduction methods<a class=\"anchor\" id=\"dim_reduction_methods\"></a>"]},{"cell_type":"markdown","metadata":{"id":"6KJANo_xRPBN"},"source":["####3.3.1 Principal component analysis<a class=\"anchor\" id=\"pca\"></a>\n","PCA is one of the most popular unsupervised dimensionality reduction technique that allows to reduce the dimensionality of large datasets. Is an unsupervised method since it involves only a set of features $X_1, X_2,...,X_d$ and no associated response $Y$.\n","\n","It consists in making an orthogonal projection of the data onto a lower dimensional space that:\n","- maximizes the variance of the projected data\n","- minimizes the mean squared distance between data points and projections\n","\n","#### Maximum variance perspective\n","PCA aims to find a low-dimensional representation of the data that captures as much of the information as possible. Since the variance is an indicator of the spread of the data, is possible derive PCA as a dimensionality reduction algorithm that maximizes the variance in this lower-dimensional space.\n","Each dimension (or principal component) found by PCA is a linear combination of the d features.\n","The first principal component $Z_1$ is the normalized ($\\sum_{j=1}^{d} \\phi_{j1}^2 = 1 $) linear combination of the orginal set of features $X_1, X_2,...,X_d$:\n","\n","$ Z_1 = \\phi_{11} X_1 +  \\phi_{21} X_2 + ... +  \\phi_{d1} X_d $\n","\n","that has the largest variance.\n","\n","$\\phi_{1} = (\\phi_{11}, \\phi_{21}, ..., \\phi_{d1})^T$ is the loading vector of the principal component and defines the direction in the feature space along which the data vary the most.\n","\n","Given an m x d dataset $X$, to find the first principal component loading vector we need to solve the following optimization problem:\n","\n","$\\underset{\\phi_{11}, ..., \\phi_{d1}}{maximize} \\ \\{ \\frac{1}{m} \\sum_{i=1}^m \\ ( \\sum_{j=1}^d \\phi_{j1} x_{ij} )^2 \\} \\ subject \\ to \\ \\sum_{j=1}^{d} \\phi_{j1}^2 = 1$ \n","\n","After the first principal component $Z_1$ is determined, the second principal component $Z_2$ is computed as the linear combination of $X_1, X_2,...,X_d$ that has the maximal variance out of all linear combinations that are uncorrelated with $Z_1$. Note that, constraining $Z_2$ to be uncorrelated with $Z_1$ is equivalent to constraining the direction of $\\phi_2$ to be orthogonal to the direction of $\\phi_1$.\n","Then, each subsequent PC computed is orthogonal to the previous ones and points in the direction of the largest variance of the residual subspace.\n","#### Projection perspective\n","PCA can be derived as an algorithm that directly minimizes the average reconstruction error.\n","This perspective allows to interpret PCA as a linear auto-encoder.\n","In detail, we found a compressed version $z$ of original data $x$ and then the compressed data can be reconstructed into $\\bar{x}$ which lives in the original dimensional space:\n","\n","<img src=\"images/pca_reconstructed_err.png\" alt=\"pca reconstructed err\" width=\"200\"/>\n","\n","The aim is to project (encoding) data onto a lower-dimensional space via an orthogonal linear mapping, while retaining as much information as possible, in such a way to minimize the distance between the original data and the reconstructed data (decoding). The mathematical optimization problem is the following:\n","\n","$\\underset{W \\in R^{n,d}, \\ U  \\in R^{d,n}}{argmin} \\ \\ \\frac{1}{m} \\sum_{i=1}^m \\ \\lVert x_i - UW\\bar{x_i}\\rVert_2^2$  (Reconstruction error)\n","\n","where $W \\in 𝑅^{n,d}$ and $U \\in 𝑅^{d,n}$ are the encoding and decoding matrices respectively.\n","\n","Given a set of data points $x_1, ..., x_m \\in R^d$ and let $A = X^T * X$, the solution to the problem is given by the setting:\n","\n","$U = (u_1, ..., u_n)$ and $W = U^T$\n","\n","where $u_1, ... u_n$ are the first n orthonormal eigenvectors of $A$ corresponding to the first n largest eigenvalues ($\\lambda_1\\geq, ..., \\geq\\lambda_n$). The sum of the remaining eigenvalues ($\\lambda_{n+1}\\geq, ..., \\geq\\lambda_d$) gives the reconstruction error."]},{"cell_type":"markdown","source":["Before applying PCA in our case study, since the features have different units, is recommended to scale them to have standard deviation equal to 1. Z-score normalization (see chapter 3.1) is applied separately on each feature of the training dataset."],"metadata":{"id":"KfwhcohEGlKQ"}},{"cell_type":"code","execution_count":343,"metadata":{"id":"6bTSVGtNRSPb","executionInfo":{"status":"ok","timestamp":1661109473710,"user_tz":-120,"elapsed":6,"user":{"displayName":"Elisa C","userId":"11182657622104819579"}}},"outputs":[],"source":["X_train_scaled = StandardScaler().fit_transform(X_train)\n","pca = PCA(n_components=len(features_names), random_state=config_dict['GENERAL']['SEED'])\n","X_train_pca_trasformed = pca.fit_transform(X_train_scaled)"]},{"cell_type":"markdown","source":["At this point, we are interested in knowing the proportion of variance explained (PVE) by each principal component, in order to understand their strength and decide how many to keep.\n","\n","Given a m x d dataset $X$, the PVE for the nth principal component is given by:\n","\n","$PVE =\\frac{\\sum_{i=1}^m{(\\sum_{j=1}^{d}{\\phi_{jn} \\ x_{ij}})^2}}{\\sum_{j=1}^d\\sum_{i=1}^m \\ x_{ij}^2} = \\frac{variance \\ explained \\ by \\ nth \\ PC} {tot \\ variance}$\n","\n","To compute the cumulative PVE of the first n PCs, we can simply sum over each of the first n PVEs.\n","Below is plotted the scree plot showing the cumulative PVE and the PVE for each of the 10 PCs.\n","The graph shows that the individual variance explained by each component decreases up to the last 3 PCs which explain very few variance. Looking at the cumulative explained variance, the choice is to keep the first 7 components which explain about 0.99% of the total variance."],"metadata":{"id":"TFBX2-rwHngc"}},{"cell_type":"code","execution_count":344,"metadata":{"executionInfo":{"elapsed":3299,"status":"ok","timestamp":1661109477004,"user":{"displayName":"Elisa C","userId":"11182657622104819579"},"user_tz":-120},"id":"m0dIfEEwRVqe","colab":{"base_uri":"https://localhost:8080/","height":547},"outputId":"e5965e68-1f8a-4218-d7e4-93c7ba2d03aa"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<IPython.lib.display.IFrame at 0x7f892166b490>"],"text/html":["\n","        <iframe\n","            width=\"100%\"\n","            height=\"525px\"\n","            src=\"https://plotly.com/~elisa_c/223.embed\"\n","            frameborder=\"0\"\n","            allowfullscreen\n","        ></iframe>\n","        "]},"metadata":{},"execution_count":344}],"source":["fig = prepare_PCA_explained_variance_plot(pca, template_)\n","'''\n","if config_dict['GENERAL']['SHOW_METHOD'] == 0:\n","  fig.show()\n","elif config_dict['GENERAL']['SHOW_METHOD'] == 1:\n","  py.iplot(fig, filename = 'explaied_variance')\n","elif config_dict['GENERAL']['SHOW_METHOD'] == 2:\n","  fig.show(renderer='svg')'''\n","py.iplot(fig, filename = 'explaied_variance')"]},{"cell_type":"code","execution_count":345,"metadata":{"id":"KYdHRNjOKMTr","executionInfo":{"status":"ok","timestamp":1661109477005,"user_tz":-120,"elapsed":18,"user":{"displayName":"Elisa C","userId":"11182657622104819579"}}},"outputs":[],"source":["num_components = 7"]},{"cell_type":"markdown","metadata":{"id":"oXXcL7jTRxbk"},"source":["The figure below represents in a single biplot both the loading vectors and the principal component scores, which represent the positions of each observation in this new coordinate system of principal components.\n","\n","From the graph is possible to observe that the projection of samples for the negative class (in blue) seems to be a bit clustered, while the positive samples in yellow are also spread toward the upper-right area of the graph.\n","\n","Concerning the loading vectors, they are visualized by arrows that are under an angle and have a certain length. The angle represents the contribution of a particular feature in the direction of the PCs where it contributes. The length of the arrow depicts the strength of the contribution of the feature in that direction. By zoom in the picture we can observe the blue arrows which indicate the first 2 PC loading vectors. \n","\n","Overall we can identify 3 main groups, where each group is composed by loading vectors close to each others which indicates a correlation among them:\n","\n","- Group 1: the features related to proteins (ALB, TP, AGR) \n","- Group 2: the transaminases (SGPT, SGOT)\n","- Group 3: the total and direct bilirubina (TB, DB)\n","\n","There is also a fourth group (Gender and AAP) but the strength of the loading vector related to the Gender feature is very short meaning that it scarcely influences the first two PCs (probably it will influence other PCs).\n","\n","The angles of the loading vectors show that TB and DB mostly contribute to the first PC, the same happens for Gender and AAP.\n","Instead TP, AGR and especially ALB have arrows with great strength but there is no favorite direction toward one of the 2 components. "]},{"cell_type":"code","execution_count":346,"metadata":{"executionInfo":{"elapsed":3167,"status":"ok","timestamp":1661109480155,"user":{"displayName":"Elisa C","userId":"11182657622104819579"},"user_tz":-120},"id":"KaI0PmInR14i","colab":{"base_uri":"https://localhost:8080/","height":722},"outputId":"876124cd-9958-40c4-97de-41dd6a8913d6"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<IPython.lib.display.IFrame at 0x7f891ed50f50>"],"text/html":["\n","        <iframe\n","            width=\"700px\"\n","            height=\"700px\"\n","            src=\"https://plotly.com/~elisa_c/225.embed\"\n","            frameborder=\"0\"\n","            allowfullscreen\n","        ></iframe>\n","        "]},"metadata":{},"execution_count":346}],"source":["fig = prepare_biplot(pca, X_train_pca_trasformed, y_train, features_names, template_)\n","'''\n","if config_dict['GENERAL']['SHOW_METHOD'] == 0:\n","  fig.show()\n","elif config_dict['GENERAL']['SHOW_METHOD'] == 1:\n","  py.iplot(fig, filename = 'bi_plot')\n","elif config_dict['GENERAL']['SHOW_METHOD'] == 2:\n","  fig.show(renderer='svg')'''\n","py.iplot(fig, filename = 'bi_plot')"]},{"cell_type":"code","execution_count":347,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":363},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1661109480156,"user":{"displayName":"Elisa C","userId":"11182657622104819579"},"user_tz":-120},"id":"2NSjVWlRU_OM","outputId":"bc734fb2-3fb8-4b81-ccd9-18aece0472ff"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["             PC1       PC2\n","Age     0.192074 -0.432884\n","Gender  0.168284 -0.013470\n","TB      0.776831  0.296896\n","DB      0.761022  0.298497\n","AAP     0.393975 -0.016101\n","SGPT    0.502412  0.601261\n","SGOT    0.568354  0.575830\n","TP     -0.480906  0.565105\n","ALB    -0.680054  0.659962\n","AGR    -0.506089  0.543042"],"text/html":["\n","  <div id=\"df-e39bc65c-a8b1-47df-96a4-9c4e7ad73654\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PC1</th>\n","      <th>PC2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Age</th>\n","      <td>0.192074</td>\n","      <td>-0.432884</td>\n","    </tr>\n","    <tr>\n","      <th>Gender</th>\n","      <td>0.168284</td>\n","      <td>-0.013470</td>\n","    </tr>\n","    <tr>\n","      <th>TB</th>\n","      <td>0.776831</td>\n","      <td>0.296896</td>\n","    </tr>\n","    <tr>\n","      <th>DB</th>\n","      <td>0.761022</td>\n","      <td>0.298497</td>\n","    </tr>\n","    <tr>\n","      <th>AAP</th>\n","      <td>0.393975</td>\n","      <td>-0.016101</td>\n","    </tr>\n","    <tr>\n","      <th>SGPT</th>\n","      <td>0.502412</td>\n","      <td>0.601261</td>\n","    </tr>\n","    <tr>\n","      <th>SGOT</th>\n","      <td>0.568354</td>\n","      <td>0.575830</td>\n","    </tr>\n","    <tr>\n","      <th>TP</th>\n","      <td>-0.480906</td>\n","      <td>0.565105</td>\n","    </tr>\n","    <tr>\n","      <th>ALB</th>\n","      <td>-0.680054</td>\n","      <td>0.659962</td>\n","    </tr>\n","    <tr>\n","      <th>AGR</th>\n","      <td>-0.506089</td>\n","      <td>0.543042</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e39bc65c-a8b1-47df-96a4-9c4e7ad73654')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-e39bc65c-a8b1-47df-96a4-9c4e7ad73654 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-e39bc65c-a8b1-47df-96a4-9c4e7ad73654');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":347}],"source":["loadings = pca.components_.T * np.sqrt(pca.explained_variance_)\n","loading_matrix = pd.DataFrame(loadings[:, 0:2], columns=['PC1', 'PC2'], index=features_names)\n","loading_matrix"]},{"cell_type":"markdown","source":["PCA is a technique that provides a transformation of the feature space, generating meta-features. This transformation leads to the loss of information on the nature of the features and the consequent decrease in the interpretability of the ML models built. \n","For this reason, in the next sections PCA will not be applied on RandomForest and DecisionTree since one of their main advantages is the interpretability and we do not want to loose this main characteristic."],"metadata":{"id":"qKovaR3IrZ19"}},{"cell_type":"markdown","metadata":{"id":"0Us1Y1idXtH8"},"source":["####3.3.2 Empirical feature selection<a class=\"anchor\" id=\"empirical_feature_selection\"></a>\n","\n","Alternatively, to reduce the dataset dimensionality is possible to apply an \"empirical dimensionality reduction\" technique which consists in removing duplicated features according to their pairwise correlation with others.\n","\n","The strategy consists in performing an agglomerative hierarchical clustering with average linkage to cluster the features according to their correlation.\n","The process starts by creating one cluster for each feature and by computing the pairwise distance (=correlation) between all the clusters. Then, the two clusters with the highest average correlation are selected and merged. In the next iteration, the next pair of clusters with highest correlation is selected and merged. This step is repeated until we end up with one cluster. The dendogram helps to visualize the clusters."]},{"cell_type":"code","execution_count":348,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":622},"executionInfo":{"elapsed":3104,"status":"ok","timestamp":1661109483249,"user":{"displayName":"Elisa C","userId":"11182657622104819579"},"user_tz":-120},"id":"V5R7CakwI8eL","outputId":"f8e47f96-e20a-4266-d146-68c6f28553d8"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<IPython.lib.display.IFrame at 0x7f89215dc550>"],"text/html":["\n","        <iframe\n","            width=\"800px\"\n","            height=\"600px\"\n","            src=\"https://plotly.com/~elisa_c/227.embed\"\n","            frameborder=\"0\"\n","            allowfullscreen\n","        ></iframe>\n","        "]},"metadata":{},"execution_count":348}],"source":["fig = prepare_dendogram(X_train, title_ = \"Dendrogram of clustering the features according to correlation\", template_=template_)\n","'''\n","if config_dict['GENERAL']['SHOW_METHOD'] == 0:\n","  fig.show()\n","elif config_dict['GENERAL']['SHOW_METHOD'] == 1:\n","  py.iplot(fig, filename = 'dendogram')\n","elif config_dict['GENERAL']['SHOW_METHOD'] == 2:\n","  fig.show(renderer='svg')'''\n","py.iplot(fig, filename = 'dendogram')"]},{"cell_type":"markdown","source":["The dendogram shows 3 main clusters highlighted in brown, green and orange.\n","The feature pairs which are clustered with lower distance are TB and DB (brown cluster). Also SGPT and SGOT are quite close. The orange cluster which contains AGR, TP, ALB shows a correlation but not so strong.\n","The choice is to remove TB and SGOT features since they are considerated as duplicates."],"metadata":{"id":"1UqAyFEI4Wnx"}},{"cell_type":"code","execution_count":349,"metadata":{"id":"IYnch-otPsU9","executionInfo":{"status":"ok","timestamp":1661109483250,"user_tz":-120,"elapsed":15,"user":{"displayName":"Elisa C","userId":"11182657622104819579"}}},"outputs":[],"source":["duplicated_features = [\"SGOT\", \"TB\"]\n","cols_without_duplicate = [x for x in features_names if x not in duplicated_features]\n","num_cols_without_duplicate = [x for x in cols_without_duplicate if x not in config_dict['GENERAL']['BOOLEAN_FEATURES']]\n","X_train_reduced = X_train[cols_without_duplicate]\n","X_test_reduced= X_test[cols_without_duplicate]"]},{"cell_type":"markdown","metadata":{"id":"s7rnYGiXXwI-"},"source":["##4. Classification<a class=\"anchor\" id=\"classification\"></a>"]},{"cell_type":"markdown","metadata":{"id":"Purr7SrWXxV1"},"source":["###4.1 Metrics<a class=\"anchor\" id=\"metrics\"></a>\n","Accuracy is one of the most common metric to evaluate classification models, however it is not good when dealing with unbalanced datasets since can lead to misleading high results, even if the model performs poorly on the minority class, by simply assigning all the samples to the majority class.\n","\n","In this case F1-score is used, since it takes into account not only the number of prediction errors but also the type of errors that are made. Is defined as the harmomic mean of precision and recall, where a score reaches its best value at 1 and worst score at 0.\n","The formula is given by:\n","\n","$F1 = 2 * \\frac{precision \\ * \\ recall}{precision \\ + \\ recall}$ where,\n","\n","$precision = \\frac{TP}{TP+FP}$ and $recall = \\frac{TP}{TP+FN}$ \n","\n","F1 score gives equal weight to Precision and Recall and is used in the context of this project as main performance evaluation metric and during the grid search for tuning the model hyperparameters."]},{"cell_type":"markdown","metadata":{"id":"Gmza9mI6X4Nj"},"source":["###4.2 Cross validation<a class=\"anchor\" id=\"cv\"></a>\n","K-fold cross validation is a technique used to estimate model performance, making predictions on data unseen during training.\n","It results in a less biased or less optimistic estimate of the model skill than other methods, such as a simple train/test split.\n","However when using a single K-fold cross validation procedure for both tune and select the model, this can still lead to a optimistically biased evaluation of the performance.\n","\n","The approach used to limit this problem, is to nest the hyperparameter optimization procedure under the model selection, using the so called Nested Cross Validation technique. Two main resampling loops are generated:\n","- outer resampling loop (evaluate model performance): consists in a Stratified 10-fold Cross-Validation procedure which involves fitting the best model found in the inner loop using all folds but one (\" cv training set\") and evaluating it on the holdout fold (\" cv test set\") by computing the F1 score. \n","- inner resampling loop (best hyperparameters search): consists in taking the \" cv training dataset\" provided by the outer loop and perform a hyperparameter optimized procedure (grid search) using a Stratified 5-fold Cross-Validation that finds an optimal set of hyperparameters for the model. \n","\n","The final F1 score is computed by averaging the scores of each outer resampling iteration.\n","\n","This procedure is applied on several classifiers and the one which gives the best result is selected as final model.\n","The final model is configured and fit by applying a grid search (Stratified 5-fold cv) fo hyperparameters optimization, considering the entire training dataset as input. Then, the hyperparameters found during this final search are used to configure a final model. The final model is fit on the entire training dataset and evaluated on the test dataset (see section 1.5 for data splits).\n","\n","The cross validation procedure is handled through a pipeline which is made up of the following steps:\n","\n","- Feature scaling: fit is performed exclusively on the training dataset (to prevent any information leakages) and then the transformation is applied also on the test dataset (see section 3.1).\n","- Rebalaning: is done only on training data and not on the test dataset because we do not want to alter its original class distribution (see section 3.2).\n","- PCA: fit is performed exclusively on the training dataset (to prevent any information leakages) and then the transformation is applied also on the test dataset (see section 3.3.1).\n"]},{"cell_type":"code","execution_count":350,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1661109483251,"user":{"displayName":"Elisa C","userId":"11182657622104819579"},"user_tz":-120},"id":"49SHOF0lX8WX","outputId":"55b17618-595b-450b-add5-fd63eb21d621"},"outputs":[{"output_type":"stream","name":"stdout","text":["{'CLASSIFICATION': {'BALANCER': {'SMOTENC': SMOTENC(categorical_features=[9], random_state=42,\n","        sampling_strategy='not majority')},\n","                    'GENERAL': {'cv_inner': 5,\n","                                'cv_outer': 10,\n","                                'score_metric': 'f1',\n","                                'seed': 42},\n","                    'MODELS': {'DecisionTree': DecisionTreeClassifier(),\n","                               'KNN': KNeighborsClassifier(),\n","                               'LinearSVC': SVC(kernel='linear'),\n","                               'LogisticRegression': LogisticRegression(),\n","                               'RandomForest': RandomForestClassifier(),\n","                               'RbfSVC': SVC()},\n","                    'PARAMS': {'DecisionTree': {'DecisionTree__criterion': ['gini',\n","                                                                            'entropy'],\n","                                                'DecisionTree__max_depth': [2,\n","                                                                            3,\n","                                                                            4,\n","                                                                            5,\n","                                                                            6,\n","                                                                            7,\n","                                                                            8,\n","                                                                            9],\n","                                                'DecisionTree__min_samples_split': [2,\n","                                                                                    3,\n","                                                                                    4,\n","                                                                                    5,\n","                                                                                    6,\n","                                                                                    7,\n","                                                                                    8,\n","                                                                                    9]},\n","                               'KNN': {'KNN__n_neighbors': [1,\n","                                                            3,\n","                                                            5,\n","                                                            7,\n","                                                            9,\n","                                                            11,\n","                                                            13,\n","                                                            15,\n","                                                            17,\n","                                                            19,\n","                                                            21,\n","                                                            23],\n","                                       'KNN__weights': ['uniform',\n","                                                        'distance']},\n","                               'LinearSVC': {'LinearSVC__C': [0.001,\n","                                                              0.01,\n","                                                              0.1,\n","                                                              1,\n","                                                              10,\n","                                                              100,\n","                                                              1000]},\n","                               'LogisticRegression': {'LogisticRegression__C': [0.001,\n","                                                                                0.01,\n","                                                                                0.1,\n","                                                                                1,\n","                                                                                10,\n","                                                                                100,\n","                                                                                1000],\n","                                                      'LogisticRegression__max_iter': [1000],\n","                                                      'LogisticRegression__penalty': ['l1',\n","                                                                                      'l2'],\n","                                                      'LogisticRegression__solver': ['liblinear']},\n","                               'RandomForest': {'RandomForest__criterion': ['gini',\n","                                                                            'entropy'],\n","                                                'RandomForest__max_depth': [2,\n","                                                                            3,\n","                                                                            4,\n","                                                                            5,\n","                                                                            6,\n","                                                                            7,\n","                                                                            8,\n","                                                                            9],\n","                                                'RandomForest__max_features': ['sqrt'],\n","                                                'RandomForest__min_samples_split': [2,\n","                                                                                    5,\n","                                                                                    10],\n","                                                'RandomForest__n_estimators': [10,\n","                                                                               100]},\n","                               'RbfSVC': {'RbfSVC__C': [10,\n","                                                        100,\n","                                                        1000],\n","                                          'RbfSVC__gamma': [0.001,\n","                                                            0.01,\n","                                                            0.1,\n","                                                            1]}},\n","                    'SCALER': {'StandardScaler': ColumnTransformer(remainder='passthrough',\n","                  transformers=[('standardscaler', StandardScaler(),\n","                                 ['Age', 'TB', 'DB', 'AAP', 'SGPT', 'SGOT',\n","                                  'TP', 'ALB', 'AGR'])],\n","                  verbose_feature_names_out=False)}},\n"," 'GENERAL': {'BOOLEAN_FEATURES': ['Gender'],\n","             'NUMERIC_FEATURES': ['Age',\n","                                  'TB',\n","                                  'DB',\n","                                  'AAP',\n","                                  'SGPT',\n","                                  'SGOT',\n","                                  'TP',\n","                                  'ALB',\n","                                  'AGR'],\n","             'PERFORM_NCV': True,\n","             'SEED': 42,\n","             'SHOW_METHOD': 1,\n","             'TARGET_COLUMN_NAME': 'CLASS'}}\n"]}],"source":["config_dict['CLASSIFICATION']['MODELS'] = {\n","        'LinearSVC': svm.SVC(kernel='linear'),\n","        'RbfSVC': svm.SVC(kernel='rbf'),\n","        'KNN': neighbors.KNeighborsClassifier(),\n","        'LogisticRegression': linear_model.LogisticRegression(),\n","        'DecisionTree': tree.DecisionTreeClassifier(),\n","        'RandomForest': ensemble.RandomForestClassifier(),\n","}\n","\n","config_dict['CLASSIFICATION']['GENERAL'] = {\n","    'score_metric': 'f1',\n","    'cv_inner': 5,\n","    'cv_outer': 10,\n","    'seed': config_dict['GENERAL']['SEED']\n","}\n","\n","config_dict['CLASSIFICATION']['PARAMS'] = {\n","    'KNN': {\n","            'KNN__n_neighbors' : list(range(1,25, 2)), \n","            'KNN__weights': ['uniform', 'distance' ],\n","            #'KNN__n_jobs' : [-1],\n","            },\n","    'LinearSVC': {\n","            'LinearSVC__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000], \n","            #'LinearSVC__kernel': ['linear'],  \n","            },\n","    'RbfSVC': {\n","            'RbfSVC__C': [10, 100, 1000],  \n","            'RbfSVC__gamma': [0.001, 0.01, 0.1, 1],    \n","            #'RbfSVC__kernel': ['rbf'],\n","            },\n","    'LogisticRegression': {\n","            'LogisticRegression__penalty': ['l1', 'l2'],\n","            'LogisticRegression__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],   \n","            'LogisticRegression__max_iter': [1000],\n","            'LogisticRegression__solver': ['liblinear'],\n","            },\n","    'DecisionTree': {\n","            'DecisionTree__max_depth': list(range(2, 10)),\n","            'DecisionTree__min_samples_split': list(range(2, 10)),\n","            'DecisionTree__criterion' : ['gini', 'entropy'],\n","            },\n","    'RandomForest': {\n","            'RandomForest__n_estimators': [10, 100],\n","            'RandomForest__criterion' : ['gini', 'entropy'],\n","            'RandomForest__max_depth': list(range(2, 10)),\n","            'RandomForest__min_samples_split': [2, 5, 10], \n","            'RandomForest__max_features': ['sqrt'],\n","            #'RandomForest__n_jobs' : [-1],\n","            },\n","}\n","\n","show_dict(config_dict)"]},{"cell_type":"code","execution_count":351,"metadata":{"id":"-8FlmJut4-iy","executionInfo":{"status":"ok","timestamp":1661109483252,"user_tz":-120,"elapsed":11,"user":{"displayName":"Elisa C","userId":"11182657622104819579"}}},"outputs":[],"source":["classifiers = []"]},{"cell_type":"markdown","metadata":{"id":"Zlq7TWDA5QHg"},"source":["###Support vector machines"]},{"cell_type":"code","execution_count":352,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":208},"executionInfo":{"elapsed":531,"status":"ok","timestamp":1661109483772,"user":{"displayName":"Elisa C","userId":"11182657622104819579"},"user_tz":-120},"id":"YJCAgrPwvx2Q","outputId":"a68d13d8-4f70-4b40-a25a-8136b3398c72"},"outputs":[{"output_type":"display_data","data":{"text/plain":["                  0     1    2    3     4      5       6\n","LinearSVC__C  0.001  0.01  0.1  1.0  10.0  100.0  1000.0"],"text/html":["\n","  <div id=\"df-04eab0a8-6a38-4a14-be1c-0d2dad383a39\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>LinearSVC__C</th>\n","      <td>0.001</td>\n","      <td>0.01</td>\n","      <td>0.1</td>\n","      <td>1.0</td>\n","      <td>10.0</td>\n","      <td>100.0</td>\n","      <td>1000.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-04eab0a8-6a38-4a14-be1c-0d2dad383a39')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-04eab0a8-6a38-4a14-be1c-0d2dad383a39 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-04eab0a8-6a38-4a14-be1c-0d2dad383a39');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["            0    1     2\n","RbfSVC__C  10  100  1000"],"text/html":["\n","  <div id=\"df-63f959e4-7d6d-4b98-b1e3-3db5a967ac39\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>RbfSVC__C</th>\n","      <td>10</td>\n","      <td>100</td>\n","      <td>1000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-63f959e4-7d6d-4b98-b1e3-3db5a967ac39')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-63f959e4-7d6d-4b98-b1e3-3db5a967ac39 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-63f959e4-7d6d-4b98-b1e3-3db5a967ac39');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["                   0     1    2    3\n","RbfSVC__gamma  0.001  0.01  0.1  1.0"],"text/html":["\n","  <div id=\"df-2bdb75fb-5f4b-4ebf-aa23-2e0d3a4eb09f\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>RbfSVC__gamma</th>\n","      <td>0.001</td>\n","      <td>0.01</td>\n","      <td>0.1</td>\n","      <td>1.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2bdb75fb-5f4b-4ebf-aa23-2e0d3a4eb09f')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-2bdb75fb-5f4b-4ebf-aa23-2e0d3a4eb09f button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-2bdb75fb-5f4b-4ebf-aa23-2e0d3a4eb09f');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}],"source":["display(pd.DataFrame(config_dict['CLASSIFICATION']['PARAMS']['LinearSVC'], columns = ['LinearSVC__C']).T)\n","display(pd.DataFrame(config_dict['CLASSIFICATION']['PARAMS']['RbfSVC'], columns = ['RbfSVC__C']).T)\n","display(pd.DataFrame(config_dict['CLASSIFICATION']['PARAMS']['RbfSVC'], columns = ['RbfSVC__gamma']).T)"]},{"cell_type":"code","execution_count":353,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":101570,"status":"ok","timestamp":1661109585334,"user":{"displayName":"Elisa C","userId":"11182657622104819579"},"user_tz":-120},"id":"6KBc7YQ35QnD","outputId":"1fb0984e-a6e6-40a5-9871-ba97c77a9e0a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Computing inner cross validation for grid search of best hyperparameters...\n","Fitting 5 folds for each of 7 candidates, totalling 35 fits\n","[CV 1/5] END ................LinearSVC__C=0.001;, score=0.261 total time=   0.1s\n","[CV 2/5] END ................LinearSVC__C=0.001;, score=0.356 total time=   0.1s\n","[CV 3/5] END ................LinearSVC__C=0.001;, score=0.182 total time=   0.1s\n","[CV 4/5] END ................LinearSVC__C=0.001;, score=0.232 total time=   0.1s\n","[CV 5/5] END ................LinearSVC__C=0.001;, score=0.185 total time=   0.1s\n","[CV 1/5] END .................LinearSVC__C=0.01;, score=0.637 total time=   0.1s\n","[CV 2/5] END .................LinearSVC__C=0.01;, score=0.575 total time=   0.1s\n","[CV 3/5] END .................LinearSVC__C=0.01;, score=0.421 total time=   0.1s\n","[CV 4/5] END .................LinearSVC__C=0.01;, score=0.488 total time=   0.1s\n","[CV 5/5] END .................LinearSVC__C=0.01;, score=0.506 total time=   0.1s\n","[CV 1/5] END ..................LinearSVC__C=0.1;, score=0.646 total time=   0.1s\n","[CV 2/5] END ..................LinearSVC__C=0.1;, score=0.584 total time=   0.1s\n","[CV 3/5] END ..................LinearSVC__C=0.1;, score=0.541 total time=   0.1s\n","[CV 4/5] END ..................LinearSVC__C=0.1;, score=0.584 total time=   0.1s\n","[CV 5/5] END ..................LinearSVC__C=0.1;, score=0.588 total time=   0.1s\n","[CV 1/5] END ....................LinearSVC__C=1;, score=0.687 total time=   0.1s\n","[CV 2/5] END ....................LinearSVC__C=1;, score=0.615 total time=   0.1s\n","[CV 3/5] END ....................LinearSVC__C=1;, score=0.622 total time=   0.1s\n","[CV 4/5] END ....................LinearSVC__C=1;, score=0.617 total time=   0.1s\n","[CV 5/5] END ....................LinearSVC__C=1;, score=0.621 total time=   0.1s\n","[CV 1/5] END ...................LinearSVC__C=10;, score=0.687 total time=   0.1s\n","[CV 2/5] END ...................LinearSVC__C=10;, score=0.615 total time=   0.1s\n","[CV 3/5] END ...................LinearSVC__C=10;, score=0.600 total time=   0.1s\n","[CV 4/5] END ...................LinearSVC__C=10;, score=0.632 total time=   0.1s\n","[CV 5/5] END ...................LinearSVC__C=10;, score=0.605 total time=   0.1s\n","[CV 1/5] END ..................LinearSVC__C=100;, score=0.687 total time=   0.3s\n","[CV 2/5] END ..................LinearSVC__C=100;, score=0.630 total time=   0.3s\n","[CV 3/5] END ..................LinearSVC__C=100;, score=0.600 total time=   0.4s\n","[CV 4/5] END ..................LinearSVC__C=100;, score=0.632 total time=   0.5s\n","[CV 5/5] END ..................LinearSVC__C=100;, score=0.605 total time=   0.3s\n","[CV 1/5] END .................LinearSVC__C=1000;, score=0.687 total time=   2.5s\n","[CV 2/5] END .................LinearSVC__C=1000;, score=0.630 total time=   2.5s\n","[CV 3/5] END .................LinearSVC__C=1000;, score=0.600 total time=   2.5s\n","[CV 4/5] END .................LinearSVC__C=1000;, score=0.632 total time=   1.7s\n","[CV 5/5] END .................LinearSVC__C=1000;, score=0.605 total time=   1.0s\n","\n","--------------------------------------------\n","\n","Inner CV (Hyperparameters and model selection): \n","  F1-score = 0.6324372912487366\n","  Best hyperparams = {'LinearSVC__C': 1}\n","Outer CV (Quality of model selection assessment): \n","  F1-score = 0.5306122448979592\n","\n","--------------------------------------------\n","\n","Computing inner cross validation for grid search of best hyperparameters...\n","Fitting 5 folds for each of 7 candidates, totalling 35 fits\n","[CV 1/5] END ................LinearSVC__C=0.001;, score=0.235 total time=   0.1s\n","[CV 2/5] END ................LinearSVC__C=0.001;, score=0.421 total time=   0.0s\n","[CV 3/5] END ................LinearSVC__C=0.001;, score=0.209 total time=   0.0s\n","[CV 4/5] END ................LinearSVC__C=0.001;, score=0.282 total time=   0.0s\n","[CV 5/5] END ................LinearSVC__C=0.001;, score=0.356 total time=   0.0s\n","[CV 1/5] END .................LinearSVC__C=0.01;, score=0.500 total time=   0.0s\n","[CV 2/5] END .................LinearSVC__C=0.01;, score=0.614 total time=   0.0s\n","[CV 3/5] END .................LinearSVC__C=0.01;, score=0.378 total time=   0.0s\n","[CV 4/5] END .................LinearSVC__C=0.01;, score=0.494 total time=   0.0s\n","[CV 5/5] END .................LinearSVC__C=0.01;, score=0.598 total time=   0.0s\n","[CV 1/5] END ..................LinearSVC__C=0.1;, score=0.614 total time=   0.0s\n","[CV 2/5] END ..................LinearSVC__C=0.1;, score=0.622 total time=   0.0s\n","[CV 3/5] END ..................LinearSVC__C=0.1;, score=0.524 total time=   0.0s\n","[CV 4/5] END ..................LinearSVC__C=0.1;, score=0.584 total time=   0.0s\n","[CV 5/5] END ..................LinearSVC__C=0.1;, score=0.673 total time=   0.0s\n","[CV 1/5] END ....................LinearSVC__C=1;, score=0.607 total time=   0.0s\n","[CV 2/5] END ....................LinearSVC__C=1;, score=0.637 total time=   0.0s\n","[CV 3/5] END ....................LinearSVC__C=1;, score=0.512 total time=   0.0s\n","[CV 4/5] END ....................LinearSVC__C=1;, score=0.653 total time=   0.0s\n","[CV 5/5] END ....................LinearSVC__C=1;, score=0.693 total time=   0.0s\n","[CV 1/5] END ...................LinearSVC__C=10;, score=0.607 total time=   0.1s\n","[CV 2/5] END ...................LinearSVC__C=10;, score=0.637 total time=   0.1s\n","[CV 3/5] END ...................LinearSVC__C=10;, score=0.512 total time=   0.1s\n","[CV 4/5] END ...................LinearSVC__C=10;, score=0.653 total time=   0.1s\n","[CV 5/5] END ...................LinearSVC__C=10;, score=0.693 total time=   0.0s\n","[CV 1/5] END ..................LinearSVC__C=100;, score=0.607 total time=   0.2s\n","[CV 2/5] END ..................LinearSVC__C=100;, score=0.637 total time=   0.2s\n","[CV 3/5] END ..................LinearSVC__C=100;, score=0.545 total time=   0.2s\n","[CV 4/5] END ..................LinearSVC__C=100;, score=0.653 total time=   0.2s\n","[CV 5/5] END ..................LinearSVC__C=100;, score=0.693 total time=   0.2s\n","[CV 1/5] END .................LinearSVC__C=1000;, score=0.607 total time=   1.2s\n","[CV 2/5] END .................LinearSVC__C=1000;, score=0.637 total time=   1.8s\n","[CV 3/5] END .................LinearSVC__C=1000;, score=0.545 total time=   1.1s\n","[CV 4/5] END .................LinearSVC__C=1000;, score=0.653 total time=   1.1s\n","[CV 5/5] END .................LinearSVC__C=1000;, score=0.693 total time=   0.8s\n","\n","--------------------------------------------\n","\n","Inner CV (Hyperparameters and model selection): \n","  F1-score = 0.6270519283457905\n","  Best hyperparams = {'LinearSVC__C': 100}\n","Outer CV (Quality of model selection assessment): \n","  F1-score = 0.679245283018868\n","\n","--------------------------------------------\n","\n","Computing inner cross validation for grid search of best hyperparameters...\n","Fitting 5 folds for each of 7 candidates, totalling 35 fits\n","[CV 1/5] END ................LinearSVC__C=0.001;, score=0.306 total time=   0.0s\n","[CV 2/5] END ................LinearSVC__C=0.001;, score=0.154 total time=   0.0s\n","[CV 3/5] END ................LinearSVC__C=0.001;, score=0.356 total time=   0.0s\n","[CV 4/5] END ................LinearSVC__C=0.001;, score=0.436 total time=   0.0s\n","[CV 5/5] END ................LinearSVC__C=0.001;, score=0.156 total time=   0.0s\n","[CV 1/5] END .................LinearSVC__C=0.01;, score=0.593 total time=   0.0s\n","[CV 2/5] END .................LinearSVC__C=0.01;, score=0.524 total time=   0.0s\n","[CV 3/5] END .................LinearSVC__C=0.01;, score=0.524 total time=   0.0s\n","[CV 4/5] END .................LinearSVC__C=0.01;, score=0.681 total time=   0.0s\n","[CV 5/5] END .................LinearSVC__C=0.01;, score=0.468 total time=   0.0s\n","[CV 1/5] END ..................LinearSVC__C=0.1;, score=0.660 total time=   0.0s\n","[CV 2/5] END ..................LinearSVC__C=0.1;, score=0.596 total time=   0.0s\n","[CV 3/5] END ..................LinearSVC__C=0.1;, score=0.630 total time=   0.0s\n","[CV 4/5] END ..................LinearSVC__C=0.1;, score=0.701 total time=   0.0s\n","[CV 5/5] END ..................LinearSVC__C=0.1;, score=0.575 total time=   0.0s\n","[CV 1/5] END ....................LinearSVC__C=1;, score=0.673 total time=   0.0s\n","[CV 2/5] END ....................LinearSVC__C=1;, score=0.606 total time=   0.0s\n","[CV 3/5] END ....................LinearSVC__C=1;, score=0.615 total time=   0.1s\n","[CV 4/5] END ....................LinearSVC__C=1;, score=0.687 total time=   0.0s\n","[CV 5/5] END ....................LinearSVC__C=1;, score=0.622 total time=   0.0s\n","[CV 1/5] END ...................LinearSVC__C=10;, score=0.660 total time=   0.1s\n","[CV 2/5] END ...................LinearSVC__C=10;, score=0.620 total time=   0.0s\n","[CV 3/5] END ...................LinearSVC__C=10;, score=0.615 total time=   0.1s\n","[CV 4/5] END ...................LinearSVC__C=10;, score=0.693 total time=   0.1s\n","[CV 5/5] END ...................LinearSVC__C=10;, score=0.652 total time=   0.1s\n","[CV 1/5] END ..................LinearSVC__C=100;, score=0.660 total time=   0.2s\n","[CV 2/5] END ..................LinearSVC__C=100;, score=0.634 total time=   0.1s\n","[CV 3/5] END ..................LinearSVC__C=100;, score=0.615 total time=   0.1s\n","[CV 4/5] END ..................LinearSVC__C=100;, score=0.693 total time=   0.2s\n","[CV 5/5] END ..................LinearSVC__C=100;, score=0.637 total time=   0.1s\n","[CV 1/5] END .................LinearSVC__C=1000;, score=0.660 total time=   1.1s\n","[CV 2/5] END .................LinearSVC__C=1000;, score=0.634 total time=   0.7s\n","[CV 3/5] END .................LinearSVC__C=1000;, score=0.615 total time=   1.0s\n","[CV 4/5] END .................LinearSVC__C=1000;, score=0.693 total time=   0.9s\n","[CV 5/5] END .................LinearSVC__C=1000;, score=0.637 total time=   0.8s\n","\n","--------------------------------------------\n","\n","Inner CV (Hyperparameters and model selection): \n","  F1-score = 0.6480843299583553\n","  Best hyperparams = {'LinearSVC__C': 10}\n","Outer CV (Quality of model selection assessment): \n","  F1-score = 0.75\n","\n","--------------------------------------------\n","\n","Computing inner cross validation for grid search of best hyperparameters...\n","Fitting 5 folds for each of 7 candidates, totalling 35 fits\n","[CV 1/5] END ................LinearSVC__C=0.001;, score=0.351 total time=   0.0s\n","[CV 2/5] END ................LinearSVC__C=0.001;, score=0.306 total time=   0.0s\n","[CV 3/5] END ................LinearSVC__C=0.001;, score=0.400 total time=   0.0s\n","[CV 4/5] END ................LinearSVC__C=0.001;, score=0.378 total time=   0.0s\n","[CV 5/5] END ................LinearSVC__C=0.001;, score=0.286 total time=   0.0s\n","[CV 1/5] END .................LinearSVC__C=0.01;, score=0.556 total time=   0.0s\n","[CV 2/5] END .................LinearSVC__C=0.01;, score=0.476 total time=   0.0s\n","[CV 3/5] END .................LinearSVC__C=0.01;, score=0.581 total time=   0.0s\n","[CV 4/5] END .................LinearSVC__C=0.01;, score=0.565 total time=   0.0s\n","[CV 5/5] END .................LinearSVC__C=0.01;, score=0.519 total time=   0.0s\n","[CV 1/5] END ..................LinearSVC__C=0.1;, score=0.617 total time=   0.0s\n","[CV 2/5] END ..................LinearSVC__C=0.1;, score=0.615 total time=   0.0s\n","[CV 3/5] END ..................LinearSVC__C=0.1;, score=0.591 total time=   0.0s\n","[CV 4/5] END ..................LinearSVC__C=0.1;, score=0.624 total time=   0.0s\n","[CV 5/5] END ..................LinearSVC__C=0.1;, score=0.565 total time=   0.0s\n","[CV 1/5] END ....................LinearSVC__C=1;, score=0.645 total time=   0.0s\n","[CV 2/5] END ....................LinearSVC__C=1;, score=0.630 total time=   0.0s\n","[CV 3/5] END ....................LinearSVC__C=1;, score=0.591 total time=   0.0s\n","[CV 4/5] END ....................LinearSVC__C=1;, score=0.660 total time=   0.0s\n","[CV 5/5] END ....................LinearSVC__C=1;, score=0.598 total time=   0.0s\n","[CV 1/5] END ...................LinearSVC__C=10;, score=0.645 total time=   0.0s\n","[CV 2/5] END ...................LinearSVC__C=10;, score=0.630 total time=   0.1s\n","[CV 3/5] END ...................LinearSVC__C=10;, score=0.607 total time=   0.1s\n","[CV 4/5] END ...................LinearSVC__C=10;, score=0.667 total time=   0.1s\n","[CV 5/5] END ...................LinearSVC__C=10;, score=0.598 total time=   0.1s\n","[CV 1/5] END ..................LinearSVC__C=100;, score=0.638 total time=   0.2s\n","[CV 2/5] END ..................LinearSVC__C=100;, score=0.630 total time=   0.2s\n","[CV 3/5] END ..................LinearSVC__C=100;, score=0.607 total time=   0.2s\n","[CV 4/5] END ..................LinearSVC__C=100;, score=0.667 total time=   0.2s\n","[CV 5/5] END ..................LinearSVC__C=100;, score=0.598 total time=   0.2s\n","[CV 1/5] END .................LinearSVC__C=1000;, score=0.638 total time=   1.4s\n","[CV 2/5] END .................LinearSVC__C=1000;, score=0.630 total time=   1.2s\n","[CV 3/5] END .................LinearSVC__C=1000;, score=0.607 total time=   1.3s\n","[CV 4/5] END .................LinearSVC__C=1000;, score=0.667 total time=   1.2s\n","[CV 5/5] END .................LinearSVC__C=1000;, score=0.598 total time=   1.5s\n","\n","--------------------------------------------\n","\n","Inner CV (Hyperparameters and model selection): \n","  F1-score = 0.6293410924113877\n","  Best hyperparams = {'LinearSVC__C': 10}\n","Outer CV (Quality of model selection assessment): \n","  F1-score = 0.64\n","\n","--------------------------------------------\n","\n","Computing inner cross validation for grid search of best hyperparameters...\n","Fitting 5 folds for each of 7 candidates, totalling 35 fits\n","[CV 1/5] END ................LinearSVC__C=0.001;, score=0.329 total time=   0.0s\n","[CV 2/5] END ................LinearSVC__C=0.001;, score=0.152 total time=   0.0s\n","[CV 3/5] END ................LinearSVC__C=0.001;, score=0.286 total time=   0.0s\n","[CV 4/5] END ................LinearSVC__C=0.001;, score=0.286 total time=   0.0s\n","[CV 5/5] END ................LinearSVC__C=0.001;, score=0.286 total time=   0.0s\n","[CV 1/5] END .................LinearSVC__C=0.01;, score=0.512 total time=   0.0s\n","[CV 2/5] END .................LinearSVC__C=0.01;, score=0.436 total time=   0.0s\n","[CV 3/5] END .................LinearSVC__C=0.01;, score=0.500 total time=   0.0s\n","[CV 4/5] END .................LinearSVC__C=0.01;, score=0.530 total time=   0.0s\n","[CV 5/5] END .................LinearSVC__C=0.01;, score=0.568 total time=   0.0s\n","[CV 1/5] END ..................LinearSVC__C=0.1;, score=0.591 total time=   0.0s\n","[CV 2/5] END ..................LinearSVC__C=0.1;, score=0.469 total time=   0.0s\n","[CV 3/5] END ..................LinearSVC__C=0.1;, score=0.598 total time=   0.0s\n","[CV 4/5] END ..................LinearSVC__C=0.1;, score=0.615 total time=   0.0s\n","[CV 5/5] END ..................LinearSVC__C=0.1;, score=0.607 total time=   0.0s\n","[CV 1/5] END ....................LinearSVC__C=1;, score=0.615 total time=   0.0s\n","[CV 2/5] END ....................LinearSVC__C=1;, score=0.530 total time=   0.0s\n","[CV 3/5] END ....................LinearSVC__C=1;, score=0.622 total time=   0.0s\n","[CV 4/5] END ....................LinearSVC__C=1;, score=0.687 total time=   0.0s\n","[CV 5/5] END ....................LinearSVC__C=1;, score=0.581 total time=   0.0s\n","[CV 1/5] END ...................LinearSVC__C=10;, score=0.602 total time=   0.1s\n","[CV 2/5] END ...................LinearSVC__C=10;, score=0.530 total time=   0.1s\n","[CV 3/5] END ...................LinearSVC__C=10;, score=0.615 total time=   0.1s\n","[CV 4/5] END ...................LinearSVC__C=10;, score=0.700 total time=   0.1s\n","[CV 5/5] END ...................LinearSVC__C=10;, score=0.581 total time=   0.0s\n","[CV 1/5] END ..................LinearSVC__C=100;, score=0.602 total time=   0.2s\n","[CV 2/5] END ..................LinearSVC__C=100;, score=0.530 total time=   0.2s\n","[CV 3/5] END ..................LinearSVC__C=100;, score=0.615 total time=   0.2s\n","[CV 4/5] END ..................LinearSVC__C=100;, score=0.700 total time=   0.2s\n","[CV 5/5] END ..................LinearSVC__C=100;, score=0.581 total time=   0.1s\n","[CV 1/5] END .................LinearSVC__C=1000;, score=0.602 total time=   1.0s\n","[CV 2/5] END .................LinearSVC__C=1000;, score=0.530 total time=   1.2s\n","[CV 3/5] END .................LinearSVC__C=1000;, score=0.615 total time=   1.5s\n","[CV 4/5] END .................LinearSVC__C=1000;, score=0.700 total time=   0.9s\n","[CV 5/5] END .................LinearSVC__C=1000;, score=0.581 total time=   1.3s\n","\n","--------------------------------------------\n","\n","Inner CV (Hyperparameters and model selection): \n","  F1-score = 0.6073245336743516\n","  Best hyperparams = {'LinearSVC__C': 1}\n","Outer CV (Quality of model selection assessment): \n","  F1-score = 0.5714285714285714\n","\n","--------------------------------------------\n","\n","Computing inner cross validation for grid search of best hyperparameters...\n","Fitting 5 folds for each of 7 candidates, totalling 35 fits\n","[CV 1/5] END ................LinearSVC__C=0.001;, score=0.306 total time=   0.0s\n","[CV 2/5] END ................LinearSVC__C=0.001;, score=0.154 total time=   0.0s\n","[CV 3/5] END ................LinearSVC__C=0.001;, score=0.310 total time=   0.0s\n","[CV 4/5] END ................LinearSVC__C=0.001;, score=0.282 total time=   0.0s\n","[CV 5/5] END ................LinearSVC__C=0.001;, score=0.333 total time=   0.0s\n","[CV 1/5] END .................LinearSVC__C=0.01;, score=0.558 total time=   0.0s\n","[CV 2/5] END .................LinearSVC__C=0.01;, score=0.378 total time=   0.0s\n","[CV 3/5] END .................LinearSVC__C=0.01;, score=0.530 total time=   0.0s\n","[CV 4/5] END .................LinearSVC__C=0.01;, score=0.659 total time=   0.0s\n","[CV 5/5] END .................LinearSVC__C=0.01;, score=0.600 total time=   0.0s\n","[CV 1/5] END ..................LinearSVC__C=0.1;, score=0.609 total time=   0.0s\n","[CV 2/5] END ..................LinearSVC__C=0.1;, score=0.462 total time=   0.0s\n","[CV 3/5] END ..................LinearSVC__C=0.1;, score=0.600 total time=   0.0s\n","[CV 4/5] END ..................LinearSVC__C=0.1;, score=0.694 total time=   0.0s\n","[CV 5/5] END ..................LinearSVC__C=0.1;, score=0.695 total time=   0.0s\n","[CV 1/5] END ....................LinearSVC__C=1;, score=0.667 total time=   0.0s\n","[CV 2/5] END ....................LinearSVC__C=1;, score=0.571 total time=   0.0s\n","[CV 3/5] END ....................LinearSVC__C=1;, score=0.609 total time=   0.0s\n","[CV 4/5] END ....................LinearSVC__C=1;, score=0.707 total time=   0.0s\n","[CV 5/5] END ....................LinearSVC__C=1;, score=0.708 total time=   0.0s\n","[CV 1/5] END ...................LinearSVC__C=10;, score=0.667 total time=   0.1s\n","[CV 2/5] END ...................LinearSVC__C=10;, score=0.571 total time=   0.1s\n","[CV 3/5] END ...................LinearSVC__C=10;, score=0.609 total time=   0.1s\n","[CV 4/5] END ...................LinearSVC__C=10;, score=0.694 total time=   0.1s\n","[CV 5/5] END ...................LinearSVC__C=10;, score=0.701 total time=   0.1s\n","[CV 1/5] END ..................LinearSVC__C=100;, score=0.667 total time=   0.2s\n","[CV 2/5] END ..................LinearSVC__C=100;, score=0.571 total time=   0.2s\n","[CV 3/5] END ..................LinearSVC__C=100;, score=0.609 total time=   0.2s\n","[CV 4/5] END ..................LinearSVC__C=100;, score=0.694 total time=   0.2s\n","[CV 5/5] END ..................LinearSVC__C=100;, score=0.701 total time=   0.2s\n","[CV 1/5] END .................LinearSVC__C=1000;, score=0.667 total time=   1.4s\n","[CV 2/5] END .................LinearSVC__C=1000;, score=0.571 total time=   1.2s\n","[CV 3/5] END .................LinearSVC__C=1000;, score=0.609 total time=   1.4s\n","[CV 4/5] END .................LinearSVC__C=1000;, score=0.694 total time=   1.9s\n","[CV 5/5] END .................LinearSVC__C=1000;, score=0.701 total time=   1.1s\n","\n","--------------------------------------------\n","\n","Inner CV (Hyperparameters and model selection): \n","  F1-score = 0.6524389861346384\n","  Best hyperparams = {'LinearSVC__C': 1}\n","Outer CV (Quality of model selection assessment): \n","  F1-score = 0.45454545454545453\n","\n","--------------------------------------------\n","\n","Computing inner cross validation for grid search of best hyperparameters...\n","Fitting 5 folds for each of 7 candidates, totalling 35 fits\n","[CV 1/5] END ................LinearSVC__C=0.001;, score=0.400 total time=   0.0s\n","[CV 2/5] END ................LinearSVC__C=0.001;, score=0.206 total time=   0.0s\n","[CV 3/5] END ................LinearSVC__C=0.001;, score=0.286 total time=   0.0s\n","[CV 4/5] END ................LinearSVC__C=0.001;, score=0.257 total time=   0.0s\n","[CV 5/5] END ................LinearSVC__C=0.001;, score=0.235 total time=   0.0s\n","[CV 1/5] END .................LinearSVC__C=0.01;, score=0.653 total time=   0.0s\n","[CV 2/5] END .................LinearSVC__C=0.01;, score=0.475 total time=   0.0s\n","[CV 3/5] END .................LinearSVC__C=0.01;, score=0.518 total time=   0.0s\n","[CV 4/5] END .................LinearSVC__C=0.01;, score=0.558 total time=   0.0s\n","[CV 5/5] END .................LinearSVC__C=0.01;, score=0.475 total time=   0.0s\n","[CV 1/5] END ..................LinearSVC__C=0.1;, score=0.673 total time=   0.0s\n","[CV 2/5] END ..................LinearSVC__C=0.1;, score=0.530 total time=   0.0s\n","[CV 3/5] END ..................LinearSVC__C=0.1;, score=0.524 total time=   0.0s\n","[CV 4/5] END ..................LinearSVC__C=0.1;, score=0.722 total time=   0.0s\n","[CV 5/5] END ..................LinearSVC__C=0.1;, score=0.591 total time=   0.0s\n","[CV 1/5] END ....................LinearSVC__C=1;, score=0.673 total time=   0.0s\n","[CV 2/5] END ....................LinearSVC__C=1;, score=0.581 total time=   0.0s\n","[CV 3/5] END ....................LinearSVC__C=1;, score=0.541 total time=   0.0s\n","[CV 4/5] END ....................LinearSVC__C=1;, score=0.740 total time=   0.0s\n","[CV 5/5] END ....................LinearSVC__C=1;, score=0.622 total time=   0.0s\n","[CV 1/5] END ...................LinearSVC__C=10;, score=0.673 total time=   0.1s\n","[CV 2/5] END ...................LinearSVC__C=10;, score=0.598 total time=   0.1s\n","[CV 3/5] END ...................LinearSVC__C=10;, score=0.541 total time=   0.1s\n","[CV 4/5] END ...................LinearSVC__C=10;, score=0.740 total time=   0.1s\n","[CV 5/5] END ...................LinearSVC__C=10;, score=0.622 total time=   0.1s\n","[CV 1/5] END ..................LinearSVC__C=100;, score=0.673 total time=   0.2s\n","[CV 2/5] END ..................LinearSVC__C=100;, score=0.598 total time=   0.2s\n","[CV 3/5] END ..................LinearSVC__C=100;, score=0.541 total time=   0.2s\n","[CV 4/5] END ..................LinearSVC__C=100;, score=0.740 total time=   0.2s\n","[CV 5/5] END ..................LinearSVC__C=100;, score=0.622 total time=   0.2s\n","[CV 1/5] END .................LinearSVC__C=1000;, score=0.673 total time=   1.4s\n","[CV 2/5] END .................LinearSVC__C=1000;, score=0.598 total time=   1.1s\n","[CV 3/5] END .................LinearSVC__C=1000;, score=0.541 total time=   1.2s\n","[CV 4/5] END .................LinearSVC__C=1000;, score=0.740 total time=   1.2s\n","[CV 5/5] END .................LinearSVC__C=1000;, score=0.622 total time=   1.4s\n","\n","--------------------------------------------\n","\n","Inner CV (Hyperparameters and model selection): \n","  F1-score = 0.6349138459981692\n","  Best hyperparams = {'LinearSVC__C': 10}\n","Outer CV (Quality of model selection assessment): \n","  F1-score = 0.6153846153846154\n","\n","--------------------------------------------\n","\n","Computing inner cross validation for grid search of best hyperparameters...\n","Fitting 5 folds for each of 7 candidates, totalling 35 fits\n","[CV 1/5] END ................LinearSVC__C=0.001;, score=0.373 total time=   0.0s\n","[CV 2/5] END ................LinearSVC__C=0.001;, score=0.154 total time=   0.0s\n","[CV 3/5] END ................LinearSVC__C=0.001;, score=0.261 total time=   0.0s\n","[CV 4/5] END ................LinearSVC__C=0.001;, score=0.209 total time=   0.0s\n","[CV 5/5] END ................LinearSVC__C=0.001;, score=0.329 total time=   0.0s\n","[CV 1/5] END .................LinearSVC__C=0.01;, score=0.607 total time=   0.0s\n","[CV 2/5] END .................LinearSVC__C=0.01;, score=0.482 total time=   0.0s\n","[CV 3/5] END .................LinearSVC__C=0.01;, score=0.548 total time=   0.0s\n","[CV 4/5] END .................LinearSVC__C=0.01;, score=0.462 total time=   0.0s\n","[CV 5/5] END .................LinearSVC__C=0.01;, score=0.593 total time=   0.0s\n","[CV 1/5] END ..................LinearSVC__C=0.1;, score=0.667 total time=   0.0s\n","[CV 2/5] END ..................LinearSVC__C=0.1;, score=0.500 total time=   0.0s\n","[CV 3/5] END ..................LinearSVC__C=0.1;, score=0.578 total time=   0.0s\n","[CV 4/5] END ..................LinearSVC__C=0.1;, score=0.614 total time=   0.0s\n","[CV 5/5] END ..................LinearSVC__C=0.1;, score=0.645 total time=   0.0s\n","[CV 1/5] END ....................LinearSVC__C=1;, score=0.632 total time=   0.0s\n","[CV 2/5] END ....................LinearSVC__C=1;, score=0.482 total time=   0.0s\n","[CV 3/5] END ....................LinearSVC__C=1;, score=0.632 total time=   0.0s\n","[CV 4/5] END ....................LinearSVC__C=1;, score=0.702 total time=   0.0s\n","[CV 5/5] END ....................LinearSVC__C=1;, score=0.701 total time=   0.0s\n","[CV 1/5] END ...................LinearSVC__C=10;, score=0.632 total time=   0.0s\n","[CV 2/5] END ...................LinearSVC__C=10;, score=0.482 total time=   0.0s\n","[CV 3/5] END ...................LinearSVC__C=10;, score=0.646 total time=   0.1s\n","[CV 4/5] END ...................LinearSVC__C=10;, score=0.681 total time=   0.1s\n","[CV 5/5] END ...................LinearSVC__C=10;, score=0.707 total time=   0.1s\n","[CV 1/5] END ..................LinearSVC__C=100;, score=0.632 total time=   0.2s\n","[CV 2/5] END ..................LinearSVC__C=100;, score=0.482 total time=   0.1s\n","[CV 3/5] END ..................LinearSVC__C=100;, score=0.646 total time=   0.1s\n","[CV 4/5] END ..................LinearSVC__C=100;, score=0.681 total time=   0.3s\n","[CV 5/5] END ..................LinearSVC__C=100;, score=0.707 total time=   0.2s\n","[CV 1/5] END .................LinearSVC__C=1000;, score=0.632 total time=   0.9s\n","[CV 2/5] END .................LinearSVC__C=1000;, score=0.482 total time=   0.8s\n","[CV 3/5] END .................LinearSVC__C=1000;, score=0.646 total time=   0.9s\n","[CV 4/5] END .................LinearSVC__C=1000;, score=0.674 total time=   1.1s\n","[CV 5/5] END .................LinearSVC__C=1000;, score=0.707 total time=   1.2s\n","\n","--------------------------------------------\n","\n","Inner CV (Hyperparameters and model selection): \n","  F1-score = 0.6296488385979471\n","  Best hyperparams = {'LinearSVC__C': 1}\n","Outer CV (Quality of model selection assessment): \n","  F1-score = 0.6122448979591837\n","\n","--------------------------------------------\n","\n","Computing inner cross validation for grid search of best hyperparameters...\n","Fitting 5 folds for each of 7 candidates, totalling 35 fits\n","[CV 1/5] END ................LinearSVC__C=0.001;, score=0.416 total time=   0.0s\n","[CV 2/5] END ................LinearSVC__C=0.001;, score=0.125 total time=   0.0s\n","[CV 3/5] END ................LinearSVC__C=0.001;, score=0.356 total time=   0.0s\n","[CV 4/5] END ................LinearSVC__C=0.001;, score=0.333 total time=   0.0s\n","[CV 5/5] END ................LinearSVC__C=0.001;, score=0.310 total time=   0.0s\n","[CV 1/5] END .................LinearSVC__C=0.01;, score=0.584 total time=   0.0s\n","[CV 2/5] END .................LinearSVC__C=0.01;, score=0.351 total time=   0.0s\n","[CV 3/5] END .................LinearSVC__C=0.01;, score=0.605 total time=   0.0s\n","[CV 4/5] END .................LinearSVC__C=0.01;, score=0.554 total time=   0.0s\n","[CV 5/5] END .................LinearSVC__C=0.01;, score=0.588 total time=   0.0s\n","[CV 1/5] END ..................LinearSVC__C=0.1;, score=0.674 total time=   0.0s\n","[CV 2/5] END ..................LinearSVC__C=0.1;, score=0.410 total time=   0.0s\n","[CV 3/5] END ..................LinearSVC__C=0.1;, score=0.644 total time=   0.0s\n","[CV 4/5] END ..................LinearSVC__C=0.1;, score=0.622 total time=   0.0s\n","[CV 5/5] END ..................LinearSVC__C=0.1;, score=0.584 total time=   0.0s\n","[CV 1/5] END ....................LinearSVC__C=1;, score=0.687 total time=   0.0s\n","[CV 2/5] END ....................LinearSVC__C=1;, score=0.458 total time=   0.0s\n","[CV 3/5] END ....................LinearSVC__C=1;, score=0.687 total time=   0.0s\n","[CV 4/5] END ....................LinearSVC__C=1;, score=0.645 total time=   0.0s\n","[CV 5/5] END ....................LinearSVC__C=1;, score=0.615 total time=   0.0s\n","[CV 1/5] END ...................LinearSVC__C=10;, score=0.674 total time=   0.0s\n","[CV 2/5] END ...................LinearSVC__C=10;, score=0.471 total time=   0.1s\n","[CV 3/5] END ...................LinearSVC__C=10;, score=0.673 total time=   0.1s\n","[CV 4/5] END ...................LinearSVC__C=10;, score=0.653 total time=   0.0s\n","[CV 5/5] END ...................LinearSVC__C=10;, score=0.630 total time=   0.1s\n","[CV 1/5] END ..................LinearSVC__C=100;, score=0.674 total time=   0.1s\n","[CV 2/5] END ..................LinearSVC__C=100;, score=0.471 total time=   0.2s\n","[CV 3/5] END ..................LinearSVC__C=100;, score=0.667 total time=   0.2s\n","[CV 4/5] END ..................LinearSVC__C=100;, score=0.653 total time=   0.2s\n","[CV 5/5] END ..................LinearSVC__C=100;, score=0.630 total time=   0.2s\n","[CV 1/5] END .................LinearSVC__C=1000;, score=0.687 total time=   1.2s\n","[CV 2/5] END .................LinearSVC__C=1000;, score=0.471 total time=   0.9s\n","[CV 3/5] END .................LinearSVC__C=1000;, score=0.667 total time=   1.1s\n","[CV 4/5] END .................LinearSVC__C=1000;, score=0.653 total time=   2.2s\n","[CV 5/5] END .................LinearSVC__C=1000;, score=0.630 total time=   1.2s\n","\n","--------------------------------------------\n","\n","Inner CV (Hyperparameters and model selection): \n","  F1-score = 0.6215642527033697\n","  Best hyperparams = {'LinearSVC__C': 1000}\n","Outer CV (Quality of model selection assessment): \n","  F1-score = 0.6909090909090909\n","\n","--------------------------------------------\n","\n","Computing inner cross validation for grid search of best hyperparameters...\n","Fitting 5 folds for each of 7 candidates, totalling 35 fits\n","[CV 1/5] END ................LinearSVC__C=0.001;, score=0.286 total time=   0.0s\n","[CV 2/5] END ................LinearSVC__C=0.001;, score=0.373 total time=   0.0s\n","[CV 3/5] END ................LinearSVC__C=0.001;, score=0.235 total time=   0.0s\n","[CV 4/5] END ................LinearSVC__C=0.001;, score=0.123 total time=   0.0s\n","[CV 5/5] END ................LinearSVC__C=0.001;, score=0.378 total time=   0.0s\n","[CV 1/5] END .................LinearSVC__C=0.01;, score=0.622 total time=   0.0s\n","[CV 2/5] END .................LinearSVC__C=0.01;, score=0.506 total time=   0.0s\n","[CV 3/5] END .................LinearSVC__C=0.01;, score=0.565 total time=   0.0s\n","[CV 4/5] END .................LinearSVC__C=0.01;, score=0.416 total time=   0.0s\n","[CV 5/5] END .................LinearSVC__C=0.01;, score=0.659 total time=   0.0s\n","[CV 1/5] END ..................LinearSVC__C=0.1;, score=0.637 total time=   0.0s\n","[CV 2/5] END ..................LinearSVC__C=0.1;, score=0.584 total time=   0.0s\n","[CV 3/5] END ..................LinearSVC__C=0.1;, score=0.591 total time=   0.0s\n","[CV 4/5] END ..................LinearSVC__C=0.1;, score=0.482 total time=   0.0s\n","[CV 5/5] END ..................LinearSVC__C=0.1;, score=0.729 total time=   0.0s\n","[CV 1/5] END ....................LinearSVC__C=1;, score=0.615 total time=   0.0s\n","[CV 2/5] END ....................LinearSVC__C=1;, score=0.615 total time=   0.0s\n","[CV 3/5] END ....................LinearSVC__C=1;, score=0.630 total time=   0.0s\n","[CV 4/5] END ....................LinearSVC__C=1;, score=0.512 total time=   0.0s\n","[CV 5/5] END ....................LinearSVC__C=1;, score=0.716 total time=   0.0s\n","[CV 1/5] END ...................LinearSVC__C=10;, score=0.600 total time=   0.1s\n","[CV 2/5] END ...................LinearSVC__C=10;, score=0.617 total time=   0.1s\n","[CV 3/5] END ...................LinearSVC__C=10;, score=0.637 total time=   0.1s\n","[CV 4/5] END ...................LinearSVC__C=10;, score=0.506 total time=   0.0s\n","[CV 5/5] END ...................LinearSVC__C=10;, score=0.729 total time=   0.0s\n","[CV 1/5] END ..................LinearSVC__C=100;, score=0.600 total time=   0.1s\n","[CV 2/5] END ..................LinearSVC__C=100;, score=0.617 total time=   0.2s\n","[CV 3/5] END ..................LinearSVC__C=100;, score=0.637 total time=   0.2s\n","[CV 4/5] END ..................LinearSVC__C=100;, score=0.506 total time=   0.2s\n","[CV 5/5] END ..................LinearSVC__C=100;, score=0.729 total time=   0.2s\n","[CV 1/5] END .................LinearSVC__C=1000;, score=0.600 total time=   1.5s\n","[CV 2/5] END .................LinearSVC__C=1000;, score=0.617 total time=   1.2s\n","[CV 3/5] END .................LinearSVC__C=1000;, score=0.637 total time=   1.1s\n","[CV 4/5] END .................LinearSVC__C=1000;, score=0.506 total time=   1.0s\n","[CV 5/5] END .................LinearSVC__C=1000;, score=0.729 total time=   1.4s\n","\n","--------------------------------------------\n","\n","Inner CV (Hyperparameters and model selection): \n","  F1-score = 0.617859541412366\n","  Best hyperparams = {'LinearSVC__C': 10}\n","Outer CV (Quality of model selection assessment): \n","  F1-score = 0.7272727272727273\n","\n","--------------------------------------------\n","\n","\n","--------------------------------------------\n","\n","Mean training F1-score = 0.6359789495461442 (0.009974924131918068)\n","Mean validation F1-score = 0.6271642885416472 (0.08639344586079556)\n","List of best hyperparameters to check stability: \n"]},{"output_type":"display_data","data":{"text/plain":["   LinearSVC__C\n","0             1\n","1           100\n","2            10\n","3            10\n","4             1\n","5             1\n","6            10\n","7             1\n","8          1000\n","9            10"],"text/html":["\n","  <div id=\"df-0bc4a008-b73d-4204-8590-6b5a81a7c688\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>LinearSVC__C</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>100</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>1000</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>10</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0bc4a008-b73d-4204-8590-6b5a81a7c688')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-0bc4a008-b73d-4204-8590-6b5a81a7c688 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-0bc4a008-b73d-4204-8590-6b5a81a7c688');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["None\n","Fitting 5 folds for each of 7 candidates, totalling 35 fits\n","[CV 1/5] END ................LinearSVC__C=0.001;, score=0.164 total time=   0.1s\n","[CV 2/5] END ................LinearSVC__C=0.001;, score=0.341 total time=   0.1s\n","[CV 3/5] END ................LinearSVC__C=0.001;, score=0.237 total time=   0.1s\n","[CV 4/5] END ................LinearSVC__C=0.001;, score=0.350 total time=   0.1s\n","[CV 5/5] END ................LinearSVC__C=0.001;, score=0.414 total time=   0.1s\n","[CV 1/5] END .................LinearSVC__C=0.01;, score=0.477 total time=   0.1s\n","[CV 2/5] END .................LinearSVC__C=0.01;, score=0.606 total time=   0.1s\n","[CV 3/5] END .................LinearSVC__C=0.01;, score=0.442 total time=   0.1s\n","[CV 4/5] END .................LinearSVC__C=0.01;, score=0.542 total time=   0.1s\n","[CV 5/5] END .................LinearSVC__C=0.01;, score=0.627 total time=   0.1s\n","[CV 1/5] END ..................LinearSVC__C=0.1;, score=0.606 total time=   0.1s\n","[CV 2/5] END ..................LinearSVC__C=0.1;, score=0.680 total time=   0.1s\n","[CV 3/5] END ..................LinearSVC__C=0.1;, score=0.467 total time=   0.1s\n","[CV 4/5] END ..................LinearSVC__C=0.1;, score=0.600 total time=   0.1s\n","[CV 5/5] END ..................LinearSVC__C=0.1;, score=0.691 total time=   0.1s\n","[CV 1/5] END ....................LinearSVC__C=1;, score=0.600 total time=   0.1s\n","[CV 2/5] END ....................LinearSVC__C=1;, score=0.692 total time=   0.1s\n","[CV 3/5] END ....................LinearSVC__C=1;, score=0.495 total time=   0.1s\n","[CV 4/5] END ....................LinearSVC__C=1;, score=0.614 total time=   0.1s\n","[CV 5/5] END ....................LinearSVC__C=1;, score=0.691 total time=   0.1s\n","[CV 1/5] END ...................LinearSVC__C=10;, score=0.635 total time=   0.1s\n","[CV 2/5] END ...................LinearSVC__C=10;, score=0.679 total time=   0.1s\n","[CV 3/5] END ...................LinearSVC__C=10;, score=0.511 total time=   0.1s\n","[CV 4/5] END ...................LinearSVC__C=10;, score=0.614 total time=   0.1s\n","[CV 5/5] END ...................LinearSVC__C=10;, score=0.703 total time=   0.1s\n","[CV 1/5] END ..................LinearSVC__C=100;, score=0.635 total time=   0.2s\n","[CV 2/5] END ..................LinearSVC__C=100;, score=0.692 total time=   0.3s\n","[CV 3/5] END ..................LinearSVC__C=100;, score=0.511 total time=   0.3s\n","[CV 4/5] END ..................LinearSVC__C=100;, score=0.614 total time=   0.3s\n","[CV 5/5] END ..................LinearSVC__C=100;, score=0.714 total time=   0.2s\n","[CV 1/5] END .................LinearSVC__C=1000;, score=0.635 total time=   1.0s\n","[CV 2/5] END .................LinearSVC__C=1000;, score=0.692 total time=   1.9s\n","[CV 3/5] END .................LinearSVC__C=1000;, score=0.511 total time=   1.2s\n","[CV 4/5] END .................LinearSVC__C=1000;, score=0.614 total time=   2.0s\n","[CV 5/5] END .................LinearSVC__C=1000;, score=0.726 total time=   1.4s\n",">> Predicting on test dataset...\n","Best hyperparameters:\n"]},{"output_type":"display_data","data":{"text/plain":["   LinearSVC__C\n","0          1000"],"text/html":["\n","  <div id=\"df-82835e33-d106-4e62-9645-e9595940b691\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>LinearSVC__C</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-82835e33-d106-4e62-9645-e9595940b691')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-82835e33-d106-4e62-9645-e9595940b691 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-82835e33-d106-4e62-9645-e9595940b691');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["None\n","\n","Test classification report\n","              precision    recall  f1-score   support\n","\n","           0       0.46      0.91      0.61        34\n","           1       0.94      0.57      0.71        83\n","\n","    accuracy                           0.67       117\n","   macro avg       0.70      0.74      0.66       117\n","weighted avg       0.80      0.67      0.68       117\n","\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 2 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["linear_svm_classifier_pca = Classifier('LinearSVC', config_dict['CLASSIFICATION']['MODELS']['LinearSVC'], \n","                                       config_dict['CLASSIFICATION']['GENERAL'], \n","                                       config_dict['CLASSIFICATION']['PARAMS']['LinearSVC'], \n","                                       class_balancer, \n","                                       feature_scaler)\n","file_name = f'{linear_svm_classifier_pca.name}_PCA.pkl'\n","\n","if config_dict['GENERAL']['PERFORM_NCV']:\n","  linear_svm_pca_mean_score, linear_svm_pca_std_score = linear_svm_classifier_pca.nested_cv(X_train, y_train, apply_PCA=True, num_components=num_components)\n","  save(linear_svm_classifier_pca, os.path.join(MODELS_DIRPATH, file_name))\n","else:\n","  linear_svm_classifier_pca = load(os.path.join(MODELS_DIRPATH, file_name))\n","  linear_svm_classifier_pca.print_nested_cv_results()\n","\n","classifiers.append((linear_svm_classifier_pca, \"PCA\"))\n","linear_svm_classifier_pca.cv(X_train, X_test, y_train, y_test, apply_PCA=True, num_components=num_components)"]},{"cell_type":"code","execution_count":354,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":278},"executionInfo":{"elapsed":3960,"status":"ok","timestamp":1661109589688,"user":{"displayName":"Elisa C","userId":"11182657622104819579"},"user_tz":-120},"id":"OIh64hkq-DLn","outputId":"f2f1e5b3-7b0f-4b14-a77a-c75f9df927da"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAAWsAAAEFCAYAAAAluMZSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3xUVf7/8de5d1p6DwkJvRiKNAEBwd4Qe8F1bayrrPq16+6qa19119Xddd2ii738XMUOoig2FERAOkgJEAJJSO9tyr3n90cCRESKTjKZyef5ePBQ5mbuvGeM75yce++5SmuNEEKIzs0IdQAhhBAHJmUthBBhQMpaCCHCgJS1EEKEASlrIYQIA1LWQggRBqSsxU+ilJqklNoY6hxCdBVS1mK/lFLblFIn7v241vorrfVhoci0N6VUolLqOaVUsVKqTim1SSl1e+u2DUqpK/bxnBuVUt+2+fspSqkvW59fppSar5Q6M8g5X1BK+ZRS9UqpSqXUPKVUTpvtA5VSbyilypVSNUqp1UqpW5RSZpuviW19/ofBzCY6PylrEVaUUo59PPx3IBYYBCQAZwKbW7e9CFy2j+dc2roNpdT5wBvAS0A20A24BzjjIPL0VkptO4S38BetdWzr65QCL7Tupx+wGNgBHK61TgAuAEYDcW2efx7gBU5SSmUcwuuKMCdlLX4SpdSxSqmCNn/fppS6rXU0WKOUel0p5Wmz/XSl1EqlVLVS6mul1LA2225XSm1pHdV+p5Q6p822aUqphUqpvyulKoD79hFnDPCq1rpKa21rrTdord9s3fYyMFEp1avNPgcDw4D/KaUU8Dfgj1rrZ7TWNa37mK+1vio4n9YPaa0bgVeBoa0P3Q98rbW+RWu9s/VrNmqtf6m1rm7z1MuBp4DVwCXtlU90PlLWIpimAqcCfWgpw2kASqmRwHPAb4AU4L/ALKWUu/V5W4BJtIyK7wdeUUplttnvkcBWWka8D+3jdb8BHlJK/UopNaDtBq11AfA5LSPpXS4FPtBalwOHAT2AN+lASqlY4GJgRetDJx4oQ+sPnGOB/9f6Z1+/MYgIJWUtgukJrXWR1roSmA2MaH18OvBfrfVirbWltX6Rll/lxwFord9ofZ6ttX4dyAXGttlvkdb6n1rrgNa6aR+vez0t5XUd8J1SarNSanKb7S/SWtZKKYOWknyxdVtK6z93/sz3frBuU0pV0zJNE0vrD7TWHAfKcCmwWmv9HfAaMKT1B6HoAqSsRTAVt/n3RlrKCKAXcGvrFEh1a1n1ALoDKKUuazNFUk3L1EBqm33t2N+Laq2btNYPa62PoKX0ZgJvKKWSW7/kbSBTKTWOlpFpNDCndVtF6z/bjuT3Syn1yzZZVwM92743pVTP/Tz9Ma11otY6Q2t9ptZ6S5scB8pwGS0/lNBaFwLzaZkWEV2AlLXoCDuAh1pLatefaK31/1p/tX+allFxitY6EVgLqDbPP+ilIbXWtcDDQAwt0zG75offpKXsLgVe01r7Wp+ysTXfeYfwGq/ueh+0TPds3+u9bT/YfbXxyf4yKKUmAAOAO1rPeimmZXrolz9y0FVEGClrcTCcSilPmz+HWg5PA1crpY5ULWKUUlOUUnG0lKoGygCUUr9iz0G3g6KUulspNUYp5Wo9qHkjUE1LEe/yInAhLYW4awoE3bJG8C3A3a1z3vFKKUMpNVEpNeMQ3+fPcS8wQSn16K6zPJRS/ZVSryilEmkZQc8DBtMyvTSCls8pCpj8I/sUEUTKWhyMD4CmNn/uO5Qna62/Ba4C/gVU0TJfO61123fAX4FFQAlwOLDwEPNp4HmgHCgCTgKmaK3r23zNl0ANUKC1XrpXvjdpKfIrWp9fAjwIvHeIOX6y1umQ8UBvYJ1SqgZ4C/gW8NNy8PafWuviNn/yaDnbRaZCugAlNx8QQojOT0bWQggRBqSshRAiDEhZCyFEGJCyFkKIMNAu52dGxSTrhKTs9tj1D6Q05KOczg55LSGEaE/ryirKtdZp+9rWLmWdkJTNJde/3x67/oFpS6ajFJhpWR3yekII0V4GPfVc/o9tC/tpEP1gR163IIQQoRH2ZS2EEF2BlLUQQoQBKWshhAgDYV/WbyxKQa6YF0JEurAv68ayigN/kRBChLmwL2shhOgKpKyFECIMRExZB0oLQx1BCCHaTUSU9cwpb4U6ghBCtKuIKGshhIh0UtZCCBEGpKyFECIMRMQt7Heda21VFGOmZIQ4jRDBs6mikjvmzWdbXS39EhJ45OTj6JOYEOpYIgQiZmSdfcKoUEcQIqgafH6umjWXE2tdPEdvjqp2cNV7H+INBEIdTYRAxJS1EJFmU2UVSdrkZCOBWGVyupGIGdDk19SGOpoIASlrITqpBLeLcttPk7YBqNcW1bafeLc7xMlEKETEnPVuthXqBEIETd+kRI7v24vb8woYbkexzGji3MMGkhEbE+poEctnWRTXN5ASFUWMq3PdLjBiynru4fcx9NMzQx1DiKC6/7iJfNInn23VNZyYnMSxPXuEOlLEWl1SxnUfzMOwNfW2xZ0Tx3HuoIGhjrVbxJT1t18XMzTUIYQIMqUUJ/XpHeoYEc+yba7/YB7T/cmMN2IpwMcdCxczMrNbpzn7RuashRBdXmVzM96AxXgjFoBs5SLHiCK3sirEyfaQshZCdHmJbg9awUbdBECNDpBrN9MjPi7EyfaImGmQXayyQsy0rFDHECJs2VpT2tCIx+Eg0dM1zjxxmgYPn3A0d336JX1MD/lWMxcdPphBqSmhjrZbRJW1fnAG6u7poY4hRNiqaGrimtkfUVBTR7O2OT9nIHdMGodSKtTR2t0JfXox9BfnkltVRWZsLP2SEkMd6XsiqqyFED/P/Z8toH+N5mF606Bs7s7N5/2MdM4Y2C/U0TpEt9gYunXSUyNlzloIsdt35RWcSgJKKWKVyVFWNOtKy0IdSyBlLYRoIzsulhW6EQBLa9YaXnokxoc4lYAIK+sXZ4HWoU4hRPi657iJvO2s5S5jJzcYBbhSY7hg0GGhjiWQOWshRBt9kxKZ9cvzWFNaRrTDyfBuaZhGRI3pwpaUtRDiexLcbib2yA51DLEX+ZEphBBhICLL2qooDnUEIYQIqogr67U3zUJbslSqECKyRFxZf/u1jKqFEJEn4spaCCEikZS1EEKEgYgtaznIKISIJBFZ1tknjAp1BCGECKqILGshhIg0UtZCCBEGIresbTnXWggROSKyrP/m+YOsvieEiCgRWdaNZRWhjiCEEEEVkWUthBCRRspaCCHCQESXdaC0MNQRhBAiKCK2rNfeNCvUEYQQImgitqyFECKSSFkLIUQYkLIWQogwIGUthBBhIGLLWu4YI4SIJBFb1kIIEUmkrIUQIgxEfFlbZXJhjBAi/EV0Wa+9aZasvieEiAgRXdZykFEIESkiuqyFECJSSFkLIUQY6BJlLQcZhRDhLuLLOuvma0MdQQghfraIL2shhIgEUtZCCBEGHKEOIMT+5FZW8fjXS6lqbGJC7x5cPXoEDkPGGMHkt2z+s3Q5i7cXkhoTzc1HjaVPYkKoY4m9dInverkwJjwV1zcw7d059Cvycn51FAtWb+bhLxeFOlbEuf+LBSxZu5ULqqPoWdjMpW+/T1ljY6hjib1EfFk/tHBEqCOIn+jz/O2MsqM5y0hiuBHN73Q6727ajJafvkFja83szVv5ve7GMCOac4wkhmoPX24vCHU0sZeIL2sRvkxl4FN7itmLxlQqhIkik1LgY8/n7JPPuVOSshad1kl9e5Hr8PG8Luczu5aHjGIuGzYEJUUSNIZSXDp0MA8YxXxm1/KMLmO70+L43j1DHU3spcscYLQqijFTMkIdQxyCJI+H184/i/9+u5L1jU1M6zWK8wYNDHWsiHPL+DFkJ8S3HmBM4n+jhxPvdoc6lthLlyjrtTfNYujjZ4Y6htiP5kCAe+YvZEdNLSMy0vntuDEYhkF6TDR3HzMh1PEimlKKC4fkcOGQnFBHEfvRJcpadG4B22byyzNJ9MERKoaPSjexorCY1y44K9TRhOg0pKxFyL21IZeAN8CfzT44lOJ0lchlFVvZUVtLj/j4UMcTolOQA4wi5Kqam0hWDhytBw5jMXCiqGxqDnEyIToPKWsRVFprVhSXMC9vG0V19Qf1nMn9+rJde5lrVVOq/bxol+MwFEPSUts5rRDho0tMg3z7dTFDQx2iC9Bac9enX7I4v5AeysUGu4lHTzmOiT2y9/u8Xgnx/OWU47nvky95xion0eXi+TNOl8vKhWijS5S16BgLCwpZnl/EP+xsPMpgrW7kjnnz+eqKiw/43JP69OKkqy7tgJSiLa01723azIqiEjLiYrhs+FBinM5QxxL7IEMXETRFdQ0MwI1HtXxbDSaKKp8Pv2WHOJn4MX9btJRnvvqWpNwqVq/cymVvv483EAh1LLEPUtYiaIakpbBcN7JT+wCYo6vpnxCP05Rvs87IZ1m8tOY7HtDdOcNI4ladjmrw8XVBUaijiX3oUtMggdJCHOlZoY4RsYakpXLD+NHcsHAxLhSJUR6enHxKqGOJH+G3W37jiWkdsymliMOkWUbWnVKXKesXxs5g2pLpoY4R8aYOyeHsnAHUeL2kREVhyDoenVaM08m4zAz+WVrKWTqB9bqZzYaXsVmZoY4m9kF+PxVB5zJN0qKjpajDwN9OPYHEPmn8I6qKVekGz599GilRUaGOJfahy4yshRA/FONy8uAJR4c6hjgIMrIWQogw0KXKOuvma7HKCkMdQwghDlmXKmshhAhXMmcdZl5d8x2vrlqHBi4aNpiLDx8sd04RoguQsg4j723M5fnFK7lRp6GAfyxZRYzLyTk5cvcUISJdl5oGKUgZQTjfGHvuxq1cYicxSEWRo6K4xE7io41bQx1LCNEBulRZvzgr1Al+nmiXg0r2XF1WSYAolyy6I0RXINMgYeTK0SO4ouADqmwLBXxs1PHM6PGhjiWE6ABS1mFkUGoKr5x3Bu9tzEVrePmw/vRPTgp1LCFEB5CyDjP9khK5ZdyYUMcQQnSwLjVnvUugVC6MEUKEly5X1jOnvBXqCBGvzusjt7KKBp8/1FGEiBgyDSKC6qMtedz9+VckKic1OsAjJx7Dsb17hjqWEGFPyroT81s2s3M3U9LQyIhu6YzP7h7qSPtV3tjEPZ8v4CHdnb542KCbuP2T+cy79ELi3K5QxxMirElZB1FJfQMf521Dazi5b28yYmN+8r4Cts3Vs+fSUFHPAMvFTGMd00YP4/IRhwcxcXBtr6kly3DR1/YAkKOiSFIOCurqGOROCXE6IcJbl5uzbiyraJf9bquu4byZ7/Lt4o0sW7KR82a+S151zU/e36KCIsoqannAzmSakcrDujt/X7KMgN15bz6bFRdLoeWlqPUejPnaS4Xt/1k/tIQQLWRkHSRPLlnBlEAcU41kAN4MVPLk4uX85ZTjftL+ar1eMpQTs3WRplQcoMFrWTiMzvkztltsDLcdNZbfLlxKD9PNDsvL3UdPIMnjCXU0IcKelHWQ1DQ1M5Q9l35n42JLU/NP3t+ozG48pJv4xq4nR3l4m2oGpyQT4+zcl5dfMDiHiT2z2VFTR6+EeLrJqFqIoOicQ7QwNKlvD94wayjWfkq0n5lGNZP6/PSzIDJjY/nnaSfyWkw916odlHXz8MRpJwUxcfvJjI1lbFamFLUQQXTAkbVSKh5I01pv2evxYVrr1e2WrB1lnzCKgk+X40jPCto+fzl0MBWNzfx27Xo0mqmDc7h42OCftc8jMjOYffH5QUoohAhn+y1rpdRU4HGgVCnlBKZprZe2bn4BGNW+8drHg3VXM43pP+m5S4uKeWj+Qrz+AJP69uTOiS0LKSmluOHII7jhyCOCGfUn81kWNV4vyR4PZied4xZCHLwDjazvBI7QWu9USo0FXlZK3aG1fgfocrcnWVNSxlWzPuQslUSG8vDK2k0U1tbxz8knYYTgbi1+y+al1WvJLaukT0oi04YPxe1w8PGWPP7w2VeYKDxOB/+echJD0lI7PJ8QIngOVNam1nongNZ6iVLqOOB9pVQPIIyX8T84szdt4emlK2gOBBjfI4sdDfUcq+K4zExlrW7EAhZsL2TS86/y+KknMKZ7Rodl01pz89xPqS6uYoIVw+Lt5SzZUcT9x0/i3s8X8CDd6a88LPDVce2cj/n0sl902rNIhBAHdqD/e+uUUv12/aW1uI8FzgKGtGOukHti8TL+8Nl86uoaKW5qYt6mrXxXUo4HgwZt8WdrJ7cYGbztGMBNgVRu/PATar3eDsu3o7aOlTtLuMvO4BQjgdt1N7ZVVPH5tu0MMKLor1pOl3OjaPb6+f3HX7CporLD8gkhgutAI+tr2Gu6Q2tdp5Q6FZjabqk6iFVWiJnWcpDxoy15vLtuI7V+PxN6Z/P0ilW4MZhqpDBJxbHAruXJQBkfUo3HNkjA5Aij5WyHUUYMKaqK/JpaDk9P65DsftvGpRQO3fKfxwA8GCR6POTZzdRpixW6kWftUi4zUqjfXs/lBXN4+dzTZQ1sIcLQgcq6AegGbN7r8bHAN+2SqIPoB2eg7m45yDhr02Ye+HwBpgYnBkVlVThQxGJwspEAwElmIq8FKjl+cH8+yc2j1u+nXPtJVU4qdIBSy0dadHSH5e+VEE9ybDRP15ZztI7lGxowPE5O6deb3PJKbvhuI9q2ucHI2P1DxWvbvLFuA3dMkrvLCBFuDjQN8jhQu4/Ha1u3RYQnFn2LSytuNDK4ykjDh2YIUdRgUa8tAHbaPmqwmL0hl+ljRnBEZgbXWfncaxVyEzuYfsTwDr2s2mEYPH3WZFTvJJ6LraOpRzzPnXMaLtPklgljePKsU4mN8uBuc+DTjUHA/v6hhrzqGj7Nyye3sqrDsgshDt2BRtbdtNZr9n5Qa71GKdW7XRJ1AK01BQU7+CJ3GxRVUdvUzA1GBkcasQA0YPO5XYsDg+utfJIxycNHLAZOW/HXr5fQ1xHF1UY6edpLLl5GZnbcwcVdkjwe/nzSsfvcNiQtlUtHDuU/i1dyhZ1CHRbvGjU8lTNu99fMXLeBvy9aymFGFLl2M78eNYwrRg3roPRCiENxoLJO3M+2qGAGaW9aa2bOuJDKvKVoNE8Co4jGNHZiAz72LJDkw6YYPykDLqWqcjWlFat41uxDknIwy6riFV3O1TqVvoaHY4EY2+CTrdsYldktKFk3VVbxwGcLKKirY3BaKvcfP/EnTbFcNHQQDsNg9vpc3A6Tx8ecyPBu6QBUNTfz6NdL+DvZZNouKnSAG5at4uT+fciOjwvK+xBCBM+ByvpbpdRVWuun2z6olLoSWNZ+sYLruxXv8Plbt0PAy++NTNKVk/9apaygkXjbJArFv+1S6rHxo3nZLsfh6UZG6giK89/geBVLkmr5qE4yEnjGKmOj3Uxfs+WMi2plkxWkNTuqm71c+d4HXBhIYASZfLizhmtmf8TMqWcf8rncSimmDslh6pCcH2wra2gk2XCSqVvWmU5RDrIMN8UNDVLWQnRCByrrm4B3lFIXs6ecRwMu4Jz2DBYMleXb+GjmLZRuX0YqDo4igTGtUx03mN24zsrnNyqdLXh5U1fyoV1FHTYxLhdR7gDV6x9icu/uLNm0jWZt41EGy3QDSTh4kQrqbZtqZbHI0cQbgw8LSua1ZWVkaRenqpZfaqbpFC6r3UZZQ2NQ19rIio+jDovldgOjjBjW6yaKbC99EhOC9hpCiODZb1lrrUuACa0XwwxtfXiO1vqzdk/2M5SX5vLK30/B0ham4UIbLsoMFx9rH+dqiwRlUoGFG4OZupI/mz34xKolBpOdBIj1Baj2VaGBD6srcAC/sbaRiZNCfJyg4tmYpPCmp5DmdjLz8CFBK9Joh5Mq7cfSGlMp6rFp1jZRzuAukBjjdPL45BO4ee5nYJcSUPCXk44lJSqsZreE6DIOtDaIB7ga6A+sAZ7VWgc6IthPUVtdztN/PgLDcBEV3w9fbR5RsT0ZPOEJDDOKrWse55bCTznF9vC+XcUVKpVndTlP26U0YnOvmcX/s8r5jiZuNNJpxOYpu5ReuCjHYqyKIYUEntFlNFTa5FZVYaPwWza/P+pI1CFOU/gsi2U7S/BZFiMz0ol3uxmRkU7PtGTuK9vJ4ZabBWYjv8jJId7tDvrnNbZ7Jl9cfhEVTU0kR3lwmWbQX0MIERwHGq69CPiBr4DJwCBapkY6nSf/NIHmmkIAXLZFoCYXNyZJWSdiOloOzmX0PpP1RZ/whlXBVJXMp7qWjNaPwEbzJ7uMZnzcbGQwsvXc5Fosdto+jjU8fGrXUoyfc40kFul6LlTJ5Kgo7tm4jXdSkzk3Z+BB5230+7ni3Q9orG0iRpkUGwFePGcKPRPi+feUk3lrwyYKamq5Lj2VU/v1CfKntYfTNOROLkKEgQOdZz1Ya32J1vq/wPnA0R2Q6ZDNee1m/DWFaMNFFAb3GJk8afYmBxdVW99A2wFsy0vJjrkM1C7uMLrzhq6iFovHzJ5cbXbjUbMHhbqZeiwesXfygFVItQ6w3faykWZqsLjdyMQEhhJFsfaTrpzEKZPjrRhWFZUeUuYXV64locbPX+0sHrQzOdUfw5+/XAS0FOgvhuRw24SxTO7f95BH7EKIyHOgkbV/179orQOdsTS01mxY+S6mGUVsfH9OqilimNEykr7O7MZvvPksn3c+tr8WD4oaNKWGEwtNAubuMyxcWmFic6ORwWAVxRt2Jddb+QTQnGskU6R9/J/OJwbFfXYBA4mil3KjtWa94WVEfOwh5S6sqWOo7cEwWl5/ONF8XfvT79kohIhsByrr4UqpXVcwKiCq9e8K0Frr+HZNdxBsOwDY2Laf5G7jKKp9c/e2Yvy4Aa+/hnuMLEYY0WzWzdxh7aA7TjbQzLtWFSca8fzLLmEwURxltJy2dqWRxsdWDQ+Z2RymWg66NVhFLNUNOJRik27imkAetdh4PE7+Nvzg17WybJtybzOz7TKetUsZQQzRpsnhredACyHE3g50NkinP+Jkmk6iYzNpbqrGHZXJdy4PD/nKyLLhQ13DL1QyH+oaRrSOtvsrD91xcbGRTDU2z+pKXrDK8aBIwNx9FkYlAWwgqc1HlK6cDEhKZHyVyQLqicZgnHLzUXMtx73wP6INE7fDgdvpYHBaCtePG01W3PdH3JZtc+nsT9lQC8ndJlBTvhyfZbPVCDBn0jiEEGJfImKB40uvfw/bambzqkfAk8YSw+It6vBhs1Q3UEmA7bpl+dJy7aeMAD2VmxgMYuIHYBsu0nFQSYC7rQJessq53SogBQd/t4rJ114W2/XMtWtI8USRhxcnigfMLC430/i1kUrAsrnMSuJybwLVtQ2Ubi3l4rdmU7XXTXPn5eWztdHFyGNeoN+Yh+g39k/kmYqqgI9Yl5Oq5mb+vXQFD3+1iK+2F4Ti4xRCdEIRUdaxCd245U95ZPQcSW3VapS/FpcOoIBoDDSaW60d3B7YwbVWPhNULEXazwxVi88ZQ6Zy0YTmMDxEKQMHcIWRikITwOZBq4gX7HKyDRf9U5NYpBpJU47dB/5W6UYuN1I5xojnSCOWa4106rHobzmZv33H97IuKihCeevZtux+aqvWEZs4iFqrmVjTQa3Pxy/eeI/clXk41pdx98fzeeO7jbufW+v1UtrQiNYRf98HIcRegnulRQgppbjo6tcBqK7YwUuPHQfaZhmNOFFcoJLpq9xs114+13Us0HU0oTArV3G0HcU25eBGI4N7rUK24aVaW9C6+l4hjfRXbvJtHx9s3MKYrAy+KdjJUruefsrDVu2lT+ti/wB+NIaGem1RVN9AwLZxGAaf5OXzyaatTNPJeMs28kL5bcRmHI3D4eaOo8fwfu4WentNrlfpoGCkjubBxcs4f9BAHvzya97ZuBmXUvRNSuQ/p59Coif4516LzquqqZk/frGQtWXlZMXFcvexR9E3aX/L94hIEhEj670lpvTgyj8sISalDwHDTSPwnq4iWhmMMGLwo3Fj4DRdRMf2Yo7RTK72sdpu5H4jizHEYAAXqRQW0cD5KokHzGxmmL1xei38hdU4TZMXo2q52s6nCov/2RW8Z1cx167mX3YJm2hmR6CZN5ev45K3ZlPn9fHKijVcrVM50UhgipHIJToWX8kXPH7iBM4c2J/mgEVim8MESThotize3biZZZt38ILqzcv0IavK4qH5C0P06YpQ0Fpzzfsf4Sio5U5vKsPLbH717gfUdODdiURoRczIem/Rscn8+refom2byvI83n9pOveWb0WjsdD4DTejjnkeT3QGjXV5rPpqOk/bpWitGKg8/IIUNugmBuBhq25Ga00zNjlE0Q83adpF9mG9+L8xI3lnYy4L8gtYWltHnddHU73NUSqOW4yWZVOfqC7ln4uXoTWYbW68Y6I4tlcWx/XuBcAxPbN55tuVDLE9ZCkXL6lKTu7bizXFpRxtxRBjtBT5qTqex0rLO/5DFSFT1tjEtupa/khvDKXoodws0c2sKinl6J49Qh1PdICILetdlGGQkt6Py2/7FADLCvDvPwwgKqY7nuiWMo2O64PDGc9ZPrjITAHgj4FClhoB3NEZ+JrLWGIXoGwvzdgE7Fi6KxfNgQCGUpyXM5DzWq9evHHOPFS9j6NU3O5zuCfYMXxSUcXUYYN4dP4i/LbGi+Z1o4onho7enbV/chL/OO1E/rZgCTXeOib1yua2o47k5TXrWGAUcXrrmSqrdOMPzjIRkc3jMPFpm0ZlE9t61lK1DuBxRPz/wqJVl/svbZoOLrn1M176x2Tqa3KJTRhATcVKAv46ZmofjZZNEzZLTZsBw+8gtfuxBPx1rJh/BROaHaygkfnUE6UNHus+8gf799s2KThYoOsYq1su4/6cOgak9mDKgH4YSvHO2o2YhslfR53A6L1uWjC2eyavTT3re49dMnQw87du56aqAhKUg52OAM8fe1r7fUii04l3uzk/ZyB35+YzyYpmneElPTmeURnBWUNddH5drqwBktP6MHnqX/norVtwuhIwvBXMmHwcd336JYVeH+naxLaaSc6YCIDDGUdi6mgWFHzII2YP+uHhf3YFM5au2j2Fscu5Q3O4v/hL4qAtC+sAABUxSURBVC3FFVYeATQul5Mcp4PC2jom9+/L5P59Dymv2+HgubNPY3lxCd6AxfBuae2ysJPo3O6YNI7ZGWmsLSnjuPi43TeXEF1DlyxrgMOGTaHPYcdQX1vCNbkPE9c9i4dPPIb/e/9jNBrD9FBW+AndepyK31tNVdli+uDefTXjL40Uzq3cjM+yvrda3Yl9ehE4fiKvrliL4fWS39hEXI9z+LDGy+tvf8jrZ59C75+wZrTDMBjbPTNo71+EH6UUZw7sz5kD+4c6igiBLlvWAC53LMlpsUTlmVhlhQzr1nLK3KOqJztsL39d+zjbNz5HwFcDaJrQu69wzMeHSxks3FHIsb167D7n2hsIkBEbw++PGc8j36yGvhfSrcdkAAqccTyz6lsePObIEL5rIUQ46tJlvYt+cAbq7unEOJ3cMn4MDyxZwUgVTYZt0yvJpKTBzVG1TpbQwM3WdnoqF4t1A9GpI7lz4XpOLSjh3oljKG1oZNo7c/A2+fArjR9FZvc958E6PenUNx76cuBzt+SxKL+QlJgoLh0+hCSP58BPEkJEFCnrvVwybAjDM9JZX17B1Lg4JmR3Z/QzL3Ga2ZvzSGaJbmC2XUVcz8kMGPZbAv4GZs+/iMuGDuSRr76hsr6RNBzUo9HYbFl6J4XOBLQzFq+/kqsmjj5wiDaeWb6amcvXcpodR54q5aLcLbw59WxiXa52+gSEEJ2RHJ3Yh8PT05g6OIejemShlKJ3XDyLdD2mUoxQ0ZQpi+S0lkWXHM4YoqNSqW72sra4lLNUIo87evGU2ZvuOMnAyZEBG6NxJ739Fn/9egnF9Q0HlUNrzX+XreRenckZRhLXqXQyvQbztua359sXQnRCUtat9rfcxp9OOob/OWu4xSjkN+RTb4LfV4UVaKKs4GP8zWUMSE7EBo5svSGvQynGGrHEY3K90Q0T+J3ZnaN90Tzy1aL9ZimorePpFat5duUafLZNXJv/THHaoNnqtHdWE0K0E5kGAV6cBdP2s31gSjIfXHwBuVVVJLjdBGybmz75fyxd9w+yE5J5dsrxxLpcDM9IZ15RLb82UvGi+cKu5WSVgB9NAI0DOFxF8fiOIhr9fqKdzh+81qaKSqa9+wFH2THYaFwo/qZKuUgnkae9fGs28vse2e31UQghOikp64MU43Iyos3NAeZMnfKDr3nghElc9d5cft2QT10gQCImBnCXVcAwFU08JnPsatyGwfLiEibuo3SfXLyc860EzjKSAEjCZGl0gP/oapKionh60qlkxce12/sUQnROUtZBlBYdzZsXns2O2joMBR/kbuXTLdvYXNXMJg0XWJtxooi2DX7sBmm1zV4y2DPizlIuiuOj+NfpJ7dbbq01723azDf5haTERHPlqGEkRckZJ0J0JlLWQeYwDPq0XvRyzeiRfFO4k1hM+uDiZiMTS2l+b+1gQ3kFK4pLKaito7C6FgM4LWcAx/TtxWuVa8jWLiw0M41qft13VLtm/teS5cxds6n1jJMqfrF1G29OPZs4954zTjaUVzBvaz5uh8nZhw0gPSa6XTMJIb5PDjC2ESgtDPo+vYEADhSXmWkkGQ5SlZNzjGSeWrKSNSu28EluHpMqTCZXOHlu0XKUAScPO4y7HMXc5yjhnJGDOW/QwKDn2kVrzfOr1nKPzuBUI5FrVBqZPoPP8rfv/polhTv51bsfULpyOxuWbeGCme8e9BktQojgkJF1qxfGzmDakulB3+85gw7j0bJFbLab6W+2TC1s1E301S6SMDnPSOIEo+W+w9Ha5Lm1G3n3l+dx3dj2HU3vogFLa6LVnkvmozHwW/buv/9z0bdMt1M5uvVmws8Gynh59Tp+O2Fsh2TsaGtKy5i1YTMOQ3HBkBxZ4F90CjKybmcXDj6MyTn9eVqX8aBVyO3WDlYYzUxQsRgofG3OGfRrG1P92Gx2+zCU4tS+vXlMlbBeNzHHrmYljUzqkbX7a+p9PtLVnp/radpBg9fXoTk7ypLCnUyfNRdjQxnN3xVz8Vuz2VRZFepYQsjIuiP88diJ/N/okSwsKMRtmgQsi38uWMoldhJP2qW4bUUCDl43qrjliO/f4XxTRSXLikvYUVPLtopqPA4H00YNY1i3tODlO34S/1j0LS/sKCIlJooXJk6hW2zM7u0n9OvNC2s3c52dRj0W7xk13N93RNBevzOZsXQFv7ZTOK71tx23bfDyyjX88fijQ5xMdHVS1h0kIzZm9w0KAJoCFi+uWEN0wM2KGE12nIe7cyZxQp89S65+tCWP+z9fQA/byQ7by5VGGvX4+U3hXJ45azJD0lKDks1lmvx24o8vLnXNmJF4LYv7N23BZZrcMGYsx/SKzLuTeAMW8ew5sBqPSYVfLkISoSdlvRerohgzJePAX/gzXTR0EBcNHbTfr/nj/K+5S2fwtF3GzUYGA5SHd+wqugVMHvt6Mc+dedru1f7ak2kY3DphLLdG6Bx1W1Ny+vPcNyvwaAOftnndqOK+nMNDHUsImbNuK+vma8G2Qh0DAFtrqv0++uJGAz5t8ztrBzVYnGjEU1hSzROLl4U6ZofQWvP2+k3cOGced3/2JTtqa9vttS4cksPFY4fzfEwtr8U38ttjxnNcr57t9npCHCwZWXdShlKMTkvnlYpKTlYJPKFL6Iub682W2ziN07FcuXot1x95xO57Pba34voGlheXEO92MT6rO2YH3aXk2RWreWv5d5xnJ7BTNXLRttm8NfXs782rB4tSikuHDeHSYUOCvm8hfg4p607ssVOP59a5n/JuWSmmAjd7Tq+LwsDWGlvrDinr5TtLuO6DeQxWURRrP5mpCfzn9FNwmu1f2C+tWsf9uhs9jZZbmVVYFh9s2cqvhsv0hOg6pKw7sdToKF4893RsrSlvbOLc199hTqCa/srNm6qak3r16rB78N33+QKusVKYYMRhac095TuZnbuZc3Pa74KdXWytcba5QN+JwrL3s0yiEBFI5qzbeGjhiP0ulRoqhlKkx0Tz/NmnsbabyTOxdQwYmM1DJ3bc6WQljY0Mbr3/pKkUAywXJQ2NHfLa5w8+jMdUKcvslhs/LDQaOKVf7w55bSE6CxlZh5EByUnMOGtySF57eHoa75RUc7lOoYIAC40GHgziud77c8ORRxDvcjEnbzvxHg/PjzuKHvHxHfLaQnQWUtYRpDkQ4M9ffcOC7QXEu1xMHzuSo3tm73Pd7EP10IlHc/2ceVxYtRUbzY2jj2BCdtaBnxgEhlJcMWoYV4wa1iGv92O2VFXz5OLl1DR7ObpPTy4ZNrhDTp0UAqSsI8r9ny+kJL+Uu3U6hV4fd8z7AlvB1aNGcM2YkdhaM2/rNorq6xmSlsrY7pkHve+06Gheu+As6n0+3KajQw4sdiZFdfVc+vb7nGPFMxIXr1esoaq5mRuOPCLU0UQXIWW9D4HSQhzpHTNqDKbP8rfzb92DJOUgW7k4SScQg8Hbq9YzOD2F99bnsrWwjBzbzYtqNZcfMYxfjTy0Myq66o16P9qaxzgdzblGMgC9bBe/X7teylp0mK41PDoIa2+aFeoIP5nHNKlgz6XRFQRIVg7G29HMy9vOmsIS/mx35yqVxiO6O08sXUaTXEp9UBTqewefbZApENGhpKwjyA3jRvOQKuZ1u4LHrJ1s1z4mEst600tFUxO2ZfOWrqJeW6TgwK1M6v0+Xlu7nmOef5Vxz7zMfZ8vwGf9vKs4LdtGd8bTan6GU/v1YYnZxEy7koV2HX9RJVx0+P6XCxAimGQaJIKcN2gg3eNieXfDJhZvzSfHEc0d7MQd7WJDYSmnEU+e9nKbvZ2jjThi3U7u/ORL1u0s5X6jOwk4+FtuAX91LOGOSeMP+fUrm5q4de5nLC0tJcZ0cMekcZx92IB2eKcdLyM2hlfOPZ2nlqxge7OXi/sO5xdDpKxFx5GyjjDjs7szPrs7v21sYnVpGXEuF9d9MI9HdRZZRst8852BHXzsaED5NDVFVZxnJNFXtdwY4QpSeWjT1p9U1rd//AUZ5T7eMvpToH3c+9Vi+iYmBnU511Dqk5jAIycfG+oYoouSaZC9fPt1cagjBEVqdBTH9+7J6MxueG2LxDaXqnd3uPHaNneTwRAVRYHecyOBQu0nYNv72uUBLS0p4Zck41CK3srNRB3D8uKSn/1ehBAyso54SilO7t2LJ7aXcZFOIl97+cZoQAGxmJxhJHKrtYM/WUUk4uALXUvPxHimz57LquJSPA4H00cP5+LDD7ywUbLbwxafl8OJxtaaPMPHBLlLuhBBISPrLuCB4yfRs18mj3kq+CTJz39OP4UzBvTjCaOMYvycp5JYohv4jiYwFAW19ZQWVvJ3enB3oBvPLl7JR1vyDvg69xx7FI+oEp5QpdxuFBGVHMvkfn074B0KEflkZN0FeBwO7jnuqO89NjQtlX85lzFj23ainU4u6j6IzNhYVu8sZfm2An5tptFNtVz5eI6dwJd52zmlX5/9vs4xvXrwynlnsGxnMYkeD8f16tnlLp4Ror1IWf8Iq6wQMy38Low5WE7T4OYJY7h5wpjvPX7t9o+Iw2Sn9u1euKlQ+0jyuA9qv/2SEukndwMXIuhk2LMPM6e81SlX3+sI43pmETDhGbuMGVYpj1o7+cJsYNoIWTtaiFCSkfU+NJZVhDpCyFwybAg76+p5dd165lDD8LRU3jv5tN13Zfls23Y+yc0j2uXk8pFDZfU7ITqIlLX4HkMpfj9xHL876kh06993eXv9Jp5YuJTz7QTKsbhoy2xmXnAW3eNiQxdYiC5Cylrsk1KKvVe+eGbZKm7T6QwyWuayGy2La+d8TGZ0NMf1680Fgw+T9TKEaCcyZ70fVllhqCN0KgHLJqrNt4zHVniqvYwv1rzwzQpmLF8VwnRCRDYp6x+RdfO1oY7Q6Zw1eAD/NMpYbTfyuV3LHF3Dr810jjLiuM1O57U160MdUYiIJdMg4qBdM3okbtPB67lbqfP7Gd4YTV/VckqfArTW5FXXUN3czIDkpC679rUQ7UHKWhw0QymuHDWMK0cNo6C2jqlvvMc7VhUZOPmfUUn3uFgueXMW6YaLChXgqTNOZXBqSqhjCxERZBpkP7rqudYHIzs+jhfPmcLOntF8ma4ZO7AX1TUNPKV78ZidxWX+JG7/+ItQxxQiYkhZ/4iHFo4IdYROb0ByEn899QRmnD2ZXgkJHG57iFYt31LjVSxba2u48t0PWFdWHuKkQoQ/KWsRFP2TE1luNFGrW+4y85mupTsuRpVqrpo1l4LauhAnFCK8yZy1CIqJPbI5bdAAfrNuPa5AyyjgfjOLnspNrvbyRf4OLjl88PeeU9Ps5aGvvmbh9kJchsnlI4dy+fChcq62EPsgI2sRNDdPGMP7vzwfnwPuM7rTs/VMkUalf7D63taqak5++XXWbCnkT3Z37gqk8+q3a5i1aUsoogvR6UlZH4BcGHNo0mOimT5qBI8Ypcy1q5mhy9ji8HNK3+8vr3r/ZwtIsgyuMNLIUi56KzcX2Il8sWVbaIIL0cnJNMh+rL1pFkMfPzPUMcLOlaOGkRkXw8JtBaREe3ht5DAS91pidUddHZk4KMa/+7Ei7SPOE9fRcYUIC1LW+/Fdrp+hoQ4RpqYM6MeUAf1+dPvg1BQoquUVu4Id2kcTNkvMJt4cfXwHphQifMg0iAiJe4+fSFG8iWEazKWGijQ37154jiy5KsSPkJG1CIm06GjevPBsdtY3EO1wkLSPG+vaWvPfb1fy/sbNuE2Tq8aMYHJ/uaej6JqkrEXIGEqRtZ+1sJ9evoqPVm/kBjuVem3x8Bdfk+BxMyE7i3qfjzs/mc+XBYXEOpzcOmEM5+QM7MD0QnQsKev96Mp3jOkMPtq0lSvtFPorDyg4x/Yxb3MeE7KzuO+zBVhFtbys+lBs+XlgwRJ6JMQzOjMj1LGFaBcyZy06LY/DQZUO7P57FRZRzpY7ri8qLOIynUy0MumrPJxgx/JNQVGoogrR7mRkLTqta8eN4ncffc4O20cdNl85Gnmt9SrIRLeb/EYfqcqJ1podZoAB+5j3FiJSSFkfBKusEDMtK9QxupyJPbL5zxmn8PHmPLo5TF4fnLN7jvv2o8fzu48/5yhiKTECNMQ4OOewASFOLET7kbI+gBfGzmDakumhjtFljeiWzohu6T94fFLPbF4693QWFRQR53IxuX8fPA75dhaRS767RdgakJzEgOSkUMcQokPIAUYhhAgDUtZCCBEGpKwPklVRHOoIQoguTMr6IOgHZ4BthTqGEKILk7IWQogwIGUthBBhQMpaCCHCgJT1QdI61AmEEF2ZlPVBeHFWqBOIjqK1ZkVxKXO35LG9pjbUcYTYTa5gFKKV1po/zv+a+Zu30dvw8J3dyP3HTeTkfn0O/GQh2pmUtRCtlhWX8OWWfP6hexBlG2zWzdz1+Vec2Lc3hlKhjie6OJkGOQRWWWGoI4h2VFzfQD/lJkq1/G/RX3kI2DYNPv8BnilE+5OyPkgzp7wlBxkj3ODUFFbbjWzTXgA+smtIj4om1uUMcTIhZBpEiN36JiVy59Hj+d38hZhakehx858pJ6NkCkR0AlLWQrRxxsD+nNqvL3U+L0kejxS16DSkrIXYi9M0SI6KCnUMIb5H5qyFECIMSFkfpMayCrJPGCVLpQohQkLKWgghwoCUtRBChAEpayGECANS1odIW3LHGCFEx5OyPgQP1l0d6ghCiC5KyloIIcKAlLUQQoQBKeufQFbfE0J0NCnrQ6QfnBHqCEKILkjKWgghwoCUtRBChAGl22FFfaVUGZAf9B0LIURk66W1TtvXhnYpayGEEMEl0yBCCBEGpKyFECIMSFkLIUQYkLIWEUUpZSmlViql1iql3lBKRbc+nqGUek0ptUUptUwp9YFSamDrtrlKqWql1PuhTS/Ej5OyFpGmSWs9Qms9FPABV6uWu96+A3yhte6ntT4CuAPo1vqcR4FLQxNXiIMjZS0i2VdAf+A4wK+1fmrXBq31Kq31V63//ilQF5qIQhwcKWsRkZRSDmAysAYYCiwLbSIhfh4paxFpopRSK4Fvge3AsyHOI0RQOEIdQIgga9Jaj2j7gFJqHXB+iPIIERQyshZdwWeAWyk1fdcDSqlhSqlJIcwkxCGRshYRT7esqXAOcGLrqXvrgD8BxQBKqa+AN4ATlFIFSqlTQpdWiH2TtUGEECIMyMhaCCHCgJS1EEKEASlrIYQIA1LWQggRBqSshRAiDEhZCyFEGJCyFkKIMPD/AcZtTZjrfT45AAAAAElFTkSuQmCC\n"},"metadata":{}}],"source":["params = linear_svm_classifier_pca.best_model.named_steps[linear_svm_classifier_pca.name].get_params()\n","\n","plot_2D_svm_decision_boundary(X_train, y_train, X_test, y_test, svm.SVC(**params), \n","                              features_pair=['DB','SGPT'], title=\"Linear SVC + PCA\", apply_PCA=True)"]},{"cell_type":"code","execution_count":355,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":62948,"status":"error","timestamp":1661109652627,"user":{"displayName":"Elisa C","userId":"11182657622104819579"},"user_tz":-120},"id":"x0i_0sk1uAyu","outputId":"cecfbef2-fa05-4439-b1fa-c43cb253d5aa"},"outputs":[{"output_type":"stream","name":"stdout","text":["Computing inner cross validation for grid search of best hyperparameters...\n","Fitting 5 folds for each of 7 candidates, totalling 35 fits\n","[CV 1/5] END ................LinearSVC__C=0.001;, score=0.261 total time=   0.0s\n","[CV 2/5] END ................LinearSVC__C=0.001;, score=0.356 total time=   0.0s\n","[CV 3/5] END ................LinearSVC__C=0.001;, score=0.182 total time=   0.0s\n","[CV 4/5] END ................LinearSVC__C=0.001;, score=0.232 total time=   0.0s\n","[CV 5/5] END ................LinearSVC__C=0.001;, score=0.185 total time=   0.0s\n","[CV 1/5] END .................LinearSVC__C=0.01;, score=0.637 total time=   0.0s\n","[CV 2/5] END .................LinearSVC__C=0.01;, score=0.558 total time=   0.0s\n","[CV 3/5] END .................LinearSVC__C=0.01;, score=0.421 total time=   0.0s\n","[CV 4/5] END .................LinearSVC__C=0.01;, score=0.506 total time=   0.0s\n","[CV 5/5] END .................LinearSVC__C=0.01;, score=0.487 total time=   0.0s\n","[CV 1/5] END ..................LinearSVC__C=0.1;, score=0.646 total time=   0.0s\n","[CV 2/5] END ..................LinearSVC__C=0.1;, score=0.600 total time=   0.0s\n","[CV 3/5] END ..................LinearSVC__C=0.1;, score=0.541 total time=   0.0s\n","[CV 4/5] END ..................LinearSVC__C=0.1;, score=0.584 total time=   0.0s\n","[CV 5/5] END ..................LinearSVC__C=0.1;, score=0.561 total time=   0.0s\n","[CV 1/5] END ....................LinearSVC__C=1;, score=0.687 total time=   0.0s\n","[CV 2/5] END ....................LinearSVC__C=1;, score=0.609 total time=   0.1s\n","[CV 3/5] END ....................LinearSVC__C=1;, score=0.609 total time=   0.0s\n","[CV 4/5] END ....................LinearSVC__C=1;, score=0.615 total time=   0.0s\n","[CV 5/5] END ....................LinearSVC__C=1;, score=0.644 total time=   0.0s\n","[CV 1/5] END ...................LinearSVC__C=10;, score=0.687 total time=   0.1s\n","[CV 2/5] END ...................LinearSVC__C=10;, score=0.600 total time=   0.1s\n","[CV 3/5] END ...................LinearSVC__C=10;, score=0.609 total time=   0.1s\n","[CV 4/5] END ...................LinearSVC__C=10;, score=0.645 total time=   0.1s\n","[CV 5/5] END ...................LinearSVC__C=10;, score=0.629 total time=   0.1s\n","[CV 1/5] END ..................LinearSVC__C=100;, score=0.673 total time=   0.2s\n","[CV 2/5] END ..................LinearSVC__C=100;, score=0.600 total time=   0.3s\n","[CV 3/5] END ..................LinearSVC__C=100;, score=0.609 total time=   0.3s\n","[CV 4/5] END ..................LinearSVC__C=100;, score=0.638 total time=   0.4s\n","[CV 5/5] END ..................LinearSVC__C=100;, score=0.622 total time=   0.3s\n","[CV 1/5] END .................LinearSVC__C=1000;, score=0.673 total time=   1.5s\n","[CV 2/5] END .................LinearSVC__C=1000;, score=0.600 total time=   2.2s\n","[CV 3/5] END .................LinearSVC__C=1000;, score=0.609 total time=   4.4s\n","[CV 4/5] END .................LinearSVC__C=1000;, score=0.638 total time=   3.5s\n","[CV 5/5] END .................LinearSVC__C=1000;, score=0.607 total time=   2.2s\n","\n","--------------------------------------------\n","\n","Inner CV (Hyperparameters and model selection): \n","  F1-score = 0.6339878225022495\n","  Best hyperparams = {'LinearSVC__C': 10}\n","Outer CV (Quality of model selection assessment): \n","  F1-score = 0.56\n","\n","--------------------------------------------\n","\n","Computing inner cross validation for grid search of best hyperparameters...\n","Fitting 5 folds for each of 7 candidates, totalling 35 fits\n","[CV 1/5] END ................LinearSVC__C=0.001;, score=0.235 total time=   0.1s\n","[CV 2/5] END ................LinearSVC__C=0.001;, score=0.421 total time=   0.1s\n","[CV 3/5] END ................LinearSVC__C=0.001;, score=0.209 total time=   0.1s\n","[CV 4/5] END ................LinearSVC__C=0.001;, score=0.282 total time=   0.1s\n","[CV 5/5] END ................LinearSVC__C=0.001;, score=0.378 total time=   0.1s\n","[CV 1/5] END .................LinearSVC__C=0.01;, score=0.500 total time=   0.1s\n","[CV 2/5] END .................LinearSVC__C=0.01;, score=0.614 total time=   0.1s\n","[CV 3/5] END .................LinearSVC__C=0.01;, score=0.378 total time=   0.1s\n","[CV 4/5] END .................LinearSVC__C=0.01;, score=0.494 total time=   0.1s\n","[CV 5/5] END .................LinearSVC__C=0.01;, score=0.598 total time=   0.1s\n","[CV 1/5] END ..................LinearSVC__C=0.1;, score=0.581 total time=   0.1s\n","[CV 2/5] END ..................LinearSVC__C=0.1;, score=0.607 total time=   0.1s\n","[CV 3/5] END ..................LinearSVC__C=0.1;, score=0.518 total time=   0.1s\n","[CV 4/5] END ..................LinearSVC__C=0.1;, score=0.600 total time=   0.1s\n","[CV 5/5] END ..................LinearSVC__C=0.1;, score=0.660 total time=   0.1s\n","[CV 1/5] END ....................LinearSVC__C=1;, score=0.591 total time=   0.1s\n","[CV 2/5] END ....................LinearSVC__C=1;, score=0.645 total time=   0.1s\n","[CV 3/5] END ....................LinearSVC__C=1;, score=0.512 total time=   0.1s\n","[CV 4/5] END ....................LinearSVC__C=1;, score=0.624 total time=   0.1s\n","[CV 5/5] END ....................LinearSVC__C=1;, score=0.699 total time=   0.1s\n","[CV 1/5] END ...................LinearSVC__C=10;, score=0.562 total time=   0.1s\n","[CV 2/5] END ...................LinearSVC__C=10;, score=0.660 total time=   0.2s\n","[CV 3/5] END ...................LinearSVC__C=10;, score=0.529 total time=   0.2s\n","[CV 4/5] END ...................LinearSVC__C=10;, score=0.609 total time=   0.2s\n","[CV 5/5] END ...................LinearSVC__C=10;, score=0.692 total time=   0.1s\n","[CV 1/5] END ..................LinearSVC__C=100;, score=0.578 total time=   0.6s\n","[CV 2/5] END ..................LinearSVC__C=100;, score=0.674 total time=   0.6s\n","[CV 3/5] END ..................LinearSVC__C=100;, score=0.545 total time=   0.4s\n","[CV 4/5] END ..................LinearSVC__C=100;, score=0.609 total time=   0.4s\n","[CV 5/5] END ..................LinearSVC__C=100;, score=0.667 total time=   0.4s\n","[CV 1/5] END .................LinearSVC__C=1000;, score=0.578 total time=   3.4s\n","[CV 2/5] END .................LinearSVC__C=1000;, score=0.674 total time=   1.4s\n","[CV 3/5] END .................LinearSVC__C=1000;, score=0.523 total time=   1.2s\n","[CV 4/5] END .................LinearSVC__C=1000;, score=0.609 total time=   2.6s\n","[CV 5/5] END .................LinearSVC__C=1000;, score=0.680 total time=   2.8s\n","\n","--------------------------------------------\n","\n","Inner CV (Hyperparameters and model selection): \n","  F1-score = 0.6144557705198437\n","  Best hyperparams = {'LinearSVC__C': 100}\n","Outer CV (Quality of model selection assessment): \n","  F1-score = 0.627450980392157\n","\n","--------------------------------------------\n","\n","Computing inner cross validation for grid search of best hyperparameters...\n","Fitting 5 folds for each of 7 candidates, totalling 35 fits\n","[CV 1/5] END ................LinearSVC__C=0.001;, score=0.306 total time=   0.1s\n","[CV 2/5] END ................LinearSVC__C=0.001;, score=0.154 total time=   0.1s\n","[CV 3/5] END ................LinearSVC__C=0.001;, score=0.356 total time=   0.1s\n","[CV 4/5] END ................LinearSVC__C=0.001;, score=0.436 total time=   0.1s\n","[CV 5/5] END ................LinearSVC__C=0.001;, score=0.156 total time=   0.1s\n","[CV 1/5] END .................LinearSVC__C=0.01;, score=0.609 total time=   0.1s\n","[CV 2/5] END .................LinearSVC__C=0.01;, score=0.541 total time=   0.1s\n","[CV 3/5] END .................LinearSVC__C=0.01;, score=0.524 total time=   0.1s\n","[CV 4/5] END .................LinearSVC__C=0.01;, score=0.681 total time=   0.1s\n","[CV 5/5] END .................LinearSVC__C=0.01;, score=0.487 total time=   0.1s\n","[CV 1/5] END ..................LinearSVC__C=0.1;, score=0.667 total time=   0.1s\n","[CV 2/5] END ..................LinearSVC__C=0.1;, score=0.596 total time=   0.1s\n","[CV 3/5] END ..................LinearSVC__C=0.1;, score=0.653 total time=   0.1s\n","[CV 4/5] END ..................LinearSVC__C=0.1;, score=0.687 total time=   0.1s\n","[CV 5/5] END ..................LinearSVC__C=0.1;, score=0.558 total time=   0.1s\n","[CV 1/5] END ....................LinearSVC__C=1;, score=0.680 total time=   0.1s\n","[CV 2/5] END ....................LinearSVC__C=1;, score=0.632 total time=   0.1s\n","[CV 3/5] END ....................LinearSVC__C=1;, score=0.630 total time=   0.0s\n","[CV 4/5] END ....................LinearSVC__C=1;, score=0.687 total time=   0.0s\n","[CV 5/5] END ....................LinearSVC__C=1;, score=0.545 total time=   0.0s\n","[CV 1/5] END ...................LinearSVC__C=10;, score=0.667 total time=   0.0s\n","[CV 2/5] END ...................LinearSVC__C=10;, score=0.589 total time=   0.0s\n","[CV 3/5] END ...................LinearSVC__C=10;, score=0.653 total time=   0.0s\n","[CV 4/5] END ...................LinearSVC__C=10;, score=0.680 total time=   0.1s\n","[CV 5/5] END ...................LinearSVC__C=10;, score=0.622 total time=   0.1s\n","[CV 1/5] END ..................LinearSVC__C=100;, score=0.667 total time=   0.2s\n","[CV 2/5] END ..................LinearSVC__C=100;, score=0.589 total time=   0.2s\n","[CV 3/5] END ..................LinearSVC__C=100;, score=0.653 total time=   0.4s\n","[CV 4/5] END ..................LinearSVC__C=100;, score=0.680 total time=   0.3s\n","[CV 5/5] END ..................LinearSVC__C=100;, score=0.622 total time=   0.4s\n","[CV 1/5] END .................LinearSVC__C=1000;, score=0.667 total time=   2.5s\n","[CV 2/5] END .................LinearSVC__C=1000;, score=0.589 total time=   1.1s\n","[CV 3/5] END .................LinearSVC__C=1000;, score=0.653 total time=   1.6s\n","[CV 4/5] END .................LinearSVC__C=1000;, score=0.680 total time=   1.4s\n","[CV 5/5] END .................LinearSVC__C=1000;, score=0.622 total time=   1.1s\n","\n","--------------------------------------------\n","\n","Inner CV (Hyperparameters and model selection): \n","  F1-score = 0.6422813046361608\n","  Best hyperparams = {'LinearSVC__C': 10}\n","Outer CV (Quality of model selection assessment): \n","  F1-score = 0.7272727272727274\n","\n","--------------------------------------------\n","\n","Computing inner cross validation for grid search of best hyperparameters...\n","Fitting 5 folds for each of 7 candidates, totalling 35 fits\n","[CV 1/5] END ................LinearSVC__C=0.001;, score=0.351 total time=   0.0s\n","[CV 2/5] END ................LinearSVC__C=0.001;, score=0.306 total time=   0.0s\n","[CV 3/5] END ................LinearSVC__C=0.001;, score=0.400 total time=   0.0s\n","[CV 4/5] END ................LinearSVC__C=0.001;, score=0.378 total time=   0.0s\n","[CV 5/5] END ................LinearSVC__C=0.001;, score=0.286 total time=   0.0s\n","[CV 1/5] END .................LinearSVC__C=0.01;, score=0.556 total time=   0.0s\n","[CV 2/5] END .................LinearSVC__C=0.01;, score=0.494 total time=   0.0s\n","[CV 3/5] END .................LinearSVC__C=0.01;, score=0.581 total time=   0.0s\n","[CV 4/5] END .................LinearSVC__C=0.01;, score=0.558 total time=   0.0s\n","[CV 5/5] END .................LinearSVC__C=0.01;, score=0.519 total time=   0.0s\n","[CV 1/5] END ..................LinearSVC__C=0.1;, score=0.617 total time=   0.0s\n","[CV 2/5] END ..................LinearSVC__C=0.1;, score=0.615 total time=   0.0s\n","[CV 3/5] END ..................LinearSVC__C=0.1;, score=0.591 total time=   0.0s\n","[CV 4/5] END ..................LinearSVC__C=0.1;, score=0.624 total time=   0.0s\n","[CV 5/5] END ..................LinearSVC__C=0.1;, score=0.524 total time=   0.0s\n","[CV 1/5] END ....................LinearSVC__C=1;, score=0.638 total time=   0.0s\n","[CV 2/5] END ....................LinearSVC__C=1;, score=0.630 total time=   0.0s\n","[CV 3/5] END ....................LinearSVC__C=1;, score=0.591 total time=   0.0s\n","[CV 4/5] END ....................LinearSVC__C=1;, score=0.667 total time=   0.0s\n","[CV 5/5] END ....................LinearSVC__C=1;, score=0.660 total time=   0.0s\n","[CV 1/5] END ...................LinearSVC__C=10;, score=0.625 total time=   0.1s\n","[CV 2/5] END ...................LinearSVC__C=10;, score=0.638 total time=   0.1s\n","[CV 3/5] END ...................LinearSVC__C=10;, score=0.615 total time=   0.1s\n","[CV 4/5] END ...................LinearSVC__C=10;, score=0.639 total time=   0.1s\n","[CV 5/5] END ...................LinearSVC__C=10;, score=0.660 total time=   0.1s\n","[CV 1/5] END ..................LinearSVC__C=100;, score=0.625 total time=   0.2s\n","[CV 2/5] END ..................LinearSVC__C=100;, score=0.617 total time=   0.2s\n","[CV 3/5] END ..................LinearSVC__C=100;, score=0.622 total time=   0.2s\n","[CV 4/5] END ..................LinearSVC__C=100;, score=0.611 total time=   0.3s\n","[CV 5/5] END ..................LinearSVC__C=100;, score=0.630 total time=   0.2s\n","[CV 1/5] END .................LinearSVC__C=1000;, score=0.625 total time=   1.2s\n","[CV 2/5] END .................LinearSVC__C=1000;, score=0.617 total time=   3.2s\n","[CV 3/5] END .................LinearSVC__C=1000;, score=0.622 total time=   1.8s\n","[CV 4/5] END .................LinearSVC__C=1000;, score=0.611 total time=   2.6s\n","[CV 5/5] END .................LinearSVC__C=1000;, score=0.630 total time=   2.1s\n","\n","--------------------------------------------\n","\n","Inner CV (Hyperparameters and model selection): \n","  F1-score = 0.637176576121997\n","  Best hyperparams = {'LinearSVC__C': 1}\n","Outer CV (Quality of model selection assessment): \n","  F1-score = 0.6122448979591837\n","\n","--------------------------------------------\n","\n","Computing inner cross validation for grid search of best hyperparameters...\n","Fitting 5 folds for each of 7 candidates, totalling 35 fits\n","[CV 1/5] END ................LinearSVC__C=0.001;, score=0.329 total time=   0.0s\n","[CV 2/5] END ................LinearSVC__C=0.001;, score=0.152 total time=   0.0s\n","[CV 3/5] END ................LinearSVC__C=0.001;, score=0.286 total time=   0.0s\n","[CV 4/5] END ................LinearSVC__C=0.001;, score=0.286 total time=   0.0s\n","[CV 5/5] END ................LinearSVC__C=0.001;, score=0.286 total time=   0.0s\n","[CV 1/5] END .................LinearSVC__C=0.01;, score=0.512 total time=   0.0s\n","[CV 2/5] END .................LinearSVC__C=0.01;, score=0.416 total time=   0.0s\n","[CV 3/5] END .................LinearSVC__C=0.01;, score=0.500 total time=   0.0s\n","[CV 4/5] END .................LinearSVC__C=0.01;, score=0.565 total time=   0.0s\n","[CV 5/5] END .................LinearSVC__C=0.01;, score=0.584 total time=   0.0s\n","[CV 1/5] END ..................LinearSVC__C=0.1;, score=0.591 total time=   0.0s\n","[CV 2/5] END ..................LinearSVC__C=0.1;, score=0.494 total time=   0.0s\n","[CV 3/5] END ..................LinearSVC__C=0.1;, score=0.621 total time=   0.0s\n","[CV 4/5] END ..................LinearSVC__C=0.1;, score=0.622 total time=   0.0s\n","[CV 5/5] END ..................LinearSVC__C=0.1;, score=0.600 total time=   0.1s\n","[CV 1/5] END ....................LinearSVC__C=1;, score=0.630 total time=   0.0s\n","[CV 2/5] END ....................LinearSVC__C=1;, score=0.541 total time=   0.0s\n","[CV 3/5] END ....................LinearSVC__C=1;, score=0.652 total time=   0.0s\n","[CV 4/5] END ....................LinearSVC__C=1;, score=0.667 total time=   0.0s\n","[CV 5/5] END ....................LinearSVC__C=1;, score=0.562 total time=   0.0s\n","[CV 1/5] END ...................LinearSVC__C=10;, score=0.624 total time=   0.1s\n","[CV 2/5] END ...................LinearSVC__C=10;, score=0.500 total time=   0.1s\n","[CV 3/5] END ...................LinearSVC__C=10;, score=0.681 total time=   0.1s\n","[CV 4/5] END ...................LinearSVC__C=10;, score=0.680 total time=   0.1s\n","[CV 5/5] END ...................LinearSVC__C=10;, score=0.602 total time=   0.1s\n","[CV 1/5] END ..................LinearSVC__C=100;, score=0.624 total time=   0.2s\n","[CV 2/5] END ..................LinearSVC__C=100;, score=0.500 total time=   0.2s\n","[CV 3/5] END ..................LinearSVC__C=100;, score=0.681 total time=   0.2s\n","[CV 4/5] END ..................LinearSVC__C=100;, score=0.680 total time=   0.2s\n","[CV 5/5] END ..................LinearSVC__C=100;, score=0.617 total time=   0.2s\n","[CV 1/5] END .................LinearSVC__C=1000;, score=0.624 total time=   1.4s\n","[CV 2/5] END .................LinearSVC__C=1000;, score=0.500 total time=   1.5s\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-355-a783e14c8667>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'GENERAL'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PERFORM_NCV'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0mlinear_svm_mean_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinear_svm_std_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_svm_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnested_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_PCA\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m   \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear_svm_classifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODELS_DIRPATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-325-9f3bef27b260>\u001b[0m in \u001b[0;36mnested_cv\u001b[0;34m(self, X, y, apply_PCA, num_components)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;31m# execute search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m         \u001b[0msearch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m         \u001b[0;31m# get the best performing model fit on the whole training set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0;31m# This model can then be used to make predictions on the holdout data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    889\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1390\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1392\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    849\u001b[0m                     )\n\u001b[1;32m    850\u001b[0m                     for (cand_idx, parameters), (split_idx, (train, test)) in product(\n\u001b[0;32m--> 851\u001b[0;31m                         \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    852\u001b[0m                     )\n\u001b[1;32m    853\u001b[0m                 )\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1047\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/imblearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    264\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"passthrough\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m                 \u001b[0mfit_params_last_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"i\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    331\u001b[0m             \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m             \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m             \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_seed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m         )\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["linear_svm_classifier = Classifier('LinearSVC', config_dict['CLASSIFICATION']['MODELS']['LinearSVC'], \n","                                   config_dict['CLASSIFICATION']['GENERAL'], \n","                                   config_dict['CLASSIFICATION']['PARAMS']['LinearSVC'], \n","                                   class_balancer, \n","                                   feature_scaler)\n","file_name = f'{linear_svm_classifier.name}.pkl'\n","\n","if config_dict['GENERAL']['PERFORM_NCV']:\n","  linear_svm_mean_score, linear_svm_std_score = linear_svm_classifier.nested_cv(X_train, y_train, apply_PCA=False)\n","  save(linear_svm_classifier, os.path.join(MODELS_DIRPATH, file_name))\n","else:\n","  linear_svm_classifier = load(os.path.join(MODELS_DIRPATH, file_name))\n","  linear_svm_classifier.print_nested_cv_results()\n","\n","classifiers.append((linear_svm_classifier, \"All features\"))\n","linear_svm_classifier.cv(X_train, X_test, y_train, y_test, apply_PCA=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":19,"status":"aborted","timestamp":1661109652628,"user":{"displayName":"Elisa C","userId":"11182657622104819579"},"user_tz":-120},"id":"y7C0UW7WvIFW"},"outputs":[],"source":["params = linear_svm_classifier.best_model.named_steps[linear_svm_classifier.name].get_params()\n","print(params)\n","\n","plot_2D_svm_decision_boundary(X_train, y_train, X_test, y_test, svm.SVC(**params), \n","                              features_pair=['DB','SGPT'], title=\"Linear SVC\", apply_PCA=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":20,"status":"aborted","timestamp":1661109652629,"user":{"displayName":"Elisa C","userId":"11182657622104819579"},"user_tz":-120},"id":"OqX0FOouQmVX"},"outputs":[],"source":["feature_scaler_red = ColumnTransformer(remainder='passthrough',\n","                                       transformers=[(\"standardscaler\", StandardScaler(), num_cols_without_duplicate)],\n","                                       verbose_feature_names_out=False)\n","\n","feature_scaler1 = clone(feature_scaler_red)\n","_ = feature_scaler1.fit_transform(X_train_reduced) # to retreive the categorical features indices (order of columns is modified by the scaler)\n","\n","#set categorical features indices\n","class_balancer_red = config_dict['CLASSIFICATION']['BALANCER']['SMOTENC'].set_params(categorical_features=[i for i, f in enumerate(feature_scaler1.get_feature_names_out()) if f in config_dict['GENERAL']['BOOLEAN_FEATURES']])\n","\n","linear_svm_classifier_red = Classifier('LinearSVC', \n","                                       config_dict['CLASSIFICATION']['MODELS']['LinearSVC'], \n","                                       config_dict['CLASSIFICATION']['GENERAL'], \n","                                       config_dict['CLASSIFICATION']['PARAMS']['LinearSVC'], \n","                                       class_balancer_red, \n","                                       feature_scaler_red)\n","file_name = f'{linear_svm_classifier_red.name}_red.pkl'\n","\n","if config_dict['GENERAL']['PERFORM_NCV']:\n","  linear_svm_red_mean_score, linear_svm_red_std_score = linear_svm_classifier_red.nested_cv(X_train_reduced, y_train, apply_PCA=False)\n","  save(linear_svm_classifier_red, os.path.join(MODELS_DIRPATH, file_name))\n","else:\n","  linear_svm_classifier_red = load(os.path.join(MODELS_DIRPATH, file_name))\n","  linear_svm_classifier_red.print_nested_cv_results()\n","\n","classifiers.append((linear_svm_classifier_red, \"Reduced features\"))\n","linear_svm_classifier_red.cv(X_train_reduced, X_test_reduced, y_train, y_test, apply_PCA=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d8b27YDSuK8C","executionInfo":{"status":"aborted","timestamp":1661109652629,"user_tz":-120,"elapsed":19,"user":{"displayName":"Elisa C","userId":"11182657622104819579"}}},"outputs":[],"source":["rbf_svm_classifier_pca = Classifier('RbfSVC', config_dict['CLASSIFICATION']['MODELS']['RbfSVC'], \n","                            config_dict['CLASSIFICATION']['GENERAL'], \n","                            config_dict['CLASSIFICATION']['PARAMS']['RbfSVC'], \n","                            class_balancer, \n","                            feature_scaler)\n","\n","file_name = f'{rbf_svm_classifier_pca.name}_PCA.pkl'\n","\n","if config_dict['GENERAL']['PERFORM_NCV']:\n","  rbf_svm_mean_score_pca, rbf_svm_std_score_pca = rbf_svm_classifier_pca.nested_cv(X_train, y_train, apply_PCA=True, num_components=num_components)\n","  save(rbf_svm_classifier_pca, os.path.join(MODELS_DIRPATH, file_name))\n","else:\n","  rbf_svm_classifier_pca = load(os.path.join(MODELS_DIRPATH, file_name))\n","  rbf_svm_classifier_pca.print_nested_cv_results()\n","\n","classifiers.append((rbf_svm_classifier_pca, \"PCA\"))\n","rbf_svm_classifier_pca.cv(X_train, X_test, y_train, y_test, apply_PCA=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Cw4ASHcovwjP","executionInfo":{"status":"aborted","timestamp":1661109652630,"user_tz":-120,"elapsed":20,"user":{"displayName":"Elisa C","userId":"11182657622104819579"}}},"outputs":[],"source":["params = rbf_svm_classifier_pca.best_model.named_steps[rbf_svm_classifier_pca.name].get_params()\n","print(params)\n","\n","plot_2D_svm_decision_boundary(X_train, y_train, X_test, y_test, svm.SVC(**params), \n","                              features_pair=['DB','SGPT'], title=\"Rbf SVC + PCA\", apply_PCA=True)"]},{"cell_type":"code","source":["rbf_svm_classifier = Classifier('RbfSVC', config_dict['CLASSIFICATION']['MODELS']['RbfSVC'], \n","                            config_dict['CLASSIFICATION']['GENERAL'], \n","                            config_dict['CLASSIFICATION']['PARAMS']['RbfSVC'], \n","                            class_balancer, \n","                            feature_scaler)\n","\n","file_name = f'{rbf_svm_classifier.name}.pkl'\n","\n","if config_dict['GENERAL']['PERFORM_NCV']:\n","  rbf_svm_mean_score, rbf_svm_std_score = rbf_svm_classifier.nested_cv(X_train, y_train, apply_PCA=False)\n","  save(rbf_svm_classifier, os.path.join(MODELS_DIRPATH, file_name))\n","else:\n","  rbf_svm_classifier = load(os.path.join(MODELS_DIRPATH, file_name))\n","  rbf_svm_classifier.print_nested_cv_results()\n","\n","classifiers.append((rbf_svm_classifier, \"All Features\"))\n","rbf_svm_classifier.cv(X_train, X_test, y_train, y_test, apply_PCA=False)"],"metadata":{"id":"4G_E2kx6WMLI","executionInfo":{"status":"aborted","timestamp":1661109652631,"user_tz":-120,"elapsed":21,"user":{"displayName":"Elisa C","userId":"11182657622104819579"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["params = rbf_svm_classifier.best_model.named_steps[rbf_svm_classifier.name].get_params()\n","\n","plot_2D_svm_decision_boundary(X_train, y_train, X_test, y_test, svm.SVC(**params), \n","                              features_pair=['DB','SGPT'], title=\"Rbf SVC\", apply_PCA=False)"],"metadata":{"id":"iwnrzf1jWXDD","executionInfo":{"status":"aborted","timestamp":1661109652631,"user_tz":-120,"elapsed":21,"user":{"displayName":"Elisa C","userId":"11182657622104819579"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vdb15YSkuT8z"},"source":["###KNN"]},{"cell_type":"code","source":["display(pd.DataFrame(config_dict['CLASSIFICATION']['PARAMS']['KNN'], columns = ['KNN__n_neighbors']).T)\n","display(pd.DataFrame(config_dict['CLASSIFICATION']['PARAMS']['KNN'], columns = ['KNN__weights']).T)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":144},"id":"y5VWUB-CH3m-","executionInfo":{"status":"ok","timestamp":1661109661286,"user_tz":-120,"elapsed":315,"user":{"displayName":"Elisa C","userId":"11182657622104819579"}},"outputId":"ed809fba-90a8-4608-a6cc-de8047638128"},"execution_count":356,"outputs":[{"output_type":"display_data","data":{"text/plain":["                  0   1   2   3   4   5   6   7   8   9   10  11\n","KNN__n_neighbors   1   3   5   7   9  11  13  15  17  19  21  23"],"text/html":["\n","  <div id=\"df-282ed3a8-0d5e-4ae2-a817-4f4b1c3a58f4\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>10</th>\n","      <th>11</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>KNN__n_neighbors</th>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>5</td>\n","      <td>7</td>\n","      <td>9</td>\n","      <td>11</td>\n","      <td>13</td>\n","      <td>15</td>\n","      <td>17</td>\n","      <td>19</td>\n","      <td>21</td>\n","      <td>23</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-282ed3a8-0d5e-4ae2-a817-4f4b1c3a58f4')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-282ed3a8-0d5e-4ae2-a817-4f4b1c3a58f4 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-282ed3a8-0d5e-4ae2-a817-4f4b1c3a58f4');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["                    0         1\n","KNN__weights  uniform  distance"],"text/html":["\n","  <div id=\"df-e7bc0a2e-91be-4a66-8eeb-67b6eab7a6ae\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>KNN__weights</th>\n","      <td>uniform</td>\n","      <td>distance</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e7bc0a2e-91be-4a66-8eeb-67b6eab7a6ae')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-e7bc0a2e-91be-4a66-8eeb-67b6eab7a6ae button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-e7bc0a2e-91be-4a66-8eeb-67b6eab7a6ae');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}]},{"cell_type":"code","execution_count":357,"metadata":{"id":"Zp-RNizBuQXT","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1661109709030,"user_tz":-120,"elapsed":45194,"user":{"displayName":"Elisa C","userId":"11182657622104819579"}},"outputId":"617878aa-66f9-4702-988c-38dbd45a9ae7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Computing inner cross validation for grid search of best hyperparameters...\n","Fitting 5 folds for each of 24 candidates, totalling 120 fits\n","[CV 1/5] END KNN__n_neighbors=1, KNN__weights=uniform;, score=0.660 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=1, KNN__weights=uniform;, score=0.748 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=1, KNN__weights=uniform;, score=0.761 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=1, KNN__weights=uniform;, score=0.746 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=1, KNN__weights=uniform;, score=0.727 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=1, KNN__weights=distance;, score=0.660 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=1, KNN__weights=distance;, score=0.748 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=1, KNN__weights=distance;, score=0.761 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=1, KNN__weights=distance;, score=0.746 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=1, KNN__weights=distance;, score=0.727 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=3, KNN__weights=uniform;, score=0.704 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=3, KNN__weights=uniform;, score=0.692 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=3, KNN__weights=uniform;, score=0.686 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=3, KNN__weights=uniform;, score=0.710 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=3, KNN__weights=uniform;, score=0.673 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=3, KNN__weights=distance;, score=0.692 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=3, KNN__weights=distance;, score=0.704 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=3, KNN__weights=distance;, score=0.698 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=3, KNN__weights=distance;, score=0.722 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=3, KNN__weights=distance;, score=0.698 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=5, KNN__weights=uniform;, score=0.654 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=5, KNN__weights=uniform;, score=0.704 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=5, KNN__weights=uniform;, score=0.686 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=5, KNN__weights=uniform;, score=0.626 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=5, KNN__weights=uniform;, score=0.692 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=5, KNN__weights=distance;, score=0.654 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=5, KNN__weights=distance;, score=0.709 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=5, KNN__weights=distance;, score=0.718 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=5, KNN__weights=distance;, score=0.653 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=5, KNN__weights=distance;, score=0.705 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=7, KNN__weights=uniform;, score=0.667 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=7, KNN__weights=uniform;, score=0.698 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=7, KNN__weights=uniform;, score=0.667 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=7, KNN__weights=uniform;, score=0.642 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=7, KNN__weights=uniform;, score=0.639 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=7, KNN__weights=distance;, score=0.667 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=7, KNN__weights=distance;, score=0.704 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=7, KNN__weights=distance;, score=0.686 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=7, KNN__weights=distance;, score=0.667 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=7, KNN__weights=distance;, score=0.699 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=9, KNN__weights=uniform;, score=0.654 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=9, KNN__weights=uniform;, score=0.614 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=9, KNN__weights=uniform;, score=0.611 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=9, KNN__weights=uniform;, score=0.602 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=9, KNN__weights=uniform;, score=0.619 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=9, KNN__weights=distance;, score=0.667 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=9, KNN__weights=distance;, score=0.621 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=9, KNN__weights=distance;, score=0.667 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=9, KNN__weights=distance;, score=0.588 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=9, KNN__weights=distance;, score=0.633 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=11, KNN__weights=uniform;, score=0.627 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=11, KNN__weights=uniform;, score=0.673 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=11, KNN__weights=uniform;, score=0.625 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=11, KNN__weights=uniform;, score=0.608 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=11, KNN__weights=uniform;, score=0.626 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=11, KNN__weights=distance;, score=0.634 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=11, KNN__weights=distance;, score=0.654 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=11, KNN__weights=distance;, score=0.673 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=11, KNN__weights=distance;, score=0.621 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=11, KNN__weights=distance;, score=0.667 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=13, KNN__weights=uniform;, score=0.647 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=13, KNN__weights=uniform;, score=0.640 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=13, KNN__weights=uniform;, score=0.596 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=13, KNN__weights=uniform;, score=0.620 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=13, KNN__weights=uniform;, score=0.617 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=13, KNN__weights=distance;, score=0.647 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=13, KNN__weights=distance;, score=0.647 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=13, KNN__weights=distance;, score=0.646 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=13, KNN__weights=distance;, score=0.647 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=13, KNN__weights=distance;, score=0.632 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=15, KNN__weights=uniform;, score=0.667 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=15, KNN__weights=uniform;, score=0.633 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=15, KNN__weights=uniform;, score=0.624 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=15, KNN__weights=uniform;, score=0.586 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=15, KNN__weights=uniform;, score=0.667 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=15, KNN__weights=distance;, score=0.640 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=15, KNN__weights=distance;, score=0.640 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=15, KNN__weights=distance;, score=0.667 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=15, KNN__weights=distance;, score=0.627 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=15, KNN__weights=distance;, score=0.680 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=17, KNN__weights=uniform;, score=0.660 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=17, KNN__weights=uniform;, score=0.598 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=17, KNN__weights=uniform;, score=0.615 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=17, KNN__weights=uniform;, score=0.614 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=17, KNN__weights=uniform;, score=0.674 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=17, KNN__weights=distance;, score=0.667 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=17, KNN__weights=distance;, score=0.626 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=17, KNN__weights=distance;, score=0.667 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=17, KNN__weights=distance;, score=0.627 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=17, KNN__weights=distance;, score=0.695 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=19, KNN__weights=uniform;, score=0.633 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=19, KNN__weights=uniform;, score=0.612 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=19, KNN__weights=uniform;, score=0.584 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=19, KNN__weights=uniform;, score=0.620 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=19, KNN__weights=uniform;, score=0.667 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=19, KNN__weights=distance;, score=0.646 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=19, KNN__weights=distance;, score=0.612 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=19, KNN__weights=distance;, score=0.624 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=19, KNN__weights=distance;, score=0.620 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=19, KNN__weights=distance;, score=0.701 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=21, KNN__weights=uniform;, score=0.633 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=21, KNN__weights=uniform;, score=0.626 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=21, KNN__weights=uniform;, score=0.581 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=21, KNN__weights=uniform;, score=0.606 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=21, KNN__weights=uniform;, score=0.687 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=21, KNN__weights=distance;, score=0.640 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=21, KNN__weights=distance;, score=0.640 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=21, KNN__weights=distance;, score=0.630 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=21, KNN__weights=distance;, score=0.634 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=21, KNN__weights=distance;, score=0.708 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=23, KNN__weights=uniform;, score=0.611 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=23, KNN__weights=uniform;, score=0.598 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=23, KNN__weights=uniform;, score=0.622 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=23, KNN__weights=uniform;, score=0.598 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=23, KNN__weights=uniform;, score=0.660 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=23, KNN__weights=distance;, score=0.633 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=23, KNN__weights=distance;, score=0.640 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=23, KNN__weights=distance;, score=0.667 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=23, KNN__weights=distance;, score=0.612 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=23, KNN__weights=distance;, score=0.681 total time=   0.0s\n","\n","--------------------------------------------\n","\n","Inner CV (Hyperparameters and model selection): \n","  F1-score = 0.7284601662973754\n","  Best hyperparams = {'KNN__n_neighbors': 1, 'KNN__weights': 'uniform'}\n","Outer CV (Quality of model selection assessment): \n","  F1-score = 0.6875\n","\n","--------------------------------------------\n","\n","Computing inner cross validation for grid search of best hyperparameters...\n","Fitting 5 folds for each of 24 candidates, totalling 120 fits\n","[CV 1/5] END KNN__n_neighbors=1, KNN__weights=uniform;, score=0.719 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=1, KNN__weights=uniform;, score=0.727 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=1, KNN__weights=uniform;, score=0.698 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=1, KNN__weights=uniform;, score=0.723 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=1, KNN__weights=uniform;, score=0.703 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=1, KNN__weights=distance;, score=0.719 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=1, KNN__weights=distance;, score=0.727 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=1, KNN__weights=distance;, score=0.698 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=1, KNN__weights=distance;, score=0.723 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=1, KNN__weights=distance;, score=0.703 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=3, KNN__weights=uniform;, score=0.732 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=3, KNN__weights=uniform;, score=0.718 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=3, KNN__weights=uniform;, score=0.660 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=3, KNN__weights=uniform;, score=0.703 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=3, KNN__weights=uniform;, score=0.673 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=3, KNN__weights=distance;, score=0.732 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=3, KNN__weights=distance;, score=0.718 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=3, KNN__weights=distance;, score=0.673 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=3, KNN__weights=distance;, score=0.714 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=3, KNN__weights=distance;, score=0.673 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=5, KNN__weights=uniform;, score=0.654 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=5, KNN__weights=uniform;, score=0.684 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=5, KNN__weights=uniform;, score=0.686 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=5, KNN__weights=uniform;, score=0.727 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=5, KNN__weights=uniform;, score=0.660 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=5, KNN__weights=distance;, score=0.685 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=5, KNN__weights=distance;, score=0.707 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=5, KNN__weights=distance;, score=0.705 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=5, KNN__weights=distance;, score=0.743 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=5, KNN__weights=distance;, score=0.646 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=7, KNN__weights=uniform;, score=0.679 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=7, KNN__weights=uniform;, score=0.661 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=7, KNN__weights=uniform;, score=0.617 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=7, KNN__weights=uniform;, score=0.667 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=7, KNN__weights=uniform;, score=0.640 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=7, KNN__weights=distance;, score=0.704 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=7, KNN__weights=distance;, score=0.661 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=7, KNN__weights=distance;, score=0.639 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=7, KNN__weights=distance;, score=0.704 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=7, KNN__weights=distance;, score=0.626 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=9, KNN__weights=uniform;, score=0.654 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=9, KNN__weights=uniform;, score=0.667 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=9, KNN__weights=uniform;, score=0.587 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=9, KNN__weights=uniform;, score=0.680 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=9, KNN__weights=uniform;, score=0.640 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=9, KNN__weights=distance;, score=0.698 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=9, KNN__weights=distance;, score=0.673 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=9, KNN__weights=distance;, score=0.625 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=9, KNN__weights=distance;, score=0.729 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=9, KNN__weights=distance;, score=0.640 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=11, KNN__weights=uniform;, score=0.667 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=11, KNN__weights=uniform;, score=0.642 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=11, KNN__weights=uniform;, score=0.549 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=11, KNN__weights=uniform;, score=0.660 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=11, KNN__weights=uniform;, score=0.553 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=11, KNN__weights=distance;, score=0.710 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=11, KNN__weights=distance;, score=0.667 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=11, KNN__weights=distance;, score=0.589 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=11, KNN__weights=distance;, score=0.699 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=11, KNN__weights=distance;, score=0.620 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=13, KNN__weights=uniform;, score=0.646 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=13, KNN__weights=uniform;, score=0.630 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=13, KNN__weights=uniform;, score=0.545 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=13, KNN__weights=uniform;, score=0.653 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=13, KNN__weights=uniform;, score=0.527 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=13, KNN__weights=distance;, score=0.699 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=13, KNN__weights=distance;, score=0.642 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=13, KNN__weights=distance;, score=0.571 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=13, KNN__weights=distance;, score=0.680 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=13, KNN__weights=distance;, score=0.553 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=15, KNN__weights=uniform;, score=0.619 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=15, KNN__weights=uniform;, score=0.623 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=15, KNN__weights=uniform;, score=0.558 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=15, KNN__weights=uniform;, score=0.673 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=15, KNN__weights=uniform;, score=0.527 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=15, KNN__weights=distance;, score=0.646 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=15, KNN__weights=distance;, score=0.642 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=15, KNN__weights=distance;, score=0.562 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=15, KNN__weights=distance;, score=0.699 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=15, KNN__weights=distance;, score=0.538 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=17, KNN__weights=uniform;, score=0.596 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=17, KNN__weights=uniform;, score=0.623 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=17, KNN__weights=uniform;, score=0.575 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=17, KNN__weights=uniform;, score=0.619 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=17, KNN__weights=uniform;, score=0.527 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=17, KNN__weights=distance;, score=0.673 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=17, KNN__weights=distance;, score=0.630 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=17, KNN__weights=distance;, score=0.552 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=17, KNN__weights=distance;, score=0.646 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=17, KNN__weights=distance;, score=0.543 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=19, KNN__weights=uniform;, score=0.587 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=19, KNN__weights=uniform;, score=0.610 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=19, KNN__weights=uniform;, score=0.575 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=19, KNN__weights=uniform;, score=0.611 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=19, KNN__weights=uniform;, score=0.565 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=19, KNN__weights=distance;, score=0.638 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=19, KNN__weights=distance;, score=0.648 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=19, KNN__weights=distance;, score=0.568 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=19, KNN__weights=distance;, score=0.639 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=19, KNN__weights=distance;, score=0.559 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=21, KNN__weights=uniform;, score=0.617 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=21, KNN__weights=uniform;, score=0.636 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=21, KNN__weights=uniform;, score=0.558 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=21, KNN__weights=uniform;, score=0.639 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=21, KNN__weights=uniform;, score=0.574 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=21, KNN__weights=distance;, score=0.617 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=21, KNN__weights=distance;, score=0.661 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=21, KNN__weights=distance;, score=0.552 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=21, KNN__weights=distance;, score=0.653 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=21, KNN__weights=distance;, score=0.549 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=23, KNN__weights=uniform;, score=0.611 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=23, KNN__weights=uniform;, score=0.636 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=23, KNN__weights=uniform;, score=0.575 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=23, KNN__weights=uniform;, score=0.587 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=23, KNN__weights=uniform;, score=0.549 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=23, KNN__weights=distance;, score=0.617 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=23, KNN__weights=distance;, score=0.661 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=23, KNN__weights=distance;, score=0.584 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=23, KNN__weights=distance;, score=0.639 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=23, KNN__weights=distance;, score=0.565 total time=   0.0s\n","\n","--------------------------------------------\n","\n","Inner CV (Hyperparameters and model selection): \n","  F1-score = 0.7140151917533775\n","  Best hyperparams = {'KNN__n_neighbors': 1, 'KNN__weights': 'uniform'}\n","Outer CV (Quality of model selection assessment): \n","  F1-score = 0.8125\n","\n","--------------------------------------------\n","\n","Computing inner cross validation for grid search of best hyperparameters...\n","Fitting 5 folds for each of 24 candidates, totalling 120 fits\n","[CV 1/5] END KNN__n_neighbors=1, KNN__weights=uniform;, score=0.726 total time=   0.1s\n","[CV 2/5] END KNN__n_neighbors=1, KNN__weights=uniform;, score=0.786 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=1, KNN__weights=uniform;, score=0.759 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=1, KNN__weights=uniform;, score=0.746 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=1, KNN__weights=uniform;, score=0.754 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=1, KNN__weights=distance;, score=0.726 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=1, KNN__weights=distance;, score=0.786 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=1, KNN__weights=distance;, score=0.759 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=1, KNN__weights=distance;, score=0.746 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=1, KNN__weights=distance;, score=0.754 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=3, KNN__weights=uniform;, score=0.691 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=3, KNN__weights=uniform;, score=0.739 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=3, KNN__weights=uniform;, score=0.743 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=3, KNN__weights=uniform;, score=0.726 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=3, KNN__weights=uniform;, score=0.712 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=3, KNN__weights=distance;, score=0.703 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=3, KNN__weights=distance;, score=0.750 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=3, KNN__weights=distance;, score=0.743 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=3, KNN__weights=distance;, score=0.726 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=3, KNN__weights=distance;, score=0.736 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=5, KNN__weights=uniform;, score=0.734 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=5, KNN__weights=uniform;, score=0.703 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=5, KNN__weights=uniform;, score=0.722 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=5, KNN__weights=uniform;, score=0.721 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=5, KNN__weights=uniform;, score=0.724 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=5, KNN__weights=distance;, score=0.745 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=5, KNN__weights=distance;, score=0.703 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=5, KNN__weights=distance;, score=0.727 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=5, KNN__weights=distance;, score=0.727 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=5, KNN__weights=distance;, score=0.743 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=7, KNN__weights=uniform;, score=0.667 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=7, KNN__weights=uniform;, score=0.617 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=7, KNN__weights=uniform;, score=0.654 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=7, KNN__weights=uniform;, score=0.745 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=7, KNN__weights=uniform;, score=0.706 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=7, KNN__weights=distance;, score=0.692 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=7, KNN__weights=distance;, score=0.648 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=7, KNN__weights=distance;, score=0.660 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=7, KNN__weights=distance;, score=0.757 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=7, KNN__weights=distance;, score=0.725 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=9, KNN__weights=uniform;, score=0.620 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=9, KNN__weights=uniform;, score=0.617 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=9, KNN__weights=uniform;, score=0.647 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=9, KNN__weights=uniform;, score=0.712 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=9, KNN__weights=uniform;, score=0.693 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=9, KNN__weights=distance;, score=0.667 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=9, KNN__weights=distance;, score=0.636 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=9, KNN__weights=distance;, score=0.641 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=9, KNN__weights=distance;, score=0.736 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=9, KNN__weights=distance;, score=0.706 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=11, KNN__weights=uniform;, score=0.606 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=11, KNN__weights=uniform;, score=0.615 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=11, KNN__weights=uniform;, score=0.698 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=11, KNN__weights=uniform;, score=0.686 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=11, KNN__weights=uniform;, score=0.680 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=11, KNN__weights=distance;, score=0.660 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=11, KNN__weights=distance;, score=0.635 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=11, KNN__weights=distance;, score=0.685 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=11, KNN__weights=distance;, score=0.705 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=11, KNN__weights=distance;, score=0.713 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=13, KNN__weights=uniform;, score=0.620 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=13, KNN__weights=uniform;, score=0.594 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=13, KNN__weights=uniform;, score=0.673 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=13, KNN__weights=uniform;, score=0.693 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=13, KNN__weights=uniform;, score=0.680 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=13, KNN__weights=distance;, score=0.660 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=13, KNN__weights=distance;, score=0.600 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=13, KNN__weights=distance;, score=0.667 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=13, KNN__weights=distance;, score=0.686 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=13, KNN__weights=distance;, score=0.700 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=15, KNN__weights=uniform;, score=0.653 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=15, KNN__weights=uniform;, score=0.592 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=15, KNN__weights=uniform;, score=0.673 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=15, KNN__weights=uniform;, score=0.693 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=15, KNN__weights=uniform;, score=0.660 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=15, KNN__weights=distance;, score=0.680 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=15, KNN__weights=distance;, score=0.626 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=15, KNN__weights=distance;, score=0.667 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=15, KNN__weights=distance;, score=0.693 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=15, KNN__weights=distance;, score=0.674 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=17, KNN__weights=uniform;, score=0.619 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=17, KNN__weights=uniform;, score=0.600 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=17, KNN__weights=uniform;, score=0.660 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=17, KNN__weights=uniform;, score=0.667 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=17, KNN__weights=uniform;, score=0.607 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=17, KNN__weights=distance;, score=0.653 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=17, KNN__weights=distance;, score=0.606 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=17, KNN__weights=distance;, score=0.667 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=17, KNN__weights=distance;, score=0.680 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=17, KNN__weights=distance;, score=0.645 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=19, KNN__weights=uniform;, score=0.626 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=19, KNN__weights=uniform;, score=0.608 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=19, KNN__weights=uniform;, score=0.686 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=19, KNN__weights=uniform;, score=0.706 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=19, KNN__weights=uniform;, score=0.591 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=19, KNN__weights=distance;, score=0.660 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=19, KNN__weights=distance;, score=0.614 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=19, KNN__weights=distance;, score=0.686 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=19, KNN__weights=distance;, score=0.706 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=19, KNN__weights=distance;, score=0.674 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=21, KNN__weights=uniform;, score=0.646 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=21, KNN__weights=uniform;, score=0.586 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=21, KNN__weights=uniform;, score=0.686 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=21, KNN__weights=uniform;, score=0.680 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=21, KNN__weights=uniform;, score=0.637 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=21, KNN__weights=distance;, score=0.673 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=21, KNN__weights=distance;, score=0.606 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=21, KNN__weights=distance;, score=0.686 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=21, KNN__weights=distance;, score=0.680 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=21, KNN__weights=distance;, score=0.637 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=23, KNN__weights=uniform;, score=0.611 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=23, KNN__weights=uniform;, score=0.606 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=23, KNN__weights=uniform;, score=0.646 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=23, KNN__weights=uniform;, score=0.699 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=23, KNN__weights=uniform;, score=0.637 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=23, KNN__weights=distance;, score=0.660 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=23, KNN__weights=distance;, score=0.592 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=23, KNN__weights=distance;, score=0.660 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=23, KNN__weights=distance;, score=0.680 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=23, KNN__weights=distance;, score=0.659 total time=   0.0s\n","\n","--------------------------------------------\n","\n","Inner CV (Hyperparameters and model selection): \n","  F1-score = 0.7541515739141611\n","  Best hyperparams = {'KNN__n_neighbors': 1, 'KNN__weights': 'uniform'}\n","Outer CV (Quality of model selection assessment): \n","  F1-score = 0.7384615384615385\n","\n","--------------------------------------------\n","\n","Computing inner cross validation for grid search of best hyperparameters...\n","Fitting 5 folds for each of 24 candidates, totalling 120 fits\n","[CV 1/5] END KNN__n_neighbors=1, KNN__weights=uniform;, score=0.743 total time=   0.1s\n","[CV 2/5] END KNN__n_neighbors=1, KNN__weights=uniform;, score=0.746 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=1, KNN__weights=uniform;, score=0.752 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=1, KNN__weights=uniform;, score=0.759 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=1, KNN__weights=uniform;, score=0.690 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=1, KNN__weights=distance;, score=0.743 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=1, KNN__weights=distance;, score=0.746 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=1, KNN__weights=distance;, score=0.752 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=1, KNN__weights=distance;, score=0.759 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=1, KNN__weights=distance;, score=0.690 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=3, KNN__weights=uniform;, score=0.732 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=3, KNN__weights=uniform;, score=0.649 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=3, KNN__weights=uniform;, score=0.680 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=3, KNN__weights=uniform;, score=0.726 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=3, KNN__weights=uniform;, score=0.661 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=3, KNN__weights=distance;, score=0.765 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=3, KNN__weights=distance;, score=0.661 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=3, KNN__weights=distance;, score=0.680 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=3, KNN__weights=distance;, score=0.719 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=3, KNN__weights=distance;, score=0.655 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=5, KNN__weights=uniform;, score=0.635 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=5, KNN__weights=uniform;, score=0.704 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=5, KNN__weights=uniform;, score=0.700 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=5, KNN__weights=uniform;, score=0.692 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=5, KNN__weights=uniform;, score=0.660 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=5, KNN__weights=distance;, score=0.654 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=5, KNN__weights=distance;, score=0.716 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=5, KNN__weights=distance;, score=0.700 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=5, KNN__weights=distance;, score=0.704 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=5, KNN__weights=distance;, score=0.654 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=7, KNN__weights=uniform;, score=0.673 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=7, KNN__weights=uniform;, score=0.667 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=7, KNN__weights=uniform;, score=0.673 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=7, KNN__weights=uniform;, score=0.692 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=7, KNN__weights=uniform;, score=0.673 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=7, KNN__weights=distance;, score=0.685 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=7, KNN__weights=distance;, score=0.706 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=7, KNN__weights=distance;, score=0.673 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=7, KNN__weights=distance;, score=0.698 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=7, KNN__weights=distance;, score=0.673 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=9, KNN__weights=uniform;, score=0.592 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=9, KNN__weights=uniform;, score=0.633 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=9, KNN__weights=uniform;, score=0.693 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=9, KNN__weights=uniform;, score=0.639 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=9, KNN__weights=uniform;, score=0.660 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=9, KNN__weights=distance;, score=0.627 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=9, KNN__weights=distance;, score=0.667 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=9, KNN__weights=distance;, score=0.713 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=9, KNN__weights=distance;, score=0.653 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=9, KNN__weights=distance;, score=0.673 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=11, KNN__weights=uniform;, score=0.604 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=11, KNN__weights=uniform;, score=0.660 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=11, KNN__weights=uniform;, score=0.693 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=11, KNN__weights=uniform;, score=0.673 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=11, KNN__weights=uniform;, score=0.634 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=11, KNN__weights=distance;, score=0.634 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=11, KNN__weights=distance;, score=0.653 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=11, KNN__weights=distance;, score=0.713 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=11, KNN__weights=distance;, score=0.686 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=11, KNN__weights=distance;, score=0.660 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=13, KNN__weights=uniform;, score=0.619 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=13, KNN__weights=uniform;, score=0.646 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=13, KNN__weights=uniform;, score=0.699 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=13, KNN__weights=uniform;, score=0.673 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=13, KNN__weights=uniform;, score=0.620 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=13, KNN__weights=distance;, score=0.626 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=13, KNN__weights=distance;, score=0.660 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=13, KNN__weights=distance;, score=0.718 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=13, KNN__weights=distance;, score=0.680 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=13, KNN__weights=distance;, score=0.634 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=15, KNN__weights=uniform;, score=0.619 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=15, KNN__weights=uniform;, score=0.617 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=15, KNN__weights=uniform;, score=0.738 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=15, KNN__weights=uniform;, score=0.653 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=15, KNN__weights=uniform;, score=0.606 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=15, KNN__weights=distance;, score=0.640 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=15, KNN__weights=distance;, score=0.625 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=15, KNN__weights=distance;, score=0.738 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=15, KNN__weights=distance;, score=0.673 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=15, KNN__weights=distance;, score=0.634 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=17, KNN__weights=uniform;, score=0.583 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=17, KNN__weights=uniform;, score=0.596 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=17, KNN__weights=uniform;, score=0.724 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=17, KNN__weights=uniform;, score=0.660 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=17, KNN__weights=uniform;, score=0.598 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=17, KNN__weights=distance;, score=0.598 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=17, KNN__weights=distance;, score=0.619 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=17, KNN__weights=distance;, score=0.725 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=17, KNN__weights=distance;, score=0.693 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=17, KNN__weights=distance;, score=0.634 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=19, KNN__weights=uniform;, score=0.583 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=19, KNN__weights=uniform;, score=0.581 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=19, KNN__weights=uniform;, score=0.724 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=19, KNN__weights=uniform;, score=0.687 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=19, KNN__weights=uniform;, score=0.619 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=19, KNN__weights=distance;, score=0.598 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=19, KNN__weights=distance;, score=0.611 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=19, KNN__weights=distance;, score=0.725 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=19, KNN__weights=distance;, score=0.687 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=19, KNN__weights=distance;, score=0.620 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=21, KNN__weights=uniform;, score=0.589 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=21, KNN__weights=uniform;, score=0.549 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=21, KNN__weights=uniform;, score=0.724 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=21, KNN__weights=uniform;, score=0.673 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=21, KNN__weights=uniform;, score=0.581 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=21, KNN__weights=distance;, score=0.626 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=21, KNN__weights=distance;, score=0.587 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=21, KNN__weights=distance;, score=0.738 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=21, KNN__weights=distance;, score=0.694 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=21, KNN__weights=distance;, score=0.611 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=23, KNN__weights=uniform;, score=0.589 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=23, KNN__weights=uniform;, score=0.558 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=23, KNN__weights=uniform;, score=0.738 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=23, KNN__weights=uniform;, score=0.687 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=23, KNN__weights=uniform;, score=0.565 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=23, KNN__weights=distance;, score=0.612 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=23, KNN__weights=distance;, score=0.587 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=23, KNN__weights=distance;, score=0.725 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=23, KNN__weights=distance;, score=0.694 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=23, KNN__weights=distance;, score=0.604 total time=   0.0s\n","\n","--------------------------------------------\n","\n","Inner CV (Hyperparameters and model selection): \n","  F1-score = 0.7380610596170603\n","  Best hyperparams = {'KNN__n_neighbors': 1, 'KNN__weights': 'uniform'}\n","Outer CV (Quality of model selection assessment): \n","  F1-score = 0.7272727272727273\n","\n","--------------------------------------------\n","\n","Computing inner cross validation for grid search of best hyperparameters...\n","Fitting 5 folds for each of 24 candidates, totalling 120 fits\n","[CV 1/5] END KNN__n_neighbors=1, KNN__weights=uniform;, score=0.760 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=1, KNN__weights=uniform;, score=0.780 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=1, KNN__weights=uniform;, score=0.716 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=1, KNN__weights=uniform;, score=0.741 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=1, KNN__weights=uniform;, score=0.709 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=1, KNN__weights=distance;, score=0.760 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=1, KNN__weights=distance;, score=0.780 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=1, KNN__weights=distance;, score=0.716 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=1, KNN__weights=distance;, score=0.741 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=1, KNN__weights=distance;, score=0.709 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=3, KNN__weights=uniform;, score=0.739 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=3, KNN__weights=uniform;, score=0.654 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=3, KNN__weights=uniform;, score=0.654 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=3, KNN__weights=uniform;, score=0.667 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=3, KNN__weights=uniform;, score=0.685 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=3, KNN__weights=distance;, score=0.739 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=3, KNN__weights=distance;, score=0.654 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=3, KNN__weights=distance;, score=0.660 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=3, KNN__weights=distance;, score=0.692 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=3, KNN__weights=distance;, score=0.716 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=5, KNN__weights=uniform;, score=0.703 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=5, KNN__weights=uniform;, score=0.627 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=5, KNN__weights=uniform;, score=0.619 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=5, KNN__weights=uniform;, score=0.679 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=5, KNN__weights=uniform;, score=0.686 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=5, KNN__weights=distance;, score=0.703 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=5, KNN__weights=distance;, score=0.627 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=5, KNN__weights=distance;, score=0.633 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=5, KNN__weights=distance;, score=0.697 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=5, KNN__weights=distance;, score=0.686 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=7, KNN__weights=uniform;, score=0.745 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=7, KNN__weights=uniform;, score=0.586 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=7, KNN__weights=uniform;, score=0.596 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=7, KNN__weights=uniform;, score=0.647 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=7, KNN__weights=uniform;, score=0.667 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=7, KNN__weights=distance;, score=0.745 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=7, KNN__weights=distance;, score=0.588 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=7, KNN__weights=distance;, score=0.625 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=7, KNN__weights=distance;, score=0.685 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=7, KNN__weights=distance;, score=0.692 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=9, KNN__weights=uniform;, score=0.729 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=9, KNN__weights=uniform;, score=0.612 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=9, KNN__weights=uniform;, score=0.625 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=9, KNN__weights=uniform;, score=0.611 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=9, KNN__weights=uniform;, score=0.660 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=9, KNN__weights=distance;, score=0.729 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=9, KNN__weights=distance;, score=0.620 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=9, KNN__weights=distance;, score=0.632 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=9, KNN__weights=distance;, score=0.620 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=9, KNN__weights=distance;, score=0.692 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=11, KNN__weights=uniform;, score=0.717 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=11, KNN__weights=uniform;, score=0.568 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=11, KNN__weights=uniform;, score=0.609 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=11, KNN__weights=uniform;, score=0.625 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=11, KNN__weights=uniform;, score=0.685 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=11, KNN__weights=distance;, score=0.705 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=11, KNN__weights=distance;, score=0.592 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=11, KNN__weights=distance;, score=0.624 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=11, KNN__weights=distance;, score=0.634 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=11, KNN__weights=distance;, score=0.716 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=13, KNN__weights=uniform;, score=0.667 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=13, KNN__weights=uniform;, score=0.589 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=13, KNN__weights=uniform;, score=0.638 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=13, KNN__weights=uniform;, score=0.625 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=13, KNN__weights=uniform;, score=0.698 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=13, KNN__weights=distance;, score=0.686 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=13, KNN__weights=distance;, score=0.583 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=13, KNN__weights=distance;, score=0.653 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=13, KNN__weights=distance;, score=0.634 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=13, KNN__weights=distance;, score=0.716 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=15, KNN__weights=uniform;, score=0.654 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=15, KNN__weights=uniform;, score=0.583 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=15, KNN__weights=uniform;, score=0.674 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=15, KNN__weights=uniform;, score=0.617 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=15, KNN__weights=uniform;, score=0.654 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=15, KNN__weights=distance;, score=0.654 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=15, KNN__weights=distance;, score=0.598 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=15, KNN__weights=distance;, score=0.660 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=15, KNN__weights=distance;, score=0.633 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=15, KNN__weights=distance;, score=0.679 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=17, KNN__weights=uniform;, score=0.653 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=17, KNN__weights=uniform;, score=0.532 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=17, KNN__weights=uniform;, score=0.674 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=17, KNN__weights=uniform;, score=0.602 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=17, KNN__weights=uniform;, score=0.667 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=17, KNN__weights=distance;, score=0.673 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=17, KNN__weights=distance;, score=0.592 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=17, KNN__weights=distance;, score=0.681 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=17, KNN__weights=distance;, score=0.632 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=17, KNN__weights=distance;, score=0.667 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=19, KNN__weights=uniform;, score=0.660 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=19, KNN__weights=uniform;, score=0.568 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=19, KNN__weights=uniform;, score=0.645 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=19, KNN__weights=uniform;, score=0.630 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=19, KNN__weights=uniform;, score=0.680 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=19, KNN__weights=distance;, score=0.667 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=19, KNN__weights=distance;, score=0.577 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=19, KNN__weights=distance;, score=0.667 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=19, KNN__weights=distance;, score=0.673 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=19, KNN__weights=distance;, score=0.686 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=21, KNN__weights=uniform;, score=0.680 total time=   0.1s\n","[CV 2/5] END KNN__n_neighbors=21, KNN__weights=uniform;, score=0.538 total time=   0.1s\n","[CV 3/5] END KNN__n_neighbors=21, KNN__weights=uniform;, score=0.645 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=21, KNN__weights=uniform;, score=0.645 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=21, KNN__weights=uniform;, score=0.718 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=21, KNN__weights=distance;, score=0.667 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=21, KNN__weights=distance;, score=0.568 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=21, KNN__weights=distance;, score=0.667 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=21, KNN__weights=distance;, score=0.687 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=21, KNN__weights=distance;, score=0.722 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=23, KNN__weights=uniform;, score=0.667 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=23, KNN__weights=uniform;, score=0.462 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=23, KNN__weights=uniform;, score=0.615 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=23, KNN__weights=uniform;, score=0.645 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=23, KNN__weights=uniform;, score=0.706 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=23, KNN__weights=distance;, score=0.646 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=23, KNN__weights=distance;, score=0.542 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=23, KNN__weights=distance;, score=0.652 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=23, KNN__weights=distance;, score=0.673 total time=   0.1s\n","[CV 5/5] END KNN__n_neighbors=23, KNN__weights=distance;, score=0.736 total time=   0.1s\n","\n","--------------------------------------------\n","\n","Inner CV (Hyperparameters and model selection): \n","  F1-score = 0.7412116290345031\n","  Best hyperparams = {'KNN__n_neighbors': 1, 'KNN__weights': 'uniform'}\n","Outer CV (Quality of model selection assessment): \n","  F1-score = 0.6451612903225807\n","\n","--------------------------------------------\n","\n","Computing inner cross validation for grid search of best hyperparameters...\n","Fitting 5 folds for each of 24 candidates, totalling 120 fits\n","[CV 1/5] END KNN__n_neighbors=1, KNN__weights=uniform;, score=0.719 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=1, KNN__weights=uniform;, score=0.611 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=1, KNN__weights=uniform;, score=0.732 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=1, KNN__weights=uniform;, score=0.714 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=1, KNN__weights=uniform;, score=0.743 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=1, KNN__weights=distance;, score=0.719 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=1, KNN__weights=distance;, score=0.611 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=1, KNN__weights=distance;, score=0.732 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=1, KNN__weights=distance;, score=0.714 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=1, KNN__weights=distance;, score=0.743 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=3, KNN__weights=uniform;, score=0.691 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=3, KNN__weights=uniform;, score=0.604 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=3, KNN__weights=uniform;, score=0.667 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=3, KNN__weights=uniform;, score=0.697 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=3, KNN__weights=uniform;, score=0.660 total time=   0.1s\n","[CV 1/5] END KNN__n_neighbors=3, KNN__weights=distance;, score=0.703 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=3, KNN__weights=distance;, score=0.630 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=3, KNN__weights=distance;, score=0.667 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=3, KNN__weights=distance;, score=0.691 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=3, KNN__weights=distance;, score=0.673 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=5, KNN__weights=uniform;, score=0.679 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=5, KNN__weights=uniform;, score=0.535 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=5, KNN__weights=uniform;, score=0.743 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=5, KNN__weights=uniform;, score=0.704 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=5, KNN__weights=uniform;, score=0.653 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=5, KNN__weights=distance;, score=0.679 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=5, KNN__weights=distance;, score=0.549 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=5, KNN__weights=distance;, score=0.736 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=5, KNN__weights=distance;, score=0.685 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=5, KNN__weights=distance;, score=0.667 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=7, KNN__weights=uniform;, score=0.698 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=7, KNN__weights=uniform;, score=0.484 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=7, KNN__weights=uniform;, score=0.686 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=7, KNN__weights=uniform;, score=0.654 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=7, KNN__weights=uniform;, score=0.625 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=7, KNN__weights=distance;, score=0.705 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=7, KNN__weights=distance;, score=0.515 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=7, KNN__weights=distance;, score=0.717 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=7, KNN__weights=distance;, score=0.654 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=7, KNN__weights=distance;, score=0.639 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=9, KNN__weights=uniform;, score=0.653 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=9, KNN__weights=uniform;, score=0.489 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=9, KNN__weights=uniform;, score=0.693 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=9, KNN__weights=uniform;, score=0.647 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=9, KNN__weights=uniform;, score=0.653 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=9, KNN__weights=distance;, score=0.673 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=9, KNN__weights=distance;, score=0.495 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=9, KNN__weights=distance;, score=0.731 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=9, KNN__weights=distance;, score=0.634 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=9, KNN__weights=distance;, score=0.687 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=11, KNN__weights=uniform;, score=0.611 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=11, KNN__weights=uniform;, score=0.547 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=11, KNN__weights=uniform;, score=0.707 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=11, KNN__weights=uniform;, score=0.614 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=11, KNN__weights=uniform;, score=0.633 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=11, KNN__weights=distance;, score=0.660 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=11, KNN__weights=distance;, score=0.542 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=11, KNN__weights=distance;, score=0.693 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=11, KNN__weights=distance;, score=0.627 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=11, KNN__weights=distance;, score=0.680 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=13, KNN__weights=uniform;, score=0.611 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=13, KNN__weights=uniform;, score=0.522 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=13, KNN__weights=uniform;, score=0.700 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=13, KNN__weights=uniform;, score=0.640 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=13, KNN__weights=uniform;, score=0.646 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=13, KNN__weights=distance;, score=0.653 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=13, KNN__weights=distance;, score=0.526 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=13, KNN__weights=distance;, score=0.687 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=13, KNN__weights=distance;, score=0.647 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=13, KNN__weights=distance;, score=0.667 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=15, KNN__weights=uniform;, score=0.633 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=15, KNN__weights=uniform;, score=0.533 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=15, KNN__weights=uniform;, score=0.707 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=15, KNN__weights=uniform;, score=0.680 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=15, KNN__weights=uniform;, score=0.632 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=15, KNN__weights=distance;, score=0.667 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=15, KNN__weights=distance;, score=0.538 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=15, KNN__weights=distance;, score=0.707 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=15, KNN__weights=distance;, score=0.647 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=15, KNN__weights=distance;, score=0.638 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=17, KNN__weights=uniform;, score=0.620 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=17, KNN__weights=uniform;, score=0.494 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=17, KNN__weights=uniform;, score=0.693 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=17, KNN__weights=uniform;, score=0.680 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=17, KNN__weights=uniform;, score=0.646 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=17, KNN__weights=distance;, score=0.640 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=17, KNN__weights=distance;, score=0.549 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=17, KNN__weights=distance;, score=0.713 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=17, KNN__weights=distance;, score=0.647 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=17, KNN__weights=distance;, score=0.646 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=19, KNN__weights=uniform;, score=0.619 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=19, KNN__weights=uniform;, score=0.465 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=19, KNN__weights=uniform;, score=0.713 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=19, KNN__weights=uniform;, score=0.706 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=19, KNN__weights=uniform;, score=0.653 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=19, KNN__weights=distance;, score=0.639 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=19, KNN__weights=distance;, score=0.532 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=19, KNN__weights=distance;, score=0.707 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=19, KNN__weights=distance;, score=0.673 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=19, KNN__weights=distance;, score=0.638 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=21, KNN__weights=uniform;, score=0.545 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=21, KNN__weights=uniform;, score=0.465 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=21, KNN__weights=uniform;, score=0.693 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=21, KNN__weights=uniform;, score=0.680 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=21, KNN__weights=uniform;, score=0.638 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=21, KNN__weights=distance;, score=0.608 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=21, KNN__weights=distance;, score=0.522 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=21, KNN__weights=distance;, score=0.707 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=21, KNN__weights=distance;, score=0.653 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=21, KNN__weights=distance;, score=0.638 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=23, KNN__weights=uniform;, score=0.571 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=23, KNN__weights=uniform;, score=0.506 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=23, KNN__weights=uniform;, score=0.701 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=23, KNN__weights=uniform;, score=0.680 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=23, KNN__weights=uniform;, score=0.653 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=23, KNN__weights=distance;, score=0.600 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=23, KNN__weights=distance;, score=0.517 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=23, KNN__weights=distance;, score=0.727 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=23, KNN__weights=distance;, score=0.660 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=23, KNN__weights=distance;, score=0.638 total time=   0.0s\n","\n","--------------------------------------------\n","\n","Inner CV (Hyperparameters and model selection): \n","  F1-score = 0.704040152002425\n","  Best hyperparams = {'KNN__n_neighbors': 1, 'KNN__weights': 'uniform'}\n","Outer CV (Quality of model selection assessment): \n","  F1-score = 0.6428571428571429\n","\n","--------------------------------------------\n","\n","Computing inner cross validation for grid search of best hyperparameters...\n","Fitting 5 folds for each of 24 candidates, totalling 120 fits\n","[CV 1/5] END KNN__n_neighbors=1, KNN__weights=uniform;, score=0.661 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=1, KNN__weights=uniform;, score=0.744 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=1, KNN__weights=uniform;, score=0.667 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=1, KNN__weights=uniform;, score=0.754 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=1, KNN__weights=uniform;, score=0.692 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=1, KNN__weights=distance;, score=0.661 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=1, KNN__weights=distance;, score=0.744 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=1, KNN__weights=distance;, score=0.667 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=1, KNN__weights=distance;, score=0.754 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=1, KNN__weights=distance;, score=0.692 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=3, KNN__weights=uniform;, score=0.698 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=3, KNN__weights=uniform;, score=0.691 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=3, KNN__weights=uniform;, score=0.608 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=3, KNN__weights=uniform;, score=0.739 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=3, KNN__weights=uniform;, score=0.588 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=3, KNN__weights=distance;, score=0.692 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=3, KNN__weights=distance;, score=0.691 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=3, KNN__weights=distance;, score=0.608 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=3, KNN__weights=distance;, score=0.739 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=3, KNN__weights=distance;, score=0.608 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=5, KNN__weights=uniform;, score=0.748 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=5, KNN__weights=uniform;, score=0.722 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=5, KNN__weights=uniform;, score=0.634 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=5, KNN__weights=uniform;, score=0.748 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=5, KNN__weights=uniform;, score=0.673 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=5, KNN__weights=distance;, score=0.741 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=5, KNN__weights=distance;, score=0.710 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=5, KNN__weights=distance;, score=0.634 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=5, KNN__weights=distance;, score=0.741 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=5, KNN__weights=distance;, score=0.686 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=7, KNN__weights=uniform;, score=0.705 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=7, KNN__weights=uniform;, score=0.692 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=7, KNN__weights=uniform;, score=0.627 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=7, KNN__weights=uniform;, score=0.755 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=7, KNN__weights=uniform;, score=0.639 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=7, KNN__weights=distance;, score=0.705 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=7, KNN__weights=distance;, score=0.692 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=7, KNN__weights=distance;, score=0.641 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=7, KNN__weights=distance;, score=0.748 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=7, KNN__weights=distance;, score=0.667 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=9, KNN__weights=uniform;, score=0.621 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=9, KNN__weights=uniform;, score=0.660 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=9, KNN__weights=uniform;, score=0.606 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=9, KNN__weights=uniform;, score=0.729 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=9, KNN__weights=uniform;, score=0.578 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=9, KNN__weights=distance;, score=0.629 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=9, KNN__weights=distance;, score=0.705 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=9, KNN__weights=distance;, score=0.634 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=9, KNN__weights=distance;, score=0.734 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=9, KNN__weights=distance;, score=0.602 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=11, KNN__weights=uniform;, score=0.640 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=11, KNN__weights=uniform;, score=0.633 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=11, KNN__weights=uniform;, score=0.598 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=11, KNN__weights=uniform;, score=0.755 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=11, KNN__weights=uniform;, score=0.511 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=11, KNN__weights=distance;, score=0.641 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=11, KNN__weights=distance;, score=0.660 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=11, KNN__weights=distance;, score=0.620 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=11, KNN__weights=distance;, score=0.736 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=11, KNN__weights=distance;, score=0.598 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=13, KNN__weights=uniform;, score=0.626 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=13, KNN__weights=uniform;, score=0.646 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=13, KNN__weights=uniform;, score=0.633 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=13, KNN__weights=uniform;, score=0.724 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=13, KNN__weights=uniform;, score=0.578 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=13, KNN__weights=distance;, score=0.673 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=13, KNN__weights=distance;, score=0.673 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=13, KNN__weights=distance;, score=0.646 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=13, KNN__weights=distance;, score=0.729 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=13, KNN__weights=distance;, score=0.596 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=15, KNN__weights=uniform;, score=0.641 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=15, KNN__weights=uniform;, score=0.673 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=15, KNN__weights=uniform;, score=0.619 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=15, KNN__weights=uniform;, score=0.724 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=15, KNN__weights=uniform;, score=0.571 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=15, KNN__weights=distance;, score=0.667 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=15, KNN__weights=distance;, score=0.680 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=15, KNN__weights=distance;, score=0.646 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=15, KNN__weights=distance;, score=0.724 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=15, KNN__weights=distance;, score=0.617 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=17, KNN__weights=uniform;, score=0.653 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=17, KNN__weights=uniform;, score=0.602 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=17, KNN__weights=uniform;, score=0.611 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=17, KNN__weights=uniform;, score=0.738 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=17, KNN__weights=uniform;, score=0.587 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=17, KNN__weights=distance;, score=0.647 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=17, KNN__weights=distance;, score=0.680 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=17, KNN__weights=distance;, score=0.639 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=17, KNN__weights=distance;, score=0.743 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=17, KNN__weights=distance;, score=0.602 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=19, KNN__weights=uniform;, score=0.647 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=19, KNN__weights=uniform;, score=0.609 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=19, KNN__weights=uniform;, score=0.602 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=19, KNN__weights=uniform;, score=0.725 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=19, KNN__weights=uniform;, score=0.591 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=19, KNN__weights=distance;, score=0.634 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=19, KNN__weights=distance;, score=0.646 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=19, KNN__weights=distance;, score=0.625 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=19, KNN__weights=distance;, score=0.718 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=19, KNN__weights=distance;, score=0.600 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=21, KNN__weights=uniform;, score=0.680 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=21, KNN__weights=uniform;, score=0.587 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=21, KNN__weights=uniform;, score=0.587 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=21, KNN__weights=uniform;, score=0.706 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=21, KNN__weights=uniform;, score=0.568 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=21, KNN__weights=distance;, score=0.673 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=21, KNN__weights=distance;, score=0.653 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=21, KNN__weights=distance;, score=0.596 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=21, KNN__weights=distance;, score=0.699 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=21, KNN__weights=distance;, score=0.578 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=23, KNN__weights=uniform;, score=0.653 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=23, KNN__weights=uniform;, score=0.581 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=23, KNN__weights=uniform;, score=0.602 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=23, KNN__weights=uniform;, score=0.680 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=23, KNN__weights=uniform;, score=0.545 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=23, KNN__weights=distance;, score=0.653 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=23, KNN__weights=distance;, score=0.646 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=23, KNN__weights=distance;, score=0.581 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=23, KNN__weights=distance;, score=0.699 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=23, KNN__weights=distance;, score=0.562 total time=   0.0s\n","\n","--------------------------------------------\n","\n","Inner CV (Hyperparameters and model selection): \n","  F1-score = 0.7048960036190535\n","  Best hyperparams = {'KNN__n_neighbors': 5, 'KNN__weights': 'uniform'}\n","Outer CV (Quality of model selection assessment): \n","  F1-score = 0.721311475409836\n","\n","--------------------------------------------\n","\n","Computing inner cross validation for grid search of best hyperparameters...\n","Fitting 5 folds for each of 24 candidates, totalling 120 fits\n","[CV 1/5] END KNN__n_neighbors=1, KNN__weights=uniform;, score=0.767 total time=   0.1s\n","[CV 2/5] END KNN__n_neighbors=1, KNN__weights=uniform;, score=0.714 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=1, KNN__weights=uniform;, score=0.685 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=1, KNN__weights=uniform;, score=0.718 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=1, KNN__weights=uniform;, score=0.732 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=1, KNN__weights=distance;, score=0.767 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=1, KNN__weights=distance;, score=0.714 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=1, KNN__weights=distance;, score=0.685 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=1, KNN__weights=distance;, score=0.718 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=1, KNN__weights=distance;, score=0.732 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=3, KNN__weights=uniform;, score=0.741 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=3, KNN__weights=uniform;, score=0.626 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=3, KNN__weights=uniform;, score=0.673 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=3, KNN__weights=uniform;, score=0.746 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=3, KNN__weights=uniform;, score=0.750 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=3, KNN__weights=distance;, score=0.759 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=3, KNN__weights=distance;, score=0.634 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=3, KNN__weights=distance;, score=0.685 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=3, KNN__weights=distance;, score=0.746 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=3, KNN__weights=distance;, score=0.754 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=5, KNN__weights=uniform;, score=0.709 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=5, KNN__weights=uniform;, score=0.580 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=5, KNN__weights=uniform;, score=0.641 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=5, KNN__weights=uniform;, score=0.769 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=5, KNN__weights=uniform;, score=0.704 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=5, KNN__weights=distance;, score=0.737 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=5, KNN__weights=distance;, score=0.602 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=5, KNN__weights=distance;, score=0.660 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=5, KNN__weights=distance;, score=0.769 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=5, KNN__weights=distance;, score=0.709 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=7, KNN__weights=uniform;, score=0.679 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=7, KNN__weights=uniform;, score=0.563 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=7, KNN__weights=uniform;, score=0.706 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=7, KNN__weights=uniform;, score=0.739 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=7, KNN__weights=uniform;, score=0.661 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=7, KNN__weights=distance;, score=0.714 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=7, KNN__weights=distance;, score=0.592 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=7, KNN__weights=distance;, score=0.680 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=7, KNN__weights=distance;, score=0.739 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=7, KNN__weights=distance;, score=0.673 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=9, KNN__weights=uniform;, score=0.686 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=9, KNN__weights=uniform;, score=0.577 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=9, KNN__weights=uniform;, score=0.686 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=9, KNN__weights=uniform;, score=0.719 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=9, KNN__weights=uniform;, score=0.679 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=9, KNN__weights=distance;, score=0.692 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=9, KNN__weights=distance;, score=0.586 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=9, KNN__weights=distance;, score=0.686 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=9, KNN__weights=distance;, score=0.701 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=9, KNN__weights=distance;, score=0.692 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=11, KNN__weights=uniform;, score=0.700 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=11, KNN__weights=uniform;, score=0.563 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=11, KNN__weights=uniform;, score=0.667 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=11, KNN__weights=uniform;, score=0.697 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=11, KNN__weights=uniform;, score=0.660 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=11, KNN__weights=distance;, score=0.699 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=11, KNN__weights=distance;, score=0.568 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=11, KNN__weights=distance;, score=0.667 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=11, KNN__weights=distance;, score=0.709 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=11, KNN__weights=distance;, score=0.692 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=13, KNN__weights=uniform;, score=0.680 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=13, KNN__weights=uniform;, score=0.563 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=13, KNN__weights=uniform;, score=0.700 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=13, KNN__weights=uniform;, score=0.717 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=13, KNN__weights=uniform;, score=0.667 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=13, KNN__weights=distance;, score=0.705 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=13, KNN__weights=distance;, score=0.568 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=13, KNN__weights=distance;, score=0.713 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=13, KNN__weights=distance;, score=0.697 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=13, KNN__weights=distance;, score=0.698 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=15, KNN__weights=uniform;, score=0.680 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=15, KNN__weights=uniform;, score=0.574 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=15, KNN__weights=uniform;, score=0.694 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=15, KNN__weights=uniform;, score=0.738 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=15, KNN__weights=uniform;, score=0.635 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=15, KNN__weights=distance;, score=0.699 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=15, KNN__weights=distance;, score=0.583 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=15, KNN__weights=distance;, score=0.660 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=15, KNN__weights=distance;, score=0.722 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=15, KNN__weights=distance;, score=0.673 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=17, KNN__weights=uniform;, score=0.660 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=17, KNN__weights=uniform;, score=0.543 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=17, KNN__weights=uniform;, score=0.694 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=17, KNN__weights=uniform;, score=0.750 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=17, KNN__weights=uniform;, score=0.627 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=17, KNN__weights=distance;, score=0.712 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=17, KNN__weights=distance;, score=0.553 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=17, KNN__weights=distance;, score=0.694 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=17, KNN__weights=distance;, score=0.722 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=17, KNN__weights=distance;, score=0.679 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=19, KNN__weights=uniform;, score=0.680 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=19, KNN__weights=uniform;, score=0.522 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=19, KNN__weights=uniform;, score=0.680 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=19, KNN__weights=uniform;, score=0.745 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=19, KNN__weights=uniform;, score=0.654 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=19, KNN__weights=distance;, score=0.693 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=19, KNN__weights=distance;, score=0.538 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=19, KNN__weights=distance;, score=0.687 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=19, KNN__weights=distance;, score=0.717 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=19, KNN__weights=distance;, score=0.673 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=21, KNN__weights=uniform;, score=0.680 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=21, KNN__weights=uniform;, score=0.500 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=21, KNN__weights=uniform;, score=0.680 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=21, KNN__weights=uniform;, score=0.707 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=21, KNN__weights=uniform;, score=0.627 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=21, KNN__weights=distance;, score=0.693 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=21, KNN__weights=distance;, score=0.538 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=21, KNN__weights=distance;, score=0.674 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=21, KNN__weights=distance;, score=0.705 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=21, KNN__weights=distance;, score=0.660 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=23, KNN__weights=uniform;, score=0.653 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=23, KNN__weights=uniform;, score=0.516 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=23, KNN__weights=uniform;, score=0.687 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=23, KNN__weights=uniform;, score=0.700 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=23, KNN__weights=uniform;, score=0.620 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=23, KNN__weights=distance;, score=0.693 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=23, KNN__weights=distance;, score=0.553 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=23, KNN__weights=distance;, score=0.714 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=23, KNN__weights=distance;, score=0.700 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=23, KNN__weights=distance;, score=0.634 total time=   0.0s\n","\n","--------------------------------------------\n","\n","Inner CV (Hyperparameters and model selection): \n","  F1-score = 0.7232458282458283\n","  Best hyperparams = {'KNN__n_neighbors': 1, 'KNN__weights': 'uniform'}\n","Outer CV (Quality of model selection assessment): \n","  F1-score = 0.6666666666666666\n","\n","--------------------------------------------\n","\n","Computing inner cross validation for grid search of best hyperparameters...\n","Fitting 5 folds for each of 24 candidates, totalling 120 fits\n","[CV 1/5] END KNN__n_neighbors=1, KNN__weights=uniform;, score=0.721 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=1, KNN__weights=uniform;, score=0.696 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=1, KNN__weights=uniform;, score=0.763 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=1, KNN__weights=uniform;, score=0.690 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=1, KNN__weights=uniform;, score=0.661 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=1, KNN__weights=distance;, score=0.721 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=1, KNN__weights=distance;, score=0.696 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=1, KNN__weights=distance;, score=0.763 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=1, KNN__weights=distance;, score=0.690 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=1, KNN__weights=distance;, score=0.661 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=3, KNN__weights=uniform;, score=0.660 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=3, KNN__weights=uniform;, score=0.602 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=3, KNN__weights=uniform;, score=0.673 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=3, KNN__weights=uniform;, score=0.673 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=3, KNN__weights=uniform;, score=0.691 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=3, KNN__weights=distance;, score=0.673 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=3, KNN__weights=distance;, score=0.615 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=3, KNN__weights=distance;, score=0.685 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=3, KNN__weights=distance;, score=0.696 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=3, KNN__weights=distance;, score=0.691 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=5, KNN__weights=uniform;, score=0.716 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=5, KNN__weights=uniform;, score=0.592 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=5, KNN__weights=uniform;, score=0.634 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=5, KNN__weights=uniform;, score=0.660 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=5, KNN__weights=uniform;, score=0.642 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=5, KNN__weights=distance;, score=0.704 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=5, KNN__weights=distance;, score=0.606 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=5, KNN__weights=distance;, score=0.667 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=5, KNN__weights=distance;, score=0.654 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=5, KNN__weights=distance;, score=0.642 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=7, KNN__weights=uniform;, score=0.698 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=7, KNN__weights=uniform;, score=0.606 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=7, KNN__weights=uniform;, score=0.653 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=7, KNN__weights=uniform;, score=0.660 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=7, KNN__weights=uniform;, score=0.673 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=7, KNN__weights=distance;, score=0.686 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=7, KNN__weights=distance;, score=0.592 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=7, KNN__weights=distance;, score=0.667 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=7, KNN__weights=distance;, score=0.673 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=7, KNN__weights=distance;, score=0.667 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=9, KNN__weights=uniform;, score=0.705 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=9, KNN__weights=uniform;, score=0.606 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=9, KNN__weights=uniform;, score=0.633 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=9, KNN__weights=uniform;, score=0.667 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=9, KNN__weights=uniform;, score=0.641 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=9, KNN__weights=distance;, score=0.717 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=9, KNN__weights=distance;, score=0.620 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=9, KNN__weights=distance;, score=0.673 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=9, KNN__weights=distance;, score=0.660 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=9, KNN__weights=distance;, score=0.635 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=11, KNN__weights=uniform;, score=0.699 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=11, KNN__weights=uniform;, score=0.586 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=11, KNN__weights=uniform;, score=0.646 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=11, KNN__weights=uniform;, score=0.646 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=11, KNN__weights=uniform;, score=0.648 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=11, KNN__weights=distance;, score=0.705 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=11, KNN__weights=distance;, score=0.606 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=11, KNN__weights=distance;, score=0.646 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=11, KNN__weights=distance;, score=0.634 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=11, KNN__weights=distance;, score=0.648 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=13, KNN__weights=uniform;, score=0.673 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=13, KNN__weights=uniform;, score=0.559 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=13, KNN__weights=uniform;, score=0.660 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=13, KNN__weights=uniform;, score=0.617 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=13, KNN__weights=uniform;, score=0.673 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=13, KNN__weights=distance;, score=0.686 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=13, KNN__weights=distance;, score=0.598 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=13, KNN__weights=distance;, score=0.673 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=13, KNN__weights=distance;, score=0.612 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=13, KNN__weights=distance;, score=0.673 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=15, KNN__weights=uniform;, score=0.667 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=15, KNN__weights=uniform;, score=0.581 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=15, KNN__weights=uniform;, score=0.667 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=15, KNN__weights=uniform;, score=0.638 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=15, KNN__weights=uniform;, score=0.634 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=15, KNN__weights=distance;, score=0.680 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=15, KNN__weights=distance;, score=0.625 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=15, KNN__weights=distance;, score=0.667 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=15, KNN__weights=distance;, score=0.646 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=15, KNN__weights=distance;, score=0.634 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=17, KNN__weights=uniform;, score=0.653 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=17, KNN__weights=uniform;, score=0.565 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=17, KNN__weights=uniform;, score=0.653 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=17, KNN__weights=uniform;, score=0.617 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=17, KNN__weights=uniform;, score=0.640 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=17, KNN__weights=distance;, score=0.667 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=17, KNN__weights=distance;, score=0.596 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=17, KNN__weights=distance;, score=0.680 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=17, KNN__weights=distance;, score=0.646 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=17, KNN__weights=distance;, score=0.647 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=19, KNN__weights=uniform;, score=0.604 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=19, KNN__weights=uniform;, score=0.539 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=19, KNN__weights=uniform;, score=0.673 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=19, KNN__weights=uniform;, score=0.638 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=19, KNN__weights=uniform;, score=0.653 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=19, KNN__weights=distance;, score=0.625 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=19, KNN__weights=distance;, score=0.571 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=19, KNN__weights=distance;, score=0.667 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=19, KNN__weights=distance;, score=0.625 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=19, KNN__weights=distance;, score=0.673 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=21, KNN__weights=uniform;, score=0.589 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=21, KNN__weights=uniform;, score=0.556 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=21, KNN__weights=uniform;, score=0.680 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=21, KNN__weights=uniform;, score=0.624 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=21, KNN__weights=uniform;, score=0.598 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=21, KNN__weights=distance;, score=0.617 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=21, KNN__weights=distance;, score=0.571 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=21, KNN__weights=distance;, score=0.673 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=21, KNN__weights=distance;, score=0.638 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=21, KNN__weights=distance;, score=0.633 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=23, KNN__weights=uniform;, score=0.646 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=23, KNN__weights=uniform;, score=0.539 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=23, KNN__weights=uniform;, score=0.673 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=23, KNN__weights=uniform;, score=0.638 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=23, KNN__weights=uniform;, score=0.633 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=23, KNN__weights=distance;, score=0.660 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=23, KNN__weights=distance;, score=0.571 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=23, KNN__weights=distance;, score=0.680 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=23, KNN__weights=distance;, score=0.624 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=23, KNN__weights=distance;, score=0.619 total time=   0.0s\n","\n","--------------------------------------------\n","\n","Inner CV (Hyperparameters and model selection): \n","  F1-score = 0.7061681857992042\n","  Best hyperparams = {'KNN__n_neighbors': 1, 'KNN__weights': 'uniform'}\n","Outer CV (Quality of model selection assessment): \n","  F1-score = 0.71875\n","\n","--------------------------------------------\n","\n","Computing inner cross validation for grid search of best hyperparameters...\n","Fitting 5 folds for each of 24 candidates, totalling 120 fits\n","[CV 1/5] END KNN__n_neighbors=1, KNN__weights=uniform;, score=0.714 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=1, KNN__weights=uniform;, score=0.750 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=1, KNN__weights=uniform;, score=0.734 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=1, KNN__weights=uniform;, score=0.727 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=1, KNN__weights=uniform;, score=0.803 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=1, KNN__weights=distance;, score=0.714 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=1, KNN__weights=distance;, score=0.750 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=1, KNN__weights=distance;, score=0.734 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=1, KNN__weights=distance;, score=0.727 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=1, KNN__weights=distance;, score=0.803 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=3, KNN__weights=uniform;, score=0.710 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=3, KNN__weights=uniform;, score=0.759 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=3, KNN__weights=uniform;, score=0.654 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=3, KNN__weights=uniform;, score=0.612 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=3, KNN__weights=uniform;, score=0.691 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=3, KNN__weights=distance;, score=0.734 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=3, KNN__weights=distance;, score=0.765 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=3, KNN__weights=distance;, score=0.654 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=3, KNN__weights=distance;, score=0.612 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=3, KNN__weights=distance;, score=0.721 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=5, KNN__weights=uniform;, score=0.667 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=5, KNN__weights=uniform;, score=0.696 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=5, KNN__weights=uniform;, score=0.634 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=5, KNN__weights=uniform;, score=0.626 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=5, KNN__weights=uniform;, score=0.667 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=5, KNN__weights=distance;, score=0.667 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=5, KNN__weights=distance;, score=0.703 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=5, KNN__weights=distance;, score=0.634 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=5, KNN__weights=distance;, score=0.626 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=5, KNN__weights=distance;, score=0.685 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=7, KNN__weights=uniform;, score=0.614 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=7, KNN__weights=uniform;, score=0.719 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=7, KNN__weights=uniform;, score=0.626 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=7, KNN__weights=uniform;, score=0.598 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=7, KNN__weights=uniform;, score=0.697 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=7, KNN__weights=distance;, score=0.615 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=7, KNN__weights=distance;, score=0.737 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=7, KNN__weights=distance;, score=0.626 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=7, KNN__weights=distance;, score=0.619 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=7, KNN__weights=distance;, score=0.716 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=9, KNN__weights=uniform;, score=0.667 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=9, KNN__weights=uniform;, score=0.703 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=9, KNN__weights=uniform;, score=0.612 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=9, KNN__weights=uniform;, score=0.653 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=9, KNN__weights=uniform;, score=0.697 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=9, KNN__weights=distance;, score=0.692 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=9, KNN__weights=distance;, score=0.691 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=9, KNN__weights=distance;, score=0.620 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=9, KNN__weights=distance;, score=0.646 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=9, KNN__weights=distance;, score=0.716 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=11, KNN__weights=uniform;, score=0.680 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=11, KNN__weights=uniform;, score=0.679 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=11, KNN__weights=uniform;, score=0.639 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=11, KNN__weights=uniform;, score=0.674 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=11, KNN__weights=uniform;, score=0.722 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=11, KNN__weights=distance;, score=0.686 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=11, KNN__weights=distance;, score=0.673 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=11, KNN__weights=distance;, score=0.640 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=11, KNN__weights=distance;, score=0.680 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=11, KNN__weights=distance;, score=0.736 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=13, KNN__weights=uniform;, score=0.686 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=13, KNN__weights=uniform;, score=0.653 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=13, KNN__weights=uniform;, score=0.625 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=13, KNN__weights=uniform;, score=0.667 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=13, KNN__weights=uniform;, score=0.736 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=13, KNN__weights=distance;, score=0.699 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=13, KNN__weights=distance;, score=0.698 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=13, KNN__weights=distance;, score=0.619 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=13, KNN__weights=distance;, score=0.667 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=13, KNN__weights=distance;, score=0.766 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=15, KNN__weights=uniform;, score=0.660 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=15, KNN__weights=uniform;, score=0.698 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=15, KNN__weights=uniform;, score=0.596 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=15, KNN__weights=uniform;, score=0.660 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=15, KNN__weights=uniform;, score=0.755 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=15, KNN__weights=distance;, score=0.673 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=15, KNN__weights=distance;, score=0.729 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=15, KNN__weights=distance;, score=0.596 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=15, KNN__weights=distance;, score=0.653 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=15, KNN__weights=distance;, score=0.766 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=17, KNN__weights=uniform;, score=0.673 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=17, KNN__weights=uniform;, score=0.686 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=17, KNN__weights=uniform;, score=0.596 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=17, KNN__weights=uniform;, score=0.615 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=17, KNN__weights=uniform;, score=0.750 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=17, KNN__weights=distance;, score=0.680 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=17, KNN__weights=distance;, score=0.724 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=17, KNN__weights=distance;, score=0.589 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=17, KNN__weights=distance;, score=0.645 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=17, KNN__weights=distance;, score=0.762 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=19, KNN__weights=uniform;, score=0.653 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=19, KNN__weights=uniform;, score=0.673 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=19, KNN__weights=uniform;, score=0.619 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=19, KNN__weights=uniform;, score=0.630 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=19, KNN__weights=uniform;, score=0.733 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=19, KNN__weights=distance;, score=0.680 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=19, KNN__weights=distance;, score=0.731 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=19, KNN__weights=distance;, score=0.583 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=19, KNN__weights=distance;, score=0.660 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=19, KNN__weights=distance;, score=0.745 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=21, KNN__weights=uniform;, score=0.653 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=21, KNN__weights=uniform;, score=0.673 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=21, KNN__weights=uniform;, score=0.619 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=21, KNN__weights=uniform;, score=0.615 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=21, KNN__weights=uniform;, score=0.720 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=21, KNN__weights=distance;, score=0.686 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=21, KNN__weights=distance;, score=0.706 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=21, KNN__weights=distance;, score=0.589 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=21, KNN__weights=distance;, score=0.660 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=21, KNN__weights=distance;, score=0.745 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=23, KNN__weights=uniform;, score=0.653 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=23, KNN__weights=uniform;, score=0.673 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=23, KNN__weights=uniform;, score=0.646 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=23, KNN__weights=uniform;, score=0.600 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=23, KNN__weights=uniform;, score=0.733 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=23, KNN__weights=distance;, score=0.680 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=23, KNN__weights=distance;, score=0.706 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=23, KNN__weights=distance;, score=0.617 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=23, KNN__weights=distance;, score=0.653 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=23, KNN__weights=distance;, score=0.765 total time=   0.0s\n","\n","--------------------------------------------\n","\n","Inner CV (Hyperparameters and model selection): \n","  F1-score = 0.745784439821137\n","  Best hyperparams = {'KNN__n_neighbors': 1, 'KNN__weights': 'uniform'}\n","Outer CV (Quality of model selection assessment): \n","  F1-score = 0.6551724137931034\n","\n","--------------------------------------------\n","\n","\n","--------------------------------------------\n","\n","Mean training F1-score = 0.9796992481203007 (0.060902255639097715)\n","Mean validation F1-score = 0.7015653254783596 (0.050209605094159136)\n","List of best hyperparameters to check stability: \n"]},{"output_type":"display_data","data":{"text/plain":["   KNN__n_neighbors KNN__weights\n","0                 1      uniform\n","1                 1      uniform\n","2                 1      uniform\n","3                 1      uniform\n","4                 1      uniform\n","5                 1      uniform\n","6                 5      uniform\n","7                 1      uniform\n","8                 1      uniform\n","9                 1      uniform"],"text/html":["\n","  <div id=\"df-f4ac6260-5437-44f0-9811-c950bc42c94e\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>KNN__n_neighbors</th>\n","      <th>KNN__weights</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>uniform</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>uniform</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>uniform</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>uniform</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>uniform</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>1</td>\n","      <td>uniform</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>5</td>\n","      <td>uniform</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>1</td>\n","      <td>uniform</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>1</td>\n","      <td>uniform</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>1</td>\n","      <td>uniform</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f4ac6260-5437-44f0-9811-c950bc42c94e')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-f4ac6260-5437-44f0-9811-c950bc42c94e button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-f4ac6260-5437-44f0-9811-c950bc42c94e');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["None\n","Fitting 5 folds for each of 24 candidates, totalling 120 fits\n","[CV 1/5] END KNN__n_neighbors=1, KNN__weights=uniform;, score=0.730 total time=   0.1s\n","[CV 2/5] END KNN__n_neighbors=1, KNN__weights=uniform;, score=0.760 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=1, KNN__weights=uniform;, score=0.667 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=1, KNN__weights=uniform;, score=0.688 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=1, KNN__weights=uniform;, score=0.744 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=1, KNN__weights=distance;, score=0.730 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=1, KNN__weights=distance;, score=0.760 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=1, KNN__weights=distance;, score=0.667 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=1, KNN__weights=distance;, score=0.688 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=1, KNN__weights=distance;, score=0.744 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=3, KNN__weights=uniform;, score=0.638 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=3, KNN__weights=uniform;, score=0.699 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=3, KNN__weights=uniform;, score=0.689 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=3, KNN__weights=uniform;, score=0.644 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=3, KNN__weights=uniform;, score=0.688 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=3, KNN__weights=distance;, score=0.650 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=3, KNN__weights=distance;, score=0.710 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=3, KNN__weights=distance;, score=0.683 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=3, KNN__weights=distance;, score=0.667 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=3, KNN__weights=distance;, score=0.683 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=5, KNN__weights=uniform;, score=0.619 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=5, KNN__weights=uniform;, score=0.689 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=5, KNN__weights=uniform;, score=0.684 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=5, KNN__weights=uniform;, score=0.655 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=5, KNN__weights=uniform;, score=0.744 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=5, KNN__weights=distance;, score=0.632 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=5, KNN__weights=distance;, score=0.710 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=5, KNN__weights=distance;, score=0.672 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=5, KNN__weights=distance;, score=0.672 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=5, KNN__weights=distance;, score=0.738 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=7, KNN__weights=uniform;, score=0.589 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=7, KNN__weights=uniform;, score=0.683 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=7, KNN__weights=uniform;, score=0.702 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=7, KNN__weights=uniform;, score=0.638 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=7, KNN__weights=uniform;, score=0.672 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=7, KNN__weights=distance;, score=0.609 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=7, KNN__weights=distance;, score=0.689 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=7, KNN__weights=distance;, score=0.713 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=7, KNN__weights=distance;, score=0.667 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=7, KNN__weights=distance;, score=0.678 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=9, KNN__weights=uniform;, score=0.596 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=9, KNN__weights=uniform;, score=0.684 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=9, KNN__weights=uniform;, score=0.654 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=9, KNN__weights=uniform;, score=0.631 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=9, KNN__weights=uniform;, score=0.661 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=9, KNN__weights=distance;, score=0.596 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=9, KNN__weights=distance;, score=0.684 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=9, KNN__weights=distance;, score=0.661 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=9, KNN__weights=distance;, score=0.661 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=9, KNN__weights=distance;, score=0.673 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=11, KNN__weights=uniform;, score=0.595 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=11, KNN__weights=uniform;, score=0.696 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=11, KNN__weights=uniform;, score=0.621 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=11, KNN__weights=uniform;, score=0.667 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=11, KNN__weights=uniform;, score=0.690 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=11, KNN__weights=distance;, score=0.637 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=11, KNN__weights=distance;, score=0.684 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=11, KNN__weights=distance;, score=0.648 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=11, KNN__weights=distance;, score=0.696 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=11, KNN__weights=distance;, score=0.690 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=13, KNN__weights=uniform;, score=0.642 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=13, KNN__weights=uniform;, score=0.713 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=13, KNN__weights=uniform;, score=0.621 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=13, KNN__weights=uniform;, score=0.679 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=13, KNN__weights=uniform;, score=0.696 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=13, KNN__weights=distance;, score=0.643 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=13, KNN__weights=distance;, score=0.678 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=13, KNN__weights=distance;, score=0.623 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=13, KNN__weights=distance;, score=0.690 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=13, KNN__weights=distance;, score=0.696 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=15, KNN__weights=uniform;, score=0.636 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=15, KNN__weights=uniform;, score=0.661 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=15, KNN__weights=uniform;, score=0.629 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=15, KNN__weights=uniform;, score=0.679 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=15, KNN__weights=uniform;, score=0.690 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=15, KNN__weights=distance;, score=0.624 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=15, KNN__weights=distance;, score=0.667 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=15, KNN__weights=distance;, score=0.648 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=15, KNN__weights=distance;, score=0.702 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=15, KNN__weights=distance;, score=0.690 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=17, KNN__weights=uniform;, score=0.623 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=17, KNN__weights=uniform;, score=0.667 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=17, KNN__weights=uniform;, score=0.642 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=17, KNN__weights=uniform;, score=0.655 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=17, KNN__weights=uniform;, score=0.667 total time=   0.1s\n","[CV 1/5] END KNN__n_neighbors=17, KNN__weights=distance;, score=0.611 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=17, KNN__weights=distance;, score=0.661 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=17, KNN__weights=distance;, score=0.642 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=17, KNN__weights=distance;, score=0.667 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=17, KNN__weights=distance;, score=0.690 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=19, KNN__weights=uniform;, score=0.604 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=19, KNN__weights=uniform;, score=0.630 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=19, KNN__weights=uniform;, score=0.610 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=19, KNN__weights=uniform;, score=0.648 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=19, KNN__weights=uniform;, score=0.661 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=19, KNN__weights=distance;, score=0.643 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=19, KNN__weights=distance;, score=0.637 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=19, KNN__weights=distance;, score=0.623 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=19, KNN__weights=distance;, score=0.667 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=19, KNN__weights=distance;, score=0.678 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=21, KNN__weights=uniform;, score=0.617 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=21, KNN__weights=uniform;, score=0.673 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=21, KNN__weights=uniform;, score=0.615 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=21, KNN__weights=uniform;, score=0.636 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=21, KNN__weights=uniform;, score=0.684 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=21, KNN__weights=distance;, score=0.667 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=21, KNN__weights=distance;, score=0.643 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=21, KNN__weights=distance;, score=0.610 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=21, KNN__weights=distance;, score=0.636 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=21, KNN__weights=distance;, score=0.701 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=23, KNN__weights=uniform;, score=0.558 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=23, KNN__weights=uniform;, score=0.673 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=23, KNN__weights=uniform;, score=0.602 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=23, KNN__weights=uniform;, score=0.615 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=23, KNN__weights=uniform;, score=0.655 total time=   0.0s\n","[CV 1/5] END KNN__n_neighbors=23, KNN__weights=distance;, score=0.618 total time=   0.0s\n","[CV 2/5] END KNN__n_neighbors=23, KNN__weights=distance;, score=0.655 total time=   0.0s\n","[CV 3/5] END KNN__n_neighbors=23, KNN__weights=distance;, score=0.596 total time=   0.0s\n","[CV 4/5] END KNN__n_neighbors=23, KNN__weights=distance;, score=0.648 total time=   0.0s\n","[CV 5/5] END KNN__n_neighbors=23, KNN__weights=distance;, score=0.678 total time=   0.0s\n",">> Predicting on test dataset...\n","Best hyperparameters:\n"]},{"output_type":"display_data","data":{"text/plain":["   KNN__n_neighbors KNN__weights\n","0                 1      uniform"],"text/html":["\n","  <div id=\"df-c1ba5858-be70-4be5-9507-740f2310f879\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>KNN__n_neighbors</th>\n","      <th>KNN__weights</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>uniform</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c1ba5858-be70-4be5-9507-740f2310f879')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-c1ba5858-be70-4be5-9507-740f2310f879 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-c1ba5858-be70-4be5-9507-740f2310f879');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["None\n","\n","Test classification report\n","              precision    recall  f1-score   support\n","\n","           0       0.53      0.59      0.56        34\n","           1       0.82      0.78      0.80        83\n","\n","    accuracy                           0.73       117\n","   macro avg       0.67      0.69      0.68       117\n","weighted avg       0.74      0.73      0.73       117\n","\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 2 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["knn_classifier_pca = Classifier('KNN', config_dict['CLASSIFICATION']['MODELS']['KNN'], \n","                            config_dict['CLASSIFICATION']['GENERAL'], \n","                            config_dict['CLASSIFICATION']['PARAMS']['KNN'], \n","                            class_balancer, \n","                            feature_scaler)\n","file_name = f'{knn_classifier_pca.name}_PCA.pkl'\n","\n","if  config_dict['GENERAL']['PERFORM_NCV']:\n","  knn_mean_score_pca, knn_std_score_pca = knn_classifier_pca.nested_cv(X_train, y_train, apply_PCA=True, num_components=num_components)\n","  save(knn_classifier_pca, os.path.join(MODELS_DIRPATH, file_name))\n","else:\n","  knn_classifier_pca = load(os.path.join(MODELS_DIRPATH, file_name))\n","  knn_classifier_pca.print_nested_cv_results()\n","\n","classifiers.append((knn_classifier_pca, \"PCA\"))\n","knn_classifier_pca.cv(X_train, X_test, y_train, y_test, apply_PCA=True)"]},{"cell_type":"code","execution_count":358,"metadata":{"id":"c77fk5Xww2ZG","colab":{"base_uri":"https://localhost:8080/","height":315},"executionInfo":{"status":"ok","timestamp":1661109722170,"user_tz":-120,"elapsed":10593,"user":{"displayName":"Elisa C","userId":"11182657622104819579"}},"outputId":"1f57fbbf-3fd5-4645-8651-cadcaec84a08"},"outputs":[{"output_type":"stream","name":"stdout","text":["{'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': None, 'n_neighbors': 1, 'p': 2, 'weights': 'uniform'}\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["params = knn_classifier_pca.best_model.named_steps[knn_classifier_pca.name].get_params()\n","print(params)\n","\n","plot_2D_svm_decision_boundary(X_train, y_train, X_test, y_test, neighbors.KNeighborsClassifier(**params), \n","                              features_pair=['DB','SGPT'], title=\"KNN + PCA\", apply_PCA=True)"]},{"cell_type":"code","source":["knn_classifier = Classifier('KNN', config_dict['CLASSIFICATION']['MODELS']['KNN'], \n","                            config_dict['CLASSIFICATION']['GENERAL'], \n","                            config_dict['CLASSIFICATION']['PARAMS']['KNN'], \n","                            class_balancer, \n","                            feature_scaler)\n","file_name = f'{knn_classifier.name}.pkl'\n","\n","if  config_dict['GENERAL']['PERFORM_NCV']:\n","  knn_mean_score, knn_std_score = knn_classifier.nested_cv(X_train, y_train, apply_PCA=False)\n","  save(knn_classifier, os.path.join(MODELS_DIRPATH, file_name))\n","else:\n","  knn_classifier = load(os.path.join(MODELS_DIRPATH, file_name))\n","  knn_classifier.print_nested_cv_results()\n","\n","classifiers.append((knn_classifier, \"All features\"))\n","knn_classifier.cv(X_train, X_test, y_train, y_test, apply_PCA=False)"],"metadata":{"id":"iFAaoZBwLMqF","executionInfo":{"status":"aborted","timestamp":1661109652633,"user_tz":-120,"elapsed":22,"user":{"displayName":"Elisa C","userId":"11182657622104819579"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["params = knn_classifier.best_model.named_steps[knn_classifier.name].get_params()\n","print(params)\n","\n","plot_2D_svm_decision_boundary(X_train, y_train, X_test, y_test, neighbors.KNeighborsClassifier(**params), \n","                              features_pair=['DB','SGPT'], title=\"KNN\", apply_PCA=False)"],"metadata":{"id":"xvk5MI6ALPhL","executionInfo":{"status":"aborted","timestamp":1661109652633,"user_tz":-120,"elapsed":22,"user":{"displayName":"Elisa C","userId":"11182657622104819579"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aykO_m3pucUo"},"source":["###Logistic Regression"]},{"cell_type":"code","source":["display(pd.DataFrame(config_dict['CLASSIFICATION']['PARAMS']['LogisticRegression'], columns = ['LogisticRegression__penalty']).T)\n","display(pd.DataFrame(config_dict['CLASSIFICATION']['PARAMS']['LogisticRegression'], columns = ['LogisticRegression__C']).T)\n","display(pd.DataFrame(config_dict['CLASSIFICATION']['PARAMS']['LogisticRegression'], columns = ['LogisticRegression__max_iter']).T)\n","display(pd.DataFrame(config_dict['CLASSIFICATION']['PARAMS']['LogisticRegression'], columns = ['LogisticRegression__solver']).T)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":272},"id":"Z13UbvUwIkrU","executionInfo":{"status":"ok","timestamp":1661109734547,"user_tz":-120,"elapsed":521,"user":{"displayName":"Elisa C","userId":"11182657622104819579"}},"outputId":"c3cdd859-e7fb-4f74-a25e-3631643fce27"},"execution_count":359,"outputs":[{"output_type":"display_data","data":{"text/plain":["                              0   1\n","LogisticRegression__penalty  l1  l2"],"text/html":["\n","  <div id=\"df-050a6a0e-27ae-492d-a7cc-835b3af371a4\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>LogisticRegression__penalty</th>\n","      <td>l1</td>\n","      <td>l2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-050a6a0e-27ae-492d-a7cc-835b3af371a4')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-050a6a0e-27ae-492d-a7cc-835b3af371a4 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-050a6a0e-27ae-492d-a7cc-835b3af371a4');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["                           0     1    2    3     4      5       6\n","LogisticRegression__C  0.001  0.01  0.1  1.0  10.0  100.0  1000.0"],"text/html":["\n","  <div id=\"df-15d0503d-c801-41bf-a83d-662d675b1bd7\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>LogisticRegression__C</th>\n","      <td>0.001</td>\n","      <td>0.01</td>\n","      <td>0.1</td>\n","      <td>1.0</td>\n","      <td>10.0</td>\n","      <td>100.0</td>\n","      <td>1000.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-15d0503d-c801-41bf-a83d-662d675b1bd7')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-15d0503d-c801-41bf-a83d-662d675b1bd7 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-15d0503d-c801-41bf-a83d-662d675b1bd7');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["                                 0\n","LogisticRegression__max_iter  1000"],"text/html":["\n","  <div id=\"df-3eabf343-933d-4764-9f8b-cb02684f1a15\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>LogisticRegression__max_iter</th>\n","      <td>1000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3eabf343-933d-4764-9f8b-cb02684f1a15')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-3eabf343-933d-4764-9f8b-cb02684f1a15 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-3eabf343-933d-4764-9f8b-cb02684f1a15');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["                                    0\n","LogisticRegression__solver  liblinear"],"text/html":["\n","  <div id=\"df-0182619a-0d22-457a-9c35-c4b643472720\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>LogisticRegression__solver</th>\n","      <td>liblinear</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0182619a-0d22-457a-9c35-c4b643472720')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-0182619a-0d22-457a-9c35-c4b643472720 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-0182619a-0d22-457a-9c35-c4b643472720');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}]},{"cell_type":"code","execution_count":360,"metadata":{"id":"y0SH73SyuhaS","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1661109762724,"user_tz":-120,"elapsed":25170,"user":{"displayName":"Elisa C","userId":"11182657622104819579"}},"outputId":"63a5cb8a-6a43-444e-9b15-7d42b7c1acb0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Computing inner cross validation for grid search of best hyperparameters...\n","Fitting 5 folds for each of 14 candidates, totalling 70 fits\n","[CV 1/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.000 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.000 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.000 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.000 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.000 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.673 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.653 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.629 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.638 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.653 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.692 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.589 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.000 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.704 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.679 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.693 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.638 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.622 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.593 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.667 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.646 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.615 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.591 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.622 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.644 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.718 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.632 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.617 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.611 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.653 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.713 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.632 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.646 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.673 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.660 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.713 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.632 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.660 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.660 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.646 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.713 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.646 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.660 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.673 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.687 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.713 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.646 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.660 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.673 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.673 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.713 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.646 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.660 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.673 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.673 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.713 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.646 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.660 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.673 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.673 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.713 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.646 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.660 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.673 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.673 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.713 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.646 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.660 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.673 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.673 total time=   0.0s\n","\n","--------------------------------------------\n","\n","Inner CV (Hyperparameters and model selection): \n","  F1-score = 0.6757681268126813\n","  Best hyperparams = {'LogisticRegression__C': 10, 'LogisticRegression__max_iter': 1000, 'LogisticRegression__penalty': 'l1', 'LogisticRegression__solver': 'liblinear'}\n","Outer CV (Quality of model selection assessment): \n","  F1-score = 0.5490196078431372\n","\n","--------------------------------------------\n","\n","Computing inner cross validation for grid search of best hyperparameters...\n","Fitting 5 folds for each of 14 candidates, totalling 70 fits\n","[CV 1/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.000 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.000 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.000 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.000 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.000 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.602 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.639 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.622 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.633 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.718 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.660 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.620 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.694 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.704 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.697 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.645 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.660 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.607 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.617 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.713 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.645 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.652 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.541 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.609 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.700 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.673 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.660 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.581 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.646 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.693 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.619 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.687 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.589 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.667 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.705 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.626 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.674 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.604 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.680 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.717 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.626 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.701 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.619 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.687 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.705 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.626 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.701 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.619 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.687 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.705 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.626 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.701 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.619 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.687 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.705 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.626 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.701 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.619 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.687 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.705 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.626 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.701 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.619 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.687 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.705 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.626 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.701 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.619 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.687 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.705 total time=   0.0s\n","\n","--------------------------------------------\n","\n","Inner CV (Hyperparameters and model selection): \n","  F1-score = 0.6750046271806823\n","  Best hyperparams = {'LogisticRegression__C': 0.01, 'LogisticRegression__max_iter': 1000, 'LogisticRegression__penalty': 'l1', 'LogisticRegression__solver': 'liblinear'}\n","Outer CV (Quality of model selection assessment): \n","  F1-score = 0.7692307692307693\n","\n","--------------------------------------------\n","\n","Computing inner cross validation for grid search of best hyperparameters...\n","Fitting 5 folds for each of 14 candidates, totalling 70 fits\n","[CV 1/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.000 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.000 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.000 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.000 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.000 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.700 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.653 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.653 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.679 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.602 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.712 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.619 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.000 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.685 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.718 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.660 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.667 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.707 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.717 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.568 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.700 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.660 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.695 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.714 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.530 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.673 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.686 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.700 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.725 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.593 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.680 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.680 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.712 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.731 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.617 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.673 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.705 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.712 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.731 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.639 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.680 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.698 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.699 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.731 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.639 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.680 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.698 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.699 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.731 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.639 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.680 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.698 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.699 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.731 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.639 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.680 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.698 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.699 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.731 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.639 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.680 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.698 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.699 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.731 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.639 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.680 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.698 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.699 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.731 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.639 total time=   0.0s\n","\n","--------------------------------------------\n","\n","Inner CV (Hyperparameters and model selection): \n","  F1-score = 0.6918643555756958\n","  Best hyperparams = {'LogisticRegression__C': 1, 'LogisticRegression__max_iter': 1000, 'LogisticRegression__penalty': 'l2', 'LogisticRegression__solver': 'liblinear'}\n","Outer CV (Quality of model selection assessment): \n","  F1-score = 0.7457627118644068\n","\n","--------------------------------------------\n","\n","Computing inner cross validation for grid search of best hyperparameters...\n","Fitting 5 folds for each of 14 candidates, totalling 70 fits\n","[CV 1/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.000 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.000 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.000 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.000 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.000 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.589 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.581 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.632 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.738 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.667 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.604 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.621 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.692 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.764 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.766 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.598 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.653 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.660 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.713 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.653 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.633 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.653 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.622 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.673 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.630 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.620 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.680 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.630 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.699 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.667 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.667 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.680 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.630 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.699 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.687 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.680 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.667 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.660 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.699 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.673 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.680 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.653 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.660 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.699 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.673 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.680 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.653 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.674 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.699 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.673 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.667 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.653 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.674 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.699 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.673 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.667 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.653 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.674 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.699 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.673 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.667 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.653 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.674 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.699 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.673 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.667 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.653 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.674 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.699 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.673 total time=   0.0s\n","\n","--------------------------------------------\n","\n","Inner CV (Hyperparameters and model selection): \n","  F1-score = 0.6895650172197219\n","  Best hyperparams = {'LogisticRegression__C': 0.01, 'LogisticRegression__max_iter': 1000, 'LogisticRegression__penalty': 'l1', 'LogisticRegression__solver': 'liblinear'}\n","Outer CV (Quality of model selection assessment): \n","  F1-score = 0.6071428571428571\n","\n","--------------------------------------------\n","\n","Computing inner cross validation for grid search of best hyperparameters...\n","Fitting 5 folds for each of 14 candidates, totalling 70 fits\n","[CV 1/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.000 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.000 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.000 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.000 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.000 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.645 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.552 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.686 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.639 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.673 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.653 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.634 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.739 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.667 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.646 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.652 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.545 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.667 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.680 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.680 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.645 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.575 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.622 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.660 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.615 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.673 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.545 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.652 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.724 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.705 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.667 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.593 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.660 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.736 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.692 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.667 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.611 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.660 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.736 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.686 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.653 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.596 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.674 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.736 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.686 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.653 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.604 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.674 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.736 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.686 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.653 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.589 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.674 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.736 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.686 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.653 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.589 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.674 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.736 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.686 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.653 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.589 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.674 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.736 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.686 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.653 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.589 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.674 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.736 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.686 total time=   0.0s\n","\n","--------------------------------------------\n","\n","Inner CV (Hyperparameters and model selection): \n","  F1-score = 0.6716661585718612\n","  Best hyperparams = {'LogisticRegression__C': 1, 'LogisticRegression__max_iter': 1000, 'LogisticRegression__penalty': 'l2', 'LogisticRegression__solver': 'liblinear'}\n","Outer CV (Quality of model selection assessment): \n","  F1-score = 0.6296296296296297\n","\n","--------------------------------------------\n","\n","Computing inner cross validation for grid search of best hyperparameters...\n","Fitting 5 folds for each of 14 candidates, totalling 70 fits\n","[CV 1/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.000 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.000 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.000 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.000 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.000 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.612 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.614 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.609 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.713 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.647 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.642 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.706 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.000 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.727 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.679 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.674 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.581 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.630 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.706 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.712 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.680 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.519 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.630 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.680 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.653 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.693 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.598 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.660 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.705 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.680 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.718 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.614 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.639 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.705 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.679 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.725 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.614 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.646 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.710 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.679 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.718 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.607 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.653 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.722 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.679 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.718 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.607 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.653 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.722 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.679 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.718 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.607 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.653 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.722 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.679 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.718 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.607 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.653 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.722 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.679 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.718 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.607 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.653 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.722 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.679 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.718 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.607 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.653 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.722 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.692 total time=   0.0s\n","\n","--------------------------------------------\n","\n","Inner CV (Hyperparameters and model selection): \n","  F1-score = 0.6784120813468405\n","  Best hyperparams = {'LogisticRegression__C': 1000, 'LogisticRegression__max_iter': 1000, 'LogisticRegression__penalty': 'l2', 'LogisticRegression__solver': 'liblinear'}\n","Outer CV (Quality of model selection assessment): \n","  F1-score = 0.5416666666666666\n","\n","--------------------------------------------\n","\n","Computing inner cross validation for grid search of best hyperparameters...\n","Fitting 5 folds for each of 14 candidates, totalling 70 fits\n","[CV 1/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.000 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.000 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.000 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.000 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.000 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.667 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.630 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.596 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.811 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.596 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.686 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.712 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.640 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.739 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.660 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.646 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.622 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.574 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.811 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.638 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.680 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.591 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.535 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.765 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.591 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.641 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.607 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.587 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.815 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.660 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.660 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.622 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.581 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.804 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.646 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.667 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.637 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.619 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.807 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.646 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.673 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.652 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.626 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.807 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.646 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.673 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.652 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.626 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.807 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.646 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.673 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.652 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.626 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.807 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.646 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.673 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.652 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.626 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.807 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.646 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.673 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.652 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.626 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.807 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.646 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.673 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.652 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.626 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.807 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.646 total time=   0.0s\n","\n","--------------------------------------------\n","\n","Inner CV (Hyperparameters and model selection): \n","  F1-score = 0.6873103420162244\n","  Best hyperparams = {'LogisticRegression__C': 0.01, 'LogisticRegression__max_iter': 1000, 'LogisticRegression__penalty': 'l1', 'LogisticRegression__solver': 'liblinear'}\n","Outer CV (Quality of model selection assessment): \n","  F1-score = 0.6551724137931034\n","\n","--------------------------------------------\n","\n","Computing inner cross validation for grid search of best hyperparameters...\n","Fitting 5 folds for each of 14 candidates, totalling 70 fits\n","[CV 1/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.000 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.000 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.000 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.000 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.000 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.674 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.556 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.619 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.680 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.667 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.705 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.608 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.673 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.000 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.000 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.680 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.578 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.652 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.680 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.660 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.638 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.562 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.630 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.681 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.673 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.692 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.565 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.638 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.725 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.692 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.692 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.527 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.632 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.725 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.710 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.692 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.543 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.673 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.731 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.698 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.686 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.543 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.673 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.731 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.710 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.686 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.543 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.673 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.743 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.704 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.686 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.543 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.673 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.743 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.704 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.686 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.543 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.673 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.743 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.704 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.686 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.543 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.673 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.743 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.704 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.686 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.543 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.673 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.743 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.704 total time=   0.0s\n","\n","--------------------------------------------\n","\n","Inner CV (Hyperparameters and model selection): \n","  F1-score = 0.66984455617996\n","  Best hyperparams = {'LogisticRegression__C': 10, 'LogisticRegression__max_iter': 1000, 'LogisticRegression__penalty': 'l2', 'LogisticRegression__solver': 'liblinear'}\n","Outer CV (Quality of model selection assessment): \n","  F1-score = 0.7407407407407407\n","\n","--------------------------------------------\n","\n","Computing inner cross validation for grid search of best hyperparameters...\n","Fitting 5 folds for each of 14 candidates, totalling 70 fits\n","[CV 1/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.000 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.000 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.000 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.000 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.000 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.647 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.500 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.735 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.660 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.660 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.667 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.598 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.796 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.686 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.635 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.686 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.500 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.716 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.681 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.625 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.667 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.482 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.716 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.645 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.617 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.710 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.529 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.713 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.680 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.639 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.705 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.533 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.693 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.713 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.632 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.705 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.533 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.693 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.725 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.660 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.712 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.533 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.699 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.725 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.660 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.712 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.533 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.692 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.725 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.660 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.712 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.533 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.692 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.725 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.660 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.712 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.533 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.692 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.725 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.660 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.712 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.533 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.692 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.725 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.660 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.712 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.533 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.692 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.725 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.660 total time=   0.0s\n","\n","--------------------------------------------\n","\n","Inner CV (Hyperparameters and model selection): \n","  F1-score = 0.6763582003424331\n","  Best hyperparams = {'LogisticRegression__C': 0.01, 'LogisticRegression__max_iter': 1000, 'LogisticRegression__penalty': 'l1', 'LogisticRegression__solver': 'liblinear'}\n","Outer CV (Quality of model selection assessment): \n","  F1-score = 0.6779661016949152\n","\n","--------------------------------------------\n","\n","Computing inner cross validation for grid search of best hyperparameters...\n","Fitting 5 folds for each of 14 candidates, totalling 70 fits\n","[CV 1/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.000 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.000 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.000 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.000 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.000 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.694 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.667 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.660 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.535 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.687 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.686 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.673 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.693 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.686 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.680 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.708 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.653 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.653 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.500 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.714 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.637 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.632 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.687 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.512 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.740 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.706 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.673 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.706 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.539 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.727 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.686 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.693 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.712 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.533 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.733 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.693 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.686 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.705 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.549 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.733 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.680 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.693 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.724 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.549 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.733 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.680 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.693 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.724 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.549 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.733 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.680 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.693 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.724 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.549 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.733 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.680 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.693 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.724 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.549 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.733 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.680 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.693 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.724 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.549 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.733 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.680 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.693 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.724 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.549 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.733 total time=   0.0s\n","\n","--------------------------------------------\n","\n","Inner CV (Hyperparameters and model selection): \n","  F1-score = 0.683437290384325\n","  Best hyperparams = {'LogisticRegression__C': 0.01, 'LogisticRegression__max_iter': 1000, 'LogisticRegression__penalty': 'l1', 'LogisticRegression__solver': 'liblinear'}\n","Outer CV (Quality of model selection assessment): \n","  F1-score = 0.6779661016949152\n","\n","--------------------------------------------\n","\n","\n","--------------------------------------------\n","\n","Mean training F1-score = 0.6907116663847678 (0.008889485785707946)\n","Mean validation F1-score = 0.6594297600301141 (0.07517110385616643)\n","List of best hyperparameters to check stability: \n"]},{"output_type":"display_data","data":{"text/plain":["   LogisticRegression__C  LogisticRegression__max_iter  \\\n","0                  10.00                          1000   \n","1                   0.01                          1000   \n","2                   1.00                          1000   \n","3                   0.01                          1000   \n","4                   1.00                          1000   \n","5                1000.00                          1000   \n","6                   0.01                          1000   \n","7                  10.00                          1000   \n","8                   0.01                          1000   \n","9                   0.01                          1000   \n","\n","  LogisticRegression__penalty LogisticRegression__solver  \n","0                          l1                  liblinear  \n","1                          l1                  liblinear  \n","2                          l2                  liblinear  \n","3                          l1                  liblinear  \n","4                          l2                  liblinear  \n","5                          l2                  liblinear  \n","6                          l1                  liblinear  \n","7                          l2                  liblinear  \n","8                          l1                  liblinear  \n","9                          l1                  liblinear  "],"text/html":["\n","  <div id=\"df-3c1e97b8-cef2-4cd8-a6aa-55174607e010\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>LogisticRegression__C</th>\n","      <th>LogisticRegression__max_iter</th>\n","      <th>LogisticRegression__penalty</th>\n","      <th>LogisticRegression__solver</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>10.00</td>\n","      <td>1000</td>\n","      <td>l1</td>\n","      <td>liblinear</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.01</td>\n","      <td>1000</td>\n","      <td>l1</td>\n","      <td>liblinear</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1.00</td>\n","      <td>1000</td>\n","      <td>l2</td>\n","      <td>liblinear</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.01</td>\n","      <td>1000</td>\n","      <td>l1</td>\n","      <td>liblinear</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1.00</td>\n","      <td>1000</td>\n","      <td>l2</td>\n","      <td>liblinear</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>1000.00</td>\n","      <td>1000</td>\n","      <td>l2</td>\n","      <td>liblinear</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0.01</td>\n","      <td>1000</td>\n","      <td>l1</td>\n","      <td>liblinear</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>10.00</td>\n","      <td>1000</td>\n","      <td>l2</td>\n","      <td>liblinear</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>0.01</td>\n","      <td>1000</td>\n","      <td>l1</td>\n","      <td>liblinear</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0.01</td>\n","      <td>1000</td>\n","      <td>l1</td>\n","      <td>liblinear</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3c1e97b8-cef2-4cd8-a6aa-55174607e010')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-3c1e97b8-cef2-4cd8-a6aa-55174607e010 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-3c1e97b8-cef2-4cd8-a6aa-55174607e010');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["None\n","Fitting 5 folds for each of 14 candidates, totalling 70 fits\n","[CV 1/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.000 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.000 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.000 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.000 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.000 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.634 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.685 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.612 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.630 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=0.001, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.701 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.717 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.643 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.673 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.661 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.667 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.620 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.708 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.511 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.615 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=0.01, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.696 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.586 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.697 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.505 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.660 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.702 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.636 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.708 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.531 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.685 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=0.1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.713 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.648 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.702 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.545 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.679 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.712 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.654 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.702 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.588 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.673 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=1, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.712 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.648 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.696 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.615 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.673 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.733 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.648 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.713 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.615 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.673 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=10, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.723 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.661 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.696 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.615 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.667 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.727 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.661 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.696 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.615 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.667 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=100, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.727 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.661 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.696 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.615 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.667 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l1, LogisticRegression__solver=liblinear;, score=0.727 total time=   0.0s\n","[CV 1/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.661 total time=   0.0s\n","[CV 2/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.696 total time=   0.0s\n","[CV 3/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.615 total time=   0.0s\n","[CV 4/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.667 total time=   0.0s\n","[CV 5/5] END LogisticRegression__C=1000, LogisticRegression__max_iter=1000, LogisticRegression__penalty=l2, LogisticRegression__solver=liblinear;, score=0.727 total time=   0.0s\n",">> Predicting on test dataset...\n","Best hyperparameters:\n"]},{"output_type":"display_data","data":{"text/plain":["   LogisticRegression__C  LogisticRegression__max_iter  \\\n","0                     10                          1000   \n","\n","  LogisticRegression__penalty LogisticRegression__solver  \n","0                          l2                  liblinear  "],"text/html":["\n","  <div id=\"df-4a2f2d84-cfde-4064-8d4d-a6652a7600bd\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>LogisticRegression__C</th>\n","      <th>LogisticRegression__max_iter</th>\n","      <th>LogisticRegression__penalty</th>\n","      <th>LogisticRegression__solver</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>10</td>\n","      <td>1000</td>\n","      <td>l2</td>\n","      <td>liblinear</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4a2f2d84-cfde-4064-8d4d-a6652a7600bd')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-4a2f2d84-cfde-4064-8d4d-a6652a7600bd button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-4a2f2d84-cfde-4064-8d4d-a6652a7600bd');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["None\n","\n","Test classification report\n","              precision    recall  f1-score   support\n","\n","           0       0.52      0.88      0.65        34\n","           1       0.93      0.66      0.77        83\n","\n","    accuracy                           0.73       117\n","   macro avg       0.72      0.77      0.71       117\n","weighted avg       0.81      0.73      0.74       117\n","\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 2 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAATsAAAEWCAYAAAAZ7jAvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZhcZZn38e8v3YSsLFkIAcIelogBMYRVCKBOEGaAGVAWmciLMqiIC4roqIAyCLwqKsKryBYXdkRAdlA2hyVhJ2FJWANJCNkgGyTdfb9/nKeh0unuqu4+3VVd9ftc17m6zqlTz7mrTtddz3IWRQRmZtWuT7kDMDPrCU52ZlYTnOzMrCY42ZlZTXCyM7Oa4GRnZjWhrMlOUn9JN0t6R9K1XSjnaEl35hlbuUj6hKQXunkbSyVt2c7zr0r6ZHfG0B5Jm6YY6zrx2t9K+mF3xFUpuvL51LKSkp2koyRNTR/wHEm3Sdorh+0fBowAhkbE4Z0tJCL+HBGfziGebiUpJG3d3joR8UBEbNudcUTEoIh4OcV0uaQzO1uWpC9IejC/6CAiXk8xNnZ02xFxQkT8pNg2JN0r6b30Pz1f0l8kjexq7D2h1M+np0jaPP1vL03Tq5JOLXhekk6S9KykZZLekHStpI+2KOf0VM6u3RFn0WQn6VvAL4GzyBLTpsCFwME5bH8z4MWIaMihrF5PUn25Y6gxJ0bEIGBrYBDws7w30Jv3afoh/EIHXrJe+jyPBH4kaWJa/ivg68BJwBBgG+CvwIEF2xLwn8DC9Dd/EdHmBKwLLAUOb2edtcmS4ew0/RJYOz03AXgDOBmYB8wBjk3PnQGsBFalbRwHnA78qaDszYEA6tP8F4CXgSXAK8DRBcsfLHjdHsAU4J30d4+C5+4FfgL8M5VzJzCsjffWHP8pBfEfAnwGeJFsx3y/YP3xwEPA4rTub4C+6bn703tZlt7v5wrK/y4wF/hj87L0mq3SNnZO8xsBbwMTWon1WODmgvkZwLUF87OAndLjIPuCH58+/5UpppvT868C3waeTp/h1UC/Nj6j1T77Fs+1tx+2SJ/JEuBu4ILmfV/Kfge2B94DGlPsi9O6lwNnFmznYOBJ4F3gJWBiwf/BFwvW+wowrWB+O+Cu9Pm/AHy24LmhwM2pzCnAmaz+/xfAV9M+eCUtOyjFsRj4X2BswfrfBd5M7+8FYP+C/6epaTtvAb9o4/PZCLgpxToT+FJB2acD1wB/SOVPA8a1970veO3lwBdKWG+1eNKyKel/aHTaR+OLlLE3sCLt2wWk702eU7E3MRFoKHwTrazzY+BhYANgeNqRPylIFg1pnbXIksRyYP2CHVGY3FrOf/AhAgPTTt82PTcS+EjLLxzZL8ci4Jj0uiPT/NCCf/KXyH5d+qf5s9tJdg3Aj1L8XyJLNlcAg4GPpB20RVr/48BuabubA88B32jxJdi6lfLPIfvR6E9BskvrfAmYDgwA7gB+1kasW5J9kfqQ/fO/xodJc8v0GfRpGQctkkNBsns0lTMkvY8TOpLsStgPD5HVpPoCe6V9u0ayK3W/t/iCnlmQLN4BPpU+l42B7VomO7LkdTdwY5ofSPbjcGyK4WPAfGBMev6qNA0AxqR1Wya7u9Jn0D+9fh6wK1AHTEqf8drAtun1GxW8960KPqNj0uNBwG5tJLv7yVpb/YCdyP5H9yv4Tr1H9t2rA34KPNxdyQ4QsCfZ93x/4ATgtRLKuIQsKa9Fluz+I+9kV6wZOxSYH+03M48GfhwR8yLibbIa2zEFz69Kz6+KiFvJfoU72yfVBOwgqX9EzImIaa2scyAwIyL+GBENEXEl8DzwrwXrXBYRL0bECrIPeKd2trkK+J+IWEX2Dz4M+FVELEnbnw7sCBARj0XEw2m7rwK/A/Yp4T2dFhHvp3hWExG/J/u1foTsi/7frRUSWR/ckvRe9iZLjLMlbZdieCAimorEUujXETE7IhaS1WLa+4xa0+Z+kLQpsAvwo4hYGREPktVM2lLKfm/NccClEXFXRDRFxJsR8Xzhe5T0DlkiGwZ8LS0/CHg1Ii5LsT8BXA8cngYF/oNsny2PiOnA5Fa2/dOIWJj26fHA7yLikYhojIjJwPtkP4yNZElvjKS1IuLViHgplbEK2FrSsIhYGhEPt9yIpFFkyeW7EfFeRDwJXMzqTcEHI+LWyPr4/kj6f+0G88lqlxcDp0bEPWQ5ZE57L5I0ADgcuCJ9z66jG5qyxZLdAmBYkX6H5lpEs9fSsg/KaJEsl5P9SnVIRCwja/qdAMyRdEv6IheLpzmmjQvm53YgngXxYUdwczJ6q+D5Fc2vl7SNpL9JmivpXbJ+zmHtlA3wdkS8V2Sd3wM7AOdHxPvtrHcfWc1w7/T4XrJEt0+a74iOfEataW8/bAQsjIjlBc/Naq2QDuz31owiq8W35aSIWBcYC6wPbJKWbwbsKmlx80T2o74hWeulvkW8rcVeuGwz4OQW5Y0iq83NBL5BVgObJ+kqSc3fn+PIWiDPS5oi6aBWttP8WS4pWFbs/71fW99pSU8XxHgUcGFB3Be29poCwyJi/YjYPiJ+nZYtIPuRbs+hZC2cW9P8n4EDJA0v8roOKZbsHiL7BTqknXVmk+3MZpumZZ2xjKxp0GzDwicj4o6I+BTZh/c8WRIoFk9zTG92MqaO+H9kcY2OiHWA75NV69vT7mVnJA0i6we9BDhd0pB2Vm9Odp9Ij++jeLLrrsvetLcf5gBD0i96s1FtFdTOfi8W+yyyfs92RcQzZP1uF6SO8lnAfRGxXsE0KCK+TNZEbODDxNhW7IWxzSJrHRSWNyDVdomIKyJiL7LPK8i6NYiIGRFxJFkX0TnAdZIGttjObLLPcnDBsk7/v0fE2OYYybprvlIQ81c6UeQ9wCaSxrWzziSyH9PXJc0FriVrzh7Vie21qd1kFxHvkPVXXSDpEEkDJK0l6QBJ56bVrgR+IGm4pGFp/T91Mp4ngb3TcUTrAt9rfkLSCEkHp539PllzuLVm2a3ANulwmXpJnyPrV/lbJ2PqiMFk/UtLU+3jyy2ef4us/6wjfgVMjYgvArcAv21n3fuAfYH+EfEG8ABZv+tQ4Ik2XtOZmFqSpH6FE+3sh4h4jazj/XRJfSXtzurdDIUFt7ff3yL7IvVtI65LgGMl7S+pj6SN26kVTiY72uDfyP5XtpF0TPp/X0vSLpK2T7X8v6TYB6TyijW5fg+cIGnXdBjGQEkHShosaVtJ+0lam6xvbUXz+5P0eUnDU/fD4lTWav/zETGLrJ/8p+mzH0tWI+zsdzBXETGDrD/xSkkT0v7uJ+kISadK2pisb+8gsq6Sncia2eeQc1O26KEnEfFz4FvAD8h+1WYBJ5INHUP2iziVbOTuGeDxtKzDIuIuspG/p4HHWD1B9UlxzCbrF9iHNZMJEbGA7IM7mawKfQpwUETM70xMHfRtsl+jJWT/4Fe3eP50YHJqEny2WGGSDiZLVs3v81vAzpKObm39iHiRLBk8kObfJRvF/Ge0fUzWJWT9RYsl/bWNdYrZg+xLWji9Q/v74Whg9/TcmWSfVWtN9Pb2+9/JRhfnSlpj/0bEo2SDDOeleO5jzdpm87oryX5YfpiahJ8GjkjbncuHg0iQ/f+vy4cj6Fe2EXtz2VPJBpp+QzZIM5NscIVU5tlk/V1zyWpxzT/yE4Fpkpam2I5orV+XbPBn8xTrDWT9iXe3FU8ZnET23i8gS9ovkTVdbybr338yIu6MiLnNE/BrYKykHfIKQhG+eKeVn6Srgecj4rRyx9JRks4BNoyISeWOxdrmc2OtLFKzcKvUvJxIdjxcZ2uWPUrSdpLGpibpeLJm4w3ljsva12uP7rZeb0Oyvq+hZAdWfzkd4tEbDCZrum5E1m/4c+DGskZkRbkZa2Y1wc1YM6sJvaoZWzdoYNQPae8wM6s0a89aVu4QrIOWsGh+RHT6gN5/2XdgLFhY2gVZHnv6/TsiYmLxNbuuVyW7+iFDGPmdb5Q7DOuA0V9f4wwnq3B3x3Utz3zpkAULG3n0jk1LWrdu5IxiZxjlplclOzOrfAE0tXq8f3k52ZlZroJgVWVcV3Q1TnZmljvX7Mys6gVBYwUe0uZkZ2a5a+q2i+l0npOdmeUqgEYnOzOrBa7ZmVnVC2CV++zMrNoF4WasmdWAgMbKy3VOdmaWr+wMisrjZGdmORONRe8z1fOc7MwsV9kAhZOdmVW57Dg7JzszqwFNrtmZWbVzzc7MakIgGivwjg9OdmaWuzybsZJeJbvxfCPQEBHjJA0hu7H65sCrwGcjYlF75VRe+jWzXi0QK6OupKkD9o2InSJiXJo/FbgnIkYD96T5djnZmVmusoOK+5Q0dcHBwOT0eDJwSLEXONmZWe4a04HFxSZgmKSpBdPxrRQXwJ2SHit4fkREzEmP5wIjisXkPjszy1WEaIyS61HzC5qmbdkrIt6UtAFwl6TnV99ehKSiZ+O6ZmdmuWtCJU2liIg30995wA3AeOAtSSMB0t95xcpxsjOzXGUDFPUlTcVIGihpcPNj4NPAs8BNwKS02iTgxmJluRlrZrlqHqDIyQjgBkmQ5asrIuJ2SVOAayQdB7wGfLZYQU52Zpa7xpyOs4uIl4EdW1m+ANi/I2U52ZlZrnwGhZnVjKbSR2N7jJOdmeUquxCAk52ZVblArOrYqWA9wsnOzHIVQUcOKu4xTnZmlrPSDxjuSU52ZparwDU7M6sRHqAws6oXyPegMLPql91KsfJSS+VFZGa9nG+SbWY1IPAZFGZWI1yzM7OqFyHX7Mys+mUDFD5dzMyqXofuQdFjnOzMLFfZAIX77MysBvgMCjOrej6DwsxqRo433MmNk52Z5SoCVjU52ZlZlcuasU52ZlYDfAaFoVVNbPLraaghoClYuuMQFn5mFPUL3mPk5Bn0WdbA+6MGMvfzW0N95f06WqZPn+D8219kwZy1+NGkLcsdTkXxoSdtkDQR+BVQB1wcEWeXOaRuFfXijRPHEGvXQWMTo341jeVj1mO9f8xh0YSRLN15GBtc/TLrPjyPd/basNzhWhsO+eJ8Zs3ox4BBjeUOpQJVZjO2rBFJqgMuAA4AxgBHShpTzpi6nZQlOkCNAY1BAANmvMvSHYcC8O744Qx8ZlEZg7T2DBu5kvH7v8ttVwwpdygVqyndh6LY1JPKXbMbD8yMiJcBJF0FHAxML2tU3a0p2PRnz7DW2++x+BMjWDWsH43966Au2/kN6/WlfvHKMgdpbTnhjNlcfOZIBgxqKncoFSkbja28c2PLXdfcGJhVMP9GWvYBScdLmippauPSZT0aXLfpI14/ZSyvnLEz/V5bRt+3VpQ7IivRrp98l8Xz65n5zIByh1Kxmg8qLmXqSeWu2RUVERcBFwGsvemoKHM4uWoaUM+K0evQ79Wl1K1ohMaAOlG/eCUN6/Utd3jWijG7LGO3T7/LLvtPp+/awYDBjZxy/muc+7XNyh1aRfGtFNf0JjCqYH6TtKxq1S1dRfQRTQPq0comBrzwDov234jlo9dh0FMLWLrzMNZ59G2W7bB+uUO1Vlz205Fc9tORAIzdfSmHnTDPia4Fj8a2bgowWtIWZEnuCOCo8obUvereWcmIP7+EmoAIln5sKMt2WJ/3N+zPyMkzGHrLLN7fZCDv7r5BuUM167RKHI0ta7KLiAZJJwJ3kB16cmlETCtnTN1t5cYDmXXK2DWWNwzrx6yTP1qGiKyznn5oEE8/NKjcYVScCNHgZLemiLgVuLXccZhZfiqxGVt56dfMerXmPrs8R2Ml1Ul6QtLf0vwWkh6RNFPS1ZKKjug52ZlZ7rrh0JOvA88VzJ8DnBcRWwOLgOOKFeBkZ2a5yvs4O0mbAAcCF6d5AfsB16VVJgOHFCun7H12ZlZ9OnCc3TBJUwvmL0rH1hb6JXAKMDjNDwUWR0RDml/jZITWONmZWa4ioKH0i3fOj4hxbT0p6SBgXkQ8JmlCV+JysjOz3OU4Grsn8G+SPgP0A9Yhu0rSepLqU+2upJMR3GdnZrnKs88uIr4XEZtExOZkJx38PSKOBv4BHJZWmwTcWKwsJzszy12ESpq64LvAtyTNJOvDu6TYC9yMNbPcdceFACLiXuDe9PhlskvElczJzsxyFVGZZ1A42ZlZzkSjb6VoZrWgi/1x3cLJzsxy5evZmVltiKzfrtI42ZlZ7nxZdjOreuEBCjOrFW7GmllN8GismVW9CCc7M6sRPvTEzGqC++zMrOoFosmjsWZWCyqwYudkZ2Y58wCFmdWMCqzaOdmZWe6qrmYn6XzayeERcVJXyjez3ieApqYqS3bA1OKrmFlNCaDaanYRMblwXtKAiFjetZDMrLerxOPscjkYRtLukqYDz6f5HSVdmEfZZtYLRYlTD8rryL9fAv8CLACIiKeAvXMq28x6ldJuo9jTgxi5jcZGxCxpteAb8yrbzHqZCmzG5pXsZknaAwhJawFfB57LqWwz600CogJHY/Nqxp4AfBXYGJgN7JTmzawmqcSp5+RSs4uI+cDReZRlZlWgApuxeY3GbinpZklvS5on6UZJW+ZRtpn1QlU8GnsFcA0wEtgIuBa4Mqeyzaw3aT6ouJSpB+WV7AZExB8joiFNfwL65VS2mfUyEaVNPamr58YOSQ9vk3QqcBVZXv8ccGsXYzOz3qoCR2O7OkDxGFlya35n/1XwXADf62L5ZtYLqQIHKLp6buwWeQViZlWiDIMPpcjtDApJOwBjKOiri4g/5FW+mfUWPT/4UIpckp2k04AJZMnuVuAA4EHAyc6sFlVgzS6v0djDgP2BuRFxLLAjsG5OZZtZb9NU4lSEpH6SHpX0lKRpks5Iy7eQ9IikmZKultS3WFl5JbsVEdEENEhaB5gHjMqpbDPrTfI9zu59YL+I2JHsNNSJknYDzgHOi4itgUXAccUKyivZTZW0HvB7shHax4GHcirbzHoZRWlTMZFZmmbXSlMA+wHXpeWTgUOKlZXXubFfSQ9/K+l2YJ2IeDqPss2sFyq9z26YpMLbO1wUERcVriCpjqwStTVwAfASsDgiGtIqb5BdhKRdXT2oeOf2nouIx7tSvplVvfkRMa69FSKiEdgptR5vALbrzIa6WrP7eTvPNVc1c6MmqF9ReUPa1rY7Zj9Z7hCsg+pGdr2M7jioOCIWS/oHsDuwnqT6VLvbBHiz2Ou7elDxvl15vZlVoSC308UkDQdWpUTXH/gU2eDEP8iOArkKmATcWKws3yTbzPKXX81uJDA59dv1Aa6JiL+lG3xdJelM4AngkmIFOdmZWe7yasamgc6PtbL8ZWB8R8pysjOz/FXrGRTKfF7Sj9L8ppI6lHXNrIpU8ZWKLyQbITkyzS8hOx7GzGpMqQcU9/RloPJqxu4aETtLegIgIhaVcq6amVWpKrx4Z7NVabQk4IPh4hJO8zWzalSJF+/Mqxn7a7IjmzeQ9D9kl3c6K6eyzay3qcA+u7zOjf2zpMfILvMk4JCIeC6Pss2slylDf1wp8rp456bAcuDmwmUR8Xoe5ZtZL1OtyQ64hQ9vvNMP2AJ4AfhITuWbWS+iCuyxz6sZ+9HC+XQ1lK+0sbqZWY/rljMoIuJxSbt2R9lm1gtUazNW0rcKZvsAOwOz8yjbzHqZah6gAAYXPG4g68O7Pqeyzay3qcZklw4mHhwR384hHjOrBtWW7JqvFCppz7wCMrPeTVTnaOyjZP1zT0q6CbgWWNb8ZET8pYvlm1lvU+V9dv2ABWT3nGg+3i4AJzuzWlSFyW6DNBL7LB8muWYV+HbNrEdU4Le/q8muDhjE6kmuWQW+XTPrCdXYjJ0TET/OJRIzqx5VmOwq7wp9ZlZeUZ2jsfvnEoWZVZdqq9lFxMK8AjGz6lGNfXZmZmtysjOzqleGS66XwsnOzHIl3Iw1sxrhZGdmtcHJzsxqgpOdmVW9Kr/qiZnZh5zszKwWVOPpYmZma6jEZmyfcgdgZlUmOjAVIWmUpH9Imi5pmqSvp+VDJN0laUb6u36xspzszCx/OSU7srsVnhwRY4DdgK9KGgOcCtwTEaOBe9J8u5zszCxXzWdQlDIVExFzIuLx9HgJ8BywMXAwMDmtNhk4pFhZ7rMzs9ypKf9OO0mbAx8DHgFGRMSc9NRcYESx1zvZmVm+OnYhgGGSphbMXxQRF7VcSdIg4HrgGxHxrvThdYMjIqTi9UQnOzPLXQdGY+dHxLh2y5LWIkt0fy64PetbkkZGxBxJI4F5xTbkPjszy19+o7ECLgGei4hfFDx1EzApPZ4E3FisLNfszCx3OR5ntydwDPCMpCfTsu8DZwPXSDoOeA34bLGCnOzMLH85JbuIeJC2b+zVoXvgONmZWb6q9O5iZmar8ZWKzax2ROVlOyc7M8uda3bGhgOWcu5ef2dYvxUEcPWL2/OH58ey/frzOWO3+1m7rpGGpj6c8chePL2g6EHh1kP+c/wY+g9qpE8fqKsPfnP7i/zxZxty2xVDWHdIIwDHfm824/dfUuZIK4DvLrYmSZcCBwHzImKHcsbSUxpDnD11d6YvHM7A+pX85aDr+eecTfjOxx/mN0+N4/7Zm7LPxq/xnY8/zDF3HlzucK3AudfOZN2hjastO/RLb3P4l98uU0SVqxIHKMp9UPHlwMQyx9Cj3l4xkOkLhwOwrKEvL72zPiMGLCOAQX1XAjBorZXMWzGwjFGadY2aSpt6UllrdhFxfzq5tyZtPPBdxgyZz1PzR3DWlD255JO38N2PP0QfBZ+77dByh2eFFHz/yK1AcOAxC/jM5xcAcPNlw7nnuiGMHruc40+bzeD1GosUVAMCD1B0hqTjgeMB6tcren2+XmNA/SrOn3AnZ03Zg2Wr+nLkNo9y1pQ9uPP1LTlgs5mctce9fOGufy13mJb84q8zGTZyFYvn13PqEVsxauv3OGjSfI765lwkmHzuhlx0xkacfN6scodaESpxgKLczdiiIuKiiBgXEePqBlZH065ejZw/4Q5ufnk0d76+JQCHbvUid76+BQC3vbYVY4cWPa/ZetCwkasAWG9YA3tOfIfnnxjA+sMbqKuDPn3ggKMX8sKTA8ocZQXJ7+Kduan4ZFd9grP2uI+XFq/PZc/t+MHSecsHMH7EbAB23/BNXl2ybrkCtBbeW96H5Uv7fPD4sfsGs/l277HgrQ8bRv9727psvu175QqxouR58c48VXwzttp8fIO5HLLVizy/aAg3HnQtAL94Yjw/eHgf/nuXf1Kv4P3GOn740D5ljtSaLXq7njOOy2rdjQ2w76GL2WXfJZz7tU15aVp/JBixyUpOOtdNWAAiuuXinV1V7kNPrgQmkF3A7w3gtIi4pJwxdbfH5o1kmz+c0Opz/37LYT0cjZVi5GYr+e3dL6yx/JTzXy9DNL1E5eW6so/GHlnO7ZtZ96jEAQo3Y80sXwG4GWtmNaHycp2TnZnlz81YM6sJHo01s+rnq56YWS3IDiquvGznZGdm+avASzw52ZlZ7lyzM7Pq5z47M6sNPjfWzGqFm7FmVvV8k2wzqxmu2ZlZTai8XOdkZ2b5U1PltWOd7MwsX4EPKjaz6ifCBxWbWY1wsjOzmuBkZ2ZVr0L77HzfWDPLnZqaSpqKliNdKmmepGcLlg2RdJekGenv+qXE5GRnZjmLrBlbylTc5cDEFstOBe6JiNHAPWm+KCc7M8tXkFuyi4j7gYUtFh8MTE6PJwOHlBKW++zMLH+l99kNkzS1YP6iiLioyGtGRMSc9HguMKKUDTnZmVnuOnCc3fyIGNfZ7URESKXdy8zNWDPLX359dq15S9JIgPR3XikvcrIzs3xFQGNTaVPn3ARMSo8nATeW8iInOzPLX041O0lXAg8B20p6Q9JxwNnApyTNAD6Z5otyn52Z5S+nMygi4sg2ntq/o2U52ZlZvgLwPSjMrPoFROWdL+ZkZ2b5Croy+NBtnOzMLH++6omZ1QQnOzOrfl06YLjbONmZWb4C8A13zKwmuGZnZtUvPBprZjUgIHycnZnVBJ9BYWY1wX12Zlb1Ijwaa2Y1wjU7M6t+QTQ2ljuINTjZmVm+fIknM6sZPvTEzKpdAOGanZlVvfDFO82sRlTiAIWiAoeI2yLpbeC1csfRTYYB88sdhJWsmvfXZhExvLMvlnQ72edTivkRMbGz2+qIXpXsqpmkqV25M7r1LO+v3sf3jTWzmuBkZ2Y1wcmuclxU7gCsQ7y/ehn32ZlZTXDNzsxqgpOdmdUEJ7sykDRR0guSZko6tdzxWPskXSppnqRnyx2LdZ6TXQ+TVAdcABwAjAGOlDSmvFFZEZcDPXLgq3UfJ7ueNx6YGREvR8RK4Crg4DLHZO2IiPuBheWOw7rGya7nbQzMKph/Iy0zs27kZGdmNcHJrue9CYwqmN8kLTOzbuRk1/OmAKMlbSGpL3AEcFOZYzKrek52PSwiGoATgTuA54BrImJaeaOy9ki6EngI2FbSG5KOK3dM1nE+XczMaoJrdmZWE5zszKwmONmZWU1wsjOzmuBkZ2Y1wcmuykhqlPSkpGclXStpQBfKulzSYenxxe1dsEDSBEl7dGIbr0pa405UbS1vsc7SDm7rdEnf7miMVh2c7KrPiojYKSJ2AFYCJxQ+KalT9wqOiC9GxPR2VpkAdDjZmfUUJ7vq9gCwdap1PSDpJmC6pDpJ/1fSFElPS/ovAGV+k661dzewQXNBku6VNC49nijpcUlPSbpH0uZkSfWbqVb5CUnDJV2ftjFF0p7ptUMl3SlpmqSLARV7E5L+Kumx9JrjWzx3Xlp+j6ThadlWkm5Pr3lA0nZ5fJjWu3XqV94qX6rBHQDcnhbtDOwQEa+khPFOROwiaW3gn5LuBD4GbEt2nb0RwHTg0hblDgd+D+ydyhoSEQsl/RZYGhE/S+tdAZwXEQ9K2pTsjJHtgdOAByPix5IOBEo5G+H/pG30B6ZIuj4iFgADgakR8U1JP0pln0h2M5wTImKGpF2BC4H9OvExWhVxsqs+/SU9mR4/AFxC1rx8NCJeScs/DYxt7o8D1gVGA3sDV0ZEIzBb0t9bKX834P7msiKireu8fRIYI31QcVtH0qC0jX9Pr71F0qIS3tNJkg5Nj0elWBcATcDVafmfgL+kbewBXFuw7bVL2KEjHZQAAAE0SURBVIZVOSe76rMiInYqXJC+9MsKFwFfi4g7Wqz3mRzj6APsFhHvtRJLySRNIEucu0fEckn3Av3aWD3Sdhe3/AzM3GdXm+4AvixpLQBJ20gaCNwPfC716Y0E9m3ltQ8De0vaIr12SFq+BBhcsN6dwNeaZyQ1J5/7gaPSsgOA9YvEui6wKCW67chqls36AM2106PImsfvAq9IOjxtQ5J2LLINqwFOdrXpYrL+uMfTTWR+R1bLvwGYkZ77A9mVPlYTEW8Dx5M1GZ/iw2bkzcChzQMUwEnAuDQAMp0PR4XPIEuW08ias68XifV2oF7Sc8DZZMm22TJgfHoP+wE/TsuPBo5L8U3Dl703fNUTM6sRrtmZWU1wsjOzmuBkZ2Y1wcnOzGqCk52Z1QQnOzOrCU52ZlYT/j+8WMx+6qFZWgAAAABJRU5ErkJggg==\n"},"metadata":{"needs_background":"light"}}],"source":["logistic_classifier_pca = Classifier('LogisticRegression', config_dict['CLASSIFICATION']['MODELS']['LogisticRegression'], \n","                            config_dict['CLASSIFICATION']['GENERAL'], \n","                            config_dict['CLASSIFICATION']['PARAMS']['LogisticRegression'], \n","                            class_balancer, \n","                            feature_scaler)\n","file_name = f'{logistic_classifier_pca.name}_PCA.pkl'\n","\n","if config_dict['GENERAL']['PERFORM_NCV']:\n","  logistic_mean_score_pca, logistic_std_score_pca = logistic_classifier_pca.nested_cv(X_train, y_train, apply_PCA=True, num_components=num_components)\n","  save(logistic_classifier_pca, os.path.join(MODELS_DIRPATH, file_name))\n","else:\n","  logistic_classifier_pca = load(os.path.join(MODELS_DIRPATH, file_name))\n","  logistic_classifier_pca.print_nested_cv_results()\n","\n","classifiers.append((logistic_classifier_pca, \"PCA\"))\n","logistic_classifier_pca.cv(X_train, X_test, y_train, y_test, apply_PCA=True)"]},{"cell_type":"code","execution_count":361,"metadata":{"id":"_V1WN380yCQO","colab":{"base_uri":"https://localhost:8080/","height":315},"executionInfo":{"status":"ok","timestamp":1661109768375,"user_tz":-120,"elapsed":363,"user":{"displayName":"Elisa C","userId":"11182657622104819579"}},"outputId":"3fb5f494-5001-4283-d9d2-769c2f7c2f93"},"outputs":[{"output_type":"stream","name":"stdout","text":["{'C': 10, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'liblinear', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["params = logistic_classifier_pca.best_model.named_steps[logistic_classifier_pca.name].get_params()\n","print(params)\n","\n","plot_2D_svm_decision_boundary(X_train, y_train, X_test, y_test, linear_model.LogisticRegression(**params), \n","                              features_pair=['DB','SGPT'], title=\"Logistic Regression + PCA\", apply_PCA=True)"]},{"cell_type":"code","source":["logistic_classifier = Classifier('LogisticRegression', config_dict['CLASSIFICATION']['MODELS']['LogisticRegression'], \n","                                 config_dict['CLASSIFICATION']['GENERAL'], \n","                                 config_dict['CLASSIFICATION']['PARAMS']['LogisticRegression'], \n","                                 class_balancer, \n","                                 feature_scaler)\n","file_name = f'{logistic_classifier.name}.pkl'\n","\n","if config_dict['GENERAL']['PERFORM_NCV']:\n","  logistic_mean_score, logistic_std_score = logistic_classifier.nested_cv(X_train, y_train, apply_PCA=False)\n","  save(logistic_classifier, os.path.join(MODELS_DIRPATH, file_name))\n","else:\n","  logistic_classifier = load( os.path.join(MODELS_DIRPATH, file_name))\n","  logistic_classifier.print_nested_cv_results()\n","\n","classifiers.append((logistic_classifier, \"All features\"))\n","logistic_classifier.cv(X_train, X_test, y_train, y_test, apply_PCA=False)"],"metadata":{"id":"Dsid99kmM9UI","executionInfo":{"status":"aborted","timestamp":1661109652635,"user_tz":-120,"elapsed":23,"user":{"displayName":"Elisa C","userId":"11182657622104819579"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["params = logistic_classifier.best_model.named_steps[logistic_classifier.name].get_params()\n","print(params)\n","\n","plot_2D_svm_decision_boundary(X_train, y_train, X_test, y_test, linear_model.LogisticRegression(**params), \n","                              features_pair=['DB','SGPT'], title=\"Logistic Regression\", apply_PCA=False)"],"metadata":{"id":"mPKVVLTTM-3z","executionInfo":{"status":"aborted","timestamp":1661109652635,"user_tz":-120,"elapsed":23,"user":{"displayName":"Elisa C","userId":"11182657622104819579"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":366,"metadata":{"id":"2miWtkeuUGwQ","colab":{"base_uri":"https://localhost:8080/","height":695},"executionInfo":{"status":"ok","timestamp":1661109879259,"user_tz":-120,"elapsed":294,"user":{"displayName":"Elisa C","userId":"11182657622104819579"}},"outputId":"5796e123-980a-4b17-c8e6-40e4d5416ae1"},"outputs":[{"output_type":"stream","name":"stdout","text":["['Age' 'TB' 'DB' 'AAP' 'SGPT' 'SGOT' 'TP' 'ALB' 'AGR' 'Gender']\n","4\n","[ 0.42955678 -0.23927808 -0.18224565 -0.10965892 -0.27557144 -0.24446284\n"," -0.18224565 -0.30668004 -0.20298471 -0.27038668 -0.08373509 -0.32741911\n"," -0.31704957 -0.23409331 -0.06299602 -0.23927808 -0.34297341 -0.27038668\n"," -0.07855032 -0.09928939 -0.32223434  0.18587276 -0.24964761 -0.23409331\n"," -0.32223434 -0.26001714 -0.06818079  0.0562536   0.28956809 -0.32223434\n"," -0.3585277  -0.22372378  0.18068799  6.04984348 -0.30668004  0.27919855\n","  1.85018275 -0.22372378 -0.17187612 -0.23409331 -0.32741911  0.0406993\n","  0.06143837 -0.08373509 -0.29631051 -0.18224565 -0.36889724 -0.33778864\n"," -0.01633313 -0.27557144 -0.05781126 -0.27557144 -0.21853901 -0.34815817\n","  1.59094443 -0.35334294 -0.30149527 -0.27557144 -0.29112574 -0.36889724\n"," -0.28594098 -0.04744172  0.03032977 -0.26001714 -0.30149527 -0.32223434\n"," -0.01633313 -0.29631051 -0.30668004  1.37836902 -0.18224565 -0.3585277\n"," -0.36889724 -0.14595228 -0.13039799  0.13920986  0.49695874  1.52872724\n"," -0.31704957 -0.29112574 -0.33260387 -0.09928939 -0.33778864 -0.32223434\n"," -0.31186481 -0.31704957 -0.21335425  0.09773173 -0.11484369 -0.18743042\n"," -0.19779995 -0.26001714 -0.31186481 -0.04225696 -0.21853901 -0.18224565\n"," -0.28594098 -0.34815817 -0.28594098 -0.30668004 -0.29112574 -0.18743042\n"," -0.35334294  0.00959071 -0.34297341  0.43992631 -0.35334294 -0.24964761\n","  1.23319556 -0.26520191 -0.16150658 -0.30149527 -0.27557144 -0.30149527\n"," -0.04744172 -0.33778864 -0.21335425]\n","(117,)\n","(117,)\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["plot_logistic_curve(logistic_classifier_pca, \"SGPT\", X_test, y_test)"]},{"cell_type":"markdown","metadata":{"id":"nlp0Rcuzuklr"},"source":["###Decision tree"]},{"cell_type":"code","source":["display(pd.DataFrame(config_dict['CLASSIFICATION']['PARAMS']['DecisionTree'], columns = ['DecisionTree__max_depth']).T)\n","display(pd.DataFrame(config_dict['CLASSIFICATION']['PARAMS']['DecisionTree'], columns = ['DecisionTree__min_samples_split']).T)\n","display(pd.DataFrame(config_dict['CLASSIFICATION']['PARAMS']['DecisionTree'], columns = ['DecisionTree__criterion']).T)"],"metadata":{"id":"sL0x0YpWJSBl","executionInfo":{"status":"aborted","timestamp":1661109652637,"user_tz":-120,"elapsed":24,"user":{"displayName":"Elisa C","userId":"11182657622104819579"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cWT23g3cuqNp","executionInfo":{"status":"aborted","timestamp":1661109652637,"user_tz":-120,"elapsed":23,"user":{"displayName":"Elisa C","userId":"11182657622104819579"}}},"outputs":[],"source":["decision_tree_classifier = Classifier('DecisionTree', config_dict['CLASSIFICATION']['MODELS']['DecisionTree'], \n","                            config_dict['CLASSIFICATION']['GENERAL'], \n","                            config_dict['CLASSIFICATION']['PARAMS']['DecisionTree'], \n","                            class_balancer, \n","                            feature_scaler)\n","file_name = f'{decision_tree_classifier.name}.pkl'\n","\n","if config_dict['GENERAL']['PERFORM_NCV']:\n","  decision_tree_mean_score, decision_tree_std_score = decision_tree_classifier.nested_cv(X_train, y_train, apply_PCA=False, num_components=num_components)\n","  save(decision_tree_classifier, os.path.join(MODELS_DIRPATH, file_name))\n","else:\n","  decision_tree_classifier = load(os.path.join(MODELS_DIRPATH, file_name))\n","  decision_tree_classifier.print_nested_cv_results()\n","\n","classifiers.append(decision_tree_classifier)\n","decision_tree_classifier.cv(X_train, X_test, y_train, y_test, apply_PCA=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1YdjQ5mP0aRn","executionInfo":{"status":"aborted","timestamp":1661109652638,"user_tz":-120,"elapsed":24,"user":{"displayName":"Elisa C","userId":"11182657622104819579"}}},"outputs":[],"source":["params = decision_tree_classifier.best_model.named_steps[decision_tree_classifier.name].get_params()\n","print(params)\n","\n","plot_2D_svm_decision_boundary(X_train, y_train, X_test, y_test, tree.DecisionTreeClassifier(**params), \n","                              features_pair=['DB','SGPT'], title=\"Decision Tree\", apply_PCA=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4fTIGI3BfHGg","executionInfo":{"status":"aborted","timestamp":1661109652638,"user_tz":-120,"elapsed":24,"user":{"displayName":"Elisa C","userId":"11182657622104819579"}}},"outputs":[],"source":["plot_decision_tree(decision_tree_classifier, features_names, config_dict['GENERAL']['TARGET_COLUMN_NAME'], max_depth=5) # max_depth=None to show full tree"]},{"cell_type":"markdown","metadata":{"id":"LYX5K5nYuttr"},"source":["###Random forest"]},{"cell_type":"code","source":["display(pd.DataFrame(config_dict['CLASSIFICATION']['PARAMS']['RandomForest'], columns = ['RandomForest__criterion']).T)\n","display(pd.DataFrame(config_dict['CLASSIFICATION']['PARAMS']['RandomForest'], columns = ['RandomForest__max_depth']).T)\n","display(pd.DataFrame(config_dict['CLASSIFICATION']['PARAMS']['RandomForest'], columns = ['RandomForest__min_samples_split']).T)\n","display(pd.DataFrame(config_dict['CLASSIFICATION']['PARAMS']['RandomForest'], columns = ['RandomForest__max_features']).T)"],"metadata":{"id":"GLRnpHIMJg6y","executionInfo":{"status":"aborted","timestamp":1661109652638,"user_tz":-120,"elapsed":24,"user":{"displayName":"Elisa C","userId":"11182657622104819579"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hRotPzIvuvhm","executionInfo":{"status":"aborted","timestamp":1661109652639,"user_tz":-120,"elapsed":24,"user":{"displayName":"Elisa C","userId":"11182657622104819579"}}},"outputs":[],"source":["random_forest_classifier = Classifier('RandomForest', config_dict['CLASSIFICATION']['MODELS']['RandomForest'], \n","                            config_dict['CLASSIFICATION']['GENERAL'], \n","                            config_dict['CLASSIFICATION']['PARAMS']['RandomForest'], \n","                            class_balancer, \n","                            feature_scaler)\n","file_name = f'{random_forest_classifier.name}.pkl'\n","\n","if config_dict['GENERAL']['PERFORM_NCV']:\n","  random_forest_score, random_forset_std_score = random_forest_classifier.nested_cv(X_train, y_train, apply_PCA=False, num_components=num_components)\n","  save(random_forest_classifier, os.path.join(MODELS_DIRPATH, file_name))\n","else:\n","  random_forest_classifier = load(os.path.join(MODELS_DIRPATH, file_name))\n","  random_forest_classifier.print_nested_cv_results()\n","\n","classifiers.append(random_forest_classifier)\n","random_forest_classifier.cv(X_train, X_test, y_train, y_test, apply_PCA=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EPj73YOdyeGt","executionInfo":{"status":"aborted","timestamp":1661109652639,"user_tz":-120,"elapsed":24,"user":{"displayName":"Elisa C","userId":"11182657622104819579"}}},"outputs":[],"source":["params = random_forest_classifier.best_model.named_steps[random_forest_classifier.name].get_params()\n","print(params)\n","\n","plot_2D_svm_decision_boundary(X_train, y_train, X_test, y_test, ensemble.RandomForestClassifier(**params), \n","                              features_pair=['DB','SGPT'], title=\"Random forest\", apply_PCA=False)"]},{"cell_type":"markdown","metadata":{"id":"w9yyiXZgu4YO"},"source":["###Configure the final model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PfLKfgLbu6jx","executionInfo":{"status":"aborted","timestamp":1661109652640,"user_tz":-120,"elapsed":25,"user":{"displayName":"Elisa C","userId":"11182657622104819579"}}},"outputs":[],"source":["best_classifiers = []\n","best_score = 0\n","y_preds = []\n","clf_names = []\n","for classifier in classifiers:      \n","  if classifier.ncv_global_mean_score > best_score:\n","      best_score = classifier.ncv_global_mean_score\n","\n","for classifier in classifiers: \n","  if classifier.ncv_global_mean_score == best_score:\n","    best_classifiers.append(classifier)\n","  y_preds.append(classifier.y_pred)\n","  clf_names.append(classifier.name)\n","\n","for best_classifier in best_classifiers:\n","  if best_classifier.apply_PCA == True:        \n","    print(f'\\nBEST CLASSIFIER: {best_classifier.name} (F1-score={best_classifier.ncv_global_mean_score}), PCA applied')\n","  else:\n","    print(f'\\nBEST CLASSIFIER: {best_classifier.name} (F1-score={best_classifier.ncv_global_mean_score})')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PzQIvv2GHcSC","executionInfo":{"status":"aborted","timestamp":1661109652640,"user_tz":-120,"elapsed":25,"user":{"displayName":"Elisa C","userId":"11182657622104819579"}}},"outputs":[],"source":["plot_PRC(clf_names, y_preds, y_test)"]},{"cell_type":"markdown","metadata":{"id":"V0WwDsM_u1Qd"},"source":["##Conclusions"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"DataSpaces_project.ipynb","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.2"}},"nbformat":4,"nbformat_minor":0}