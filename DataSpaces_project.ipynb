{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DataSpaces_project.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyMwNSJd0wNLa3uyxFgIf6t5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Indian Liver Patient Dataset\n","Data Spaces (01RLPOV), A.A. 2021/22  <br /> \n","Politecnico di Torino - Corso di Laurea Magistrale in Ingegneria Informatica <br /> \n","Elisa Cenedese - s255202 <br /> \n","Link to data source: https://archive.ics.uci.edu/ml/datasets/ILPD+%28Indian+Liver+Patient+Dataset%29#"],"metadata":{"id":"mcVZmrfdlcux"}},{"cell_type":"markdown","source":["## Table of Contents\n","\n","* [1. Introduction](#introduction)\n","    * [1.1 Attributes description](#attributes_descr)\n","    * [1.2 Basic dataset exploration](#basic_dataset_exploration)\n","    * [1.3 Check_for_missing_values](#check_missing_values)\n","    * [1.4 Check_for_outliers](#check_outliers)\n","    * [1.5 Split_dataset](#split_dataset)\n","* [2. Exploratory data analysis](#exploratory_data_analysis)\n","    * [2.1 Statistical quantitative description of features](#stat_features_descr)\n","    * [2.2 Box plots](#box_plots)\n","    * [2.3 Correlation analysis](#corr_analysis)\n","      * [2.3.1 Heatmap](#heatmap)\n","      * [2.3.2 Dendogram](#dendogram)"],"metadata":{"id":"jykReSd3oKSj"}},{"cell_type":"code","source":["#Mount drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"l86AIQJkpO3z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Install\n","!pip install chart_studio\n","!pip install -U kaleido"],"metadata":{"id":"wjUmVeG1pR6R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%matplotlib inline\n","\n","#Imports\n","import pandas as pd\n","import os\n","import seaborn as sns\n","import numpy as np\n","import matplotlib\n","import matplotlib.pyplot as plt\n","import itertools\n","import math\n","import pickle\n","from numpy import mean\n","from numpy import std\n","#plot libaries\n","import plotly\n","import plotly.express as px\n","import plotly.graph_objects as go\n","import plotly.io as pio\n","import plotly.figure_factory as ff\n","import yaml\n","import pprint\n","\n","from matplotlib.colors import ListedColormap\n","from sklearn.model_selection import StratifiedKFold, GridSearchCV, cross_val_score, RandomizedSearchCV\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import plot_confusion_matrix\n","from sklearn import metrics\n","from sklearn.decomposition import PCA\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import make_scorer, f1_score\n","from imblearn.pipeline import Pipeline\n","from imblearn.over_sampling import SMOTE\n","from sklearn import tree, svm, linear_model, ensemble, neighbors \n","from sklearn.svm import LinearSVC\n","from sklearn import preprocessing\n","#from plotly.offline import init_notebook_mode\n","#init_notebook_mode(connected=True)\n","# online plotly\n","import chart_studio\n","chart_studio.tools.set_credentials_file(username='elisa_c', api_key='ixjDGQPn6k6yG1D96Wnr')\n","#chart_studio.tools.set_config_file(world_readable=False, sharing='secret')\n","import chart_studio.plotly as py\n","from scipy.cluster import hierarchy as hc"],"metadata":{"id":"7vkbnOiDpYpG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Paths\n","DATA_FILE_NAME = \"indian_liver_patient_dataset.csv\"\n","\n","ROOT_DIRPATH = os.path.join(\n","    '/content',\n","    'drive',\n","    'MyDrive',\n","    'DataSpaces',\n","    'DataSpaces_project',\n",")\n","\n","DATA_DIRPATH = os.path.join(\n","    ROOT_DIRPATH,\n","    'data',\n",")\n","\n","MODELS_DIRPATH = os.path.join(\n","    ROOT_DIRPATH,\n","    'models',\n",")\n","\n","data_file_path = os.path.join(DATA_DIRPATH, DATA_FILE_NAME)\n","\n","if not os.path.exists(MODELS_DIRPATH):\n","    os.makedirs(MODELS_DIRPATH)"],"metadata":{"id":"kvKw141nphNl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def read_dataset(dirpath: str, file_type: str, sheet_name_=None):\n","  if file_type == \"xlsx\":\n","    dataset_df = pd.read_excel(dirpath, sheet_name= sheet_name_)\n","  elif file_type == \"csv\":\n","    with open(dirpath) as in_fp:\n","      dataset_df = pd.read_csv(in_fp, sep=',', header=0)\n","  else:\n","    raise Exception(\"Unrecognised dataset format\")\n","  return dataset_df"],"metadata":{"id":"ovTSV__gpzLH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def show_dict(dict_: dict):\n","    pprint.pprint(dict_, width=1)"],"metadata":{"id":"VHBE5iBLqUDA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def print_formatted_list(str_, list):\n","  print(str_ + \":\")\n","  for value in list:\n","    print(\"  - \" + str(value))\n","  print()"],"metadata":{"id":"r5EhM1iMryCk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def prepare_bar_plot(df, title, template_):\n","  colors = plotly.colors.DEFAULT_PLOTLY_COLORS\n","  data_series = df.value_counts() # return series\n","  data = [go.Bar(x=data_series.index, y=data_series.values, marker = dict(color = colors[:len(data_series.index)]))]\n","  layout = go.Layout(\n","      #paper_bgcolor='rgba(0,0,0,0)',\n","      #plot_bgcolor='rgba(0,0,0,0)',\n","      title=title,\n","      template = template_,\n","      autosize=False,\n","      width=400,\n","      height=400,\n","      yaxis=dict(\n","          title='#samples',\n","      ),\n","  )\n","  fig = go.Figure(data=data, layout=layout)\n","  return fig, data_series"],"metadata":{"id":"xvJtnTKir4nZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def prepare_histogram_plot(X, features_names, class_names, config_dict, template_, per_feature=True):\n","  start_pos = 0\n","  data = []\n","  num_steps = len(features_names)\n","\n","  for count_class, target in enumerate(class_names):\n","    trace_list = []\n","    for count, feature in enumerate(features_names):\n","      if count != start_pos:\n","        trace_list.append(go.Histogram(x=X[feature].loc[X[config_dict['TARGET_COLUMN_NAME']] == target], name = target, visible = False))\n","      else: \n","        if per_feature and (count_class == 0 or count_class == 1):\n","            visibility_ =  True\n","        else:\n","            visibility_ =  'legendonly'\n","        trace_list.append(go.Histogram(x=X[feature].loc[X[config_dict['TARGET_COLUMN_NAME']] == target], name = target, visible = visibility_))\n","    data = data + trace_list\n","\n","  trace_list_all_classes = []\n","  for count, feature in enumerate(features_names):\n","      if count != start_pos:\n","        trace_list_all_classes.append(go.Histogram(x=X[feature], name = 'all', visible = False))\n","      else: \n","        if per_feature:\n","          visibility_ =  'legendonly'\n","        else:\n","           visibility_ = True\n","        trace_list_all_classes.append(go.Histogram(x=X[feature], name = 'all', visible = visibility_))\n","\n","  data = data + trace_list_all_classes\n","\n","  steps = []\n","\n","  for i in range(num_steps):\n","      # Hide all traces\n","      step = dict(\n","          method = 'restyle',  \n","          args = ['visible', [False] * len(data)],\n","          label = features_names[i],\n","      )\n","\n","      # Enable the traces we want to see\n","      for count, class_name in enumerate(class_names):\n","        #print(i+count*len(features_names))\n","        if per_feature and (count == 0 or count == 1):\n","          visibility_ =  True\n","        else:\n","          visibility_ =  'legendonly'\n","        step['args'][1][i+count*len(features_names)] = visibility_\n","     \n","      if per_feature:\n","        visibility_ = 'legendonly'\n","      else:\n","        visibility_ = True\n","      step['args'][1][i+(count+1)*len(features_names)] = visibility_\n","      \n","      # Add step to step list\n","      steps.append(step)\n","\n","  sliders = [dict(\n","      active = start_pos, # from where to start the slider\n","      currentvalue = dict(\n","          prefix = \"Feature: \", \n","          xanchor= 'center',\n","      ),\n","      pad = {\"t\": 50},\n","      steps = steps,\n","      len=1,\n","  )]\n","\n","  layout = dict(\n","      #paper_bgcolor='rgba(0,0,0,0)',\n","      #plot_bgcolor='rgba(0,0,0,0)',\n","      sliders=sliders,\n","      template = template_,  \n","      yaxis=dict(\n","          title='#Samples',\n","          automargin=True,\n","      ),\n","      #font=dict(\n","      #    color=font_color\n","      #)\n","  )\n","\n","  return go.Figure(data=data, layout=layout)"],"metadata":{"id":"Ha9zE_ezzrCR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def prepare_box_plot(X, features_names, class_names, config_dict, template_):\n","  active_pos = 0\n","  data = []\n","  num_steps = len(features_names)\n","\n","  for target in class_names:\n","    trace_list = []\n","    for count, feature in enumerate(features_names):\n","      if count != active_pos:\n","        trace_list.append(go.Box(y=X[feature].loc[X[config_dict['TARGET_COLUMN_NAME']] == target], name = target, visible = False))\n","      else:\n","         trace_list.append(go.Box(y=X[feature].loc[X[config_dict['TARGET_COLUMN_NAME']] == target], name = target, visible = True))\n","    data = data + trace_list\n","\n","  steps = []\n","\n","  for i in range(num_steps):\n","      # Hide all traces\n","      step = dict(\n","          method = 'restyle',  \n","          args = ['visible', [False] * len(data)],\n","          label = features_names[i],\n","      )\n","      # Enable the two traces we want to see\n","      for count, class_name in enumerate(class_names):\n","        #print(i+count*len(features_names))\n","        step['args'][1][i+count*len(features_names)] = True\n","        \n","      # Add step to step list\n","      steps.append(step)\n","\n","  sliders = [dict(\n","      active = active_pos,\n","      currentvalue = dict(\n","          prefix = \"Feature: \", \n","          xanchor= 'center',\n","      ),\n","      pad = {\"t\": 50},\n","      steps = steps,\n","      len=1,\n","  )]\n","\n","  layout = dict(\n","      #paper_bgcolor='rgba(0,0,0,0)',\n","      #plot_bgcolor='rgba(0,0,0,0)',\n","      sliders=sliders,\n","      template = template_,  \n","      yaxis=dict(\n","          title='Feature value',\n","          automargin=True,\n","      ),\n","      #font=dict(\n","      #    color=font_color\n","      #)\n","  )\n","\n","  return go.Figure(data=data, layout=layout)"],"metadata":{"id":"LQRqX9YQ-XLg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def prepare_dendogram(X, title_, template_):\n","  colors = plotly.colors.DEFAULT_PLOTLY_COLORS\n","  feature_names = X.columns\n","  inverse_correlation = 1 - abs(X.corr())\n","\n","  fig = ff.create_dendrogram(inverse_correlation.values, orientation='left', labels=feature_names, colorscale=colors, linkagefun=lambda x: hc.linkage(x, 'average'))\n","  \n","  fig['layout'].update(dict(\n","      title= title_,\n","      template= template_,\n","      width=800, \n","      height=600,\n","      margin=go.layout.Margin(l=180, r=50),\n","      xaxis=dict(\n","          title='distance',\n","      ),\n","      yaxis=dict(\n","          title='features',\n","          automargin=True,\n","      ),\n","  ))\n","  return fig"],"metadata":{"id":"wpLKsvHuJF_Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def prepare_heatmap(X, template_):\n","  corr = X.corr()\n","  trace = go.Heatmap(z=corr.values.tolist(), x=corr.columns, y=corr.columns)\n","  data=[trace]\n","  layout = go.Layout(\n","      title='Heatmap of pairwise correlation of the columns',\n","      autosize=False,\n","      template = template_,\n","      width=650,\n","      height=500,\n","      yaxis=go.layout.YAxis(automargin=True),\n","      xaxis=dict(tickangle=40),\n","      margin=go.layout.Margin(l=80, r=80, b=80, t=80)\n","  )\n","\n","  return go.Figure(data=data, layout=layout)"],"metadata":{"id":"I-R34w6CITbB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def prepare_pairplot(X, config_dict, combinations, features_names, template_):\n","  trace_list = []\n","  combinations_names = []\n","  start_pos = 0\n","  index_vals = X[config_dict['TARGET_COLUMN_NAME']].astype('category').cat.codes\n","\n","  #combinations = list(itertools.combinations(range(len(features_list)), 2))\n","  num_steps = len(combinations)\n","\n","  for couple in combinations:\n","    tuple_ = (features_names[couple[0]], features_names[couple[1]])\n","    combinations_names.append(str(tuple_))\n","\n","  for count, couple in enumerate(combinations):\n","    #print(features_names[couple[0]], features_names[couple[1]])\n","    if count == start_pos:\n","      visibility_ = True\n","    else:\n","      visibility_ = False\n"," \n","    trace_list.append(go.Splom(dimensions=[dict(label=features_names[couple[0]],\n","                                                values=X[features_names[couple[0]]]),\n","                                          dict(label=features_names[couple[1]],\n","                                          values=X[features_names[couple[1]]])],\n","                              diagonal_visible=False, # remove plots on diagonal\n","                              text=X[config_dict['TARGET_COLUMN_NAME']],\n","                              marker=dict(color=index_vals,\n","                                          showscale=False, # colors encode categorical variables\n","                                          line_color='white', line_width=0.5),\n","                              visible = visibility_))\n","\n","  steps = []\n","  \n","  for i in range(num_steps):\n","      # Hide all traces\n","      step = dict(\n","          method = 'restyle',  \n","          args = ['visible', [False] * len(trace_list)],\n","          label = combinations_names[i],\n","      )\n","\n","      # Enable the traces we want to see\n","      step['args'][1][i] = True\n","        \n","      # Add step to step list\n","      steps.append(step)\n","  \n","  sliders = [dict(\n","      active = start_pos, # from where to start the slider\n","      currentvalue = dict(\n","            prefix = \"Features couple: \", \n","            xanchor= 'center',\n","      ),\n","      pad = {\"t\": 50},\n","      steps = steps,\n","      len=1,\n","    )]\n","\n","  layout = dict(\n","        #paper_bgcolor='rgba(0,0,0,0)',\n","        #plot_bgcolor='rgba(0,0,0,0)',\n","        sliders=sliders,\n","        template = template_,  \n","        #font=dict(\n","        #    color=font_color\n","        #)\n","        width=600,\n","        height=600,\n","  )\n","\n","  return go.Figure(data=trace_list, layout=layout)"],"metadata":{"id":"8ihO0qZXKln8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def prepare_PCA_explained_variance_plot(pca, template_):\n","  #explained_variance_ratio_ is the percentage of variance explained by each of the selected components.\n","  '''\n","  fig = plt.figure()\n","  plt.plot(np.cumsum(pca.explained_variance_ratio_), label=\"Cumulative variance\")\n","  plt.plot(pca.explained_variance_ratio_, label=\"Component variance\")\n","  plt.legend()\n","  plt.xlabel('Principal component')\n","  plt.ylabel('Explained variance ratio')\n","  '''\n","  cum_explained_variance_ratio = np.cumsum(pca.explained_variance_ratio_)\n","\n","  found_explained_variance_ratio = 0.0\n","  found_pc_id = 0\n","  for pc_id, value in enumerate(cum_explained_variance_ratio):\n","    if value >= 0.95:\n","      found_explained_variance_ratio = value\n","      found_pc_id = pc_id +1\n","      break\n","\n","  trace_cum_var_exp = go.Scatter(\n","    x=list(range(1, len(pca.explained_variance_ratio_) + 1)), \n","    y=pca.explained_variance_ratio_,\n","    name=\"Component explained variance\",\n","  )\n","  trace_ind_var_exp = go.Scatter(\n","      x=list(range(1, len(cum_explained_variance_ratio) + 1)),\n","      y=cum_explained_variance_ratio,\n","      name=\"Cumulative explained variance\",\n","    )\n","  data = [trace_cum_var_exp, trace_ind_var_exp]\n","  layout = go.Layout(\n","      template = template_,\n","      title='Individual and Cumulative Explained Variance',\n","      autosize=True,\n","      yaxis=dict(\n","          title='Explained variance ratio',\n","      ),\n","      xaxis=dict(\n","          title=\"Principal component\",\n","          dtick=1,\n","      )\n","  )\n","  \n","  fig = go.Figure(data=data, layout=layout)\n","\n","  fig.add_vline(x=found_pc_id, line_width=2, line_dash=\"dash\", line_color=\"green\")\n","  fig.add_hline(y=found_explained_variance_ratio, line_width=2, line_dash=\"dash\", line_color=\"green\")\n","      \n","  return fig"],"metadata":{"id":"5g69h7I4Rgaa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def prepare_biplot(pca, X_pca_trasformed, y, features_names, template_):\n","  loadings = pca.components_.T * np.sqrt(pca.explained_variance_)\n","\n","  fig = px.scatter(X_pca_trasformed, x=0, y=1, color=y)\n","\n","  for i, feature in enumerate(features_names):\n","      fig.add_shape(\n","          type='line',\n","          x0=0, y0=0,\n","          x1=loadings[i, 0],\n","          y1=loadings[i, 1]\n","      )\n","      fig.add_annotation(\n","          x=loadings[i, 0],\n","          y=loadings[i, 1],\n","          ax=0, ay=0,\n","          xanchor=\"center\",\n","          yanchor=\"bottom\",\n","          text=feature,\n","      )\n","\n","  fig.update_layout( # customize font and legend orientation & position\n","    template = template_,\n","    width=700,\n","    height=700,\n","    legend_title_text='Class'\n","  )\n","\n","  return fig"],"metadata":{"id":"qQ_5sTpGRkoy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["config_dict = {}\n","\n","config_dict['GENERAL'] = {\n","    'SEED': 42,\n","    'TARGET_COLUMN_NAME': \"CLASS\",\n","    'NUMERIC_FEATURES': ['Age','TB','DB','AAP','SGPT','SGOT','TP','ALBA','AGR'],\n","    'BOOLEAN_FEATURES': ['Gender'],\n","    'SHOW_METHOD': 0, # 0 for colab, 1 for plotly, 2 for static png figures\n","    'PERFORM_NCV': True\n","}\n","\n","if config_dict['GENERAL']['SHOW_METHOD'] > 0:\n","  template_ =  'plotly_white'\n","else:\n","  template_ = 'plotly_dark'\n","\n","show_dict(config_dict)"],"metadata":{"id":"04ZGPPIJp81X"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 1. Introduction<a class=\"anchor\" id=\"introduction\"></a>"],"metadata":{"id":"s1LsvtusoVG5"}},{"cell_type":"markdown","source":["###1.1 Attributes description<a class=\"anchor\" id=\"attributes_descr\"></a>"],"metadata":{"id":"1xuGcEY_oVZ7"}},{"cell_type":"markdown","source":["###1.2 Basic dataset exploration<a class=\"anchor\" id=\"basic_dataset_exploration\"></a>"],"metadata":{"id":"8yUaGS57oV4I"}},{"cell_type":"code","source":["dataset_df = read_dataset(data_file_path, file_type= \"csv\")\n","dataset_df.loc[dataset_df['CLASS'] == 2, 'CLASS'] = 0\n","\n","le = preprocessing.LabelEncoder()\n","dataset_df['Gender'] = le.fit_transform(dataset_df['Gender'])\n","le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n","print(\"Label encoding for Gender feature:\")\n","print(le_name_mapping)\n","\n","print(display(dataset_df.head()))\n","\n","X = dataset_df.drop(columns=[config_dict['GENERAL']['TARGET_COLUMN_NAME']])\n","y = dataset_df[config_dict['GENERAL']['TARGET_COLUMN_NAME']] # dataframe containing class column\n","\n","features_names = X.columns.values\n","print_formatted_list(\"Feature names\", features_names)\n","class_names = list(set(y))\n","print_formatted_list(\"Class names\", class_names)\n","\n","fig, data_series = prepare_bar_plot(y, title = \"Distribution of samples per class\", template_=template_)\n","print(f'\\nNumber of samples = {dataset_df.shape[0]} | Number of features = {len(features_names)}\\n')\n","for value in zip(data_series.values, data_series.index):\n","    print(\"%s: %d instances (%.2f%%)\" % (value[1], value[0], (value[0]/y.shape[0])*100))\n","print()\n","\n","if config_dict['GENERAL']['SHOW_METHOD'] == 0:\n","  fig.show()\n","elif config_dict['GENERAL']['SHOW_METHOD'] == 1:\n","  py.iplot(fig, filename = 'bar_plot')\n","elif config_dict['GENERAL']['SHOW_METHOD'] == 2:\n","  fig.show(renderer='svg')"],"metadata":{"id":"C15NV5JlqeBX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###1.3 Check for missing values<a class=\"anchor\" id=\"check_missing_values\"></a>\n","We can observe below that there are no missing values in the dataset."],"metadata":{"id":"FsIpDTxXorMz"}},{"cell_type":"code","source":["# check for null values in the dataset\n","print(\"Missing values per feature:\")\n","print(X.isna().sum())\n","print()\n","display(dataset_df.groupby('CLASS', as_index=False)['AGR'].min().rename(columns={'AGR': 'min(AGR)'}))\n","print()\n","display(dataset_df.groupby('CLASS', as_index=False)['AGR'].max().rename(columns={'AGR': 'max(AGR)'}))\n","print()\n","display(dataset_df.groupby('CLASS', as_index=False)['AGR'].mean().rename(columns={'AGR': 'mean(AGR)'}))"],"metadata":{"id":"8efsbdpTyjGd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset_df['AGR'].fillna(dataset_df.groupby('CLASS')['AGR'].transform('mean').round(2), inplace = True)\n","X = dataset_df.drop(columns=[config_dict['GENERAL']['TARGET_COLUMN_NAME']])\n","X.info()"],"metadata":{"id":"rjMfXzivmhYC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###1.4 Checking for outliers<a class=\"anchor\" id=\"check_outliers\"></a>"],"metadata":{"id":"x2HfW8lBorf0"}},{"cell_type":"code","source":["fig = prepare_histogram_plot(dataset_df, features_names, class_names, config_dict['GENERAL'], template_)\n","\n","if config_dict['GENERAL']['SHOW_METHOD'] == 0:\n","  fig.show()\n","elif config_dict['GENERAL']['SHOW_METHOD'] == 1:\n","  py.iplot(fig, filename = 'bar_plot')\n","elif config_dict['GENERAL']['SHOW_METHOD'] == 2:\n","  fig.show(renderer='svg')"],"metadata":{"id":"3w2JF1sJze8p"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###1.5 Split dataset<a class=\"anchor\" id=\"split_dataset\"></a>"],"metadata":{"id":"hufQ4_MYo26v"}},{"cell_type":"code","source":["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=config_dict['GENERAL']['SEED'], stratify=y, shuffle=True)"],"metadata":{"id":"ZDsWeeXF8r7s"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##2. Exploratory data analysis<a class=\"anchor\" id=\"exploratory_data_analysis\"></a>"],"metadata":{"id":"MSFSzNp79Aw3"}},{"cell_type":"code","source":["fig, data_series = prepare_bar_plot(y_train, title = \"Training samples: distribution per class\", template_=template_)\n","print(f'Training dataset length: {X_train.shape[0]}\\n')\n","for value in zip(data_series.values, data_series.index):\n","    print(\"%s: %d instances (%.2f%%)\" % (value[1], value[0], (value[0]/y_train.shape[0])*100))\n","print()\n","\n","if config_dict['GENERAL']['SHOW_METHOD'] == 0:\n","  fig.show()\n","elif config_dict['GENERAL']['SHOW_METHOD'] == 1:\n","  py.iplot(fig, filename = 'bar_plot_training')\n","elif config_dict['GENERAL']['SHOW_METHOD'] == 2:\n","  fig.show(renderer='svg')"],"metadata":{"id":"Ixcpk8VT8xG1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig, data_series = prepare_bar_plot(y_test, title = \"Test samples: distribution per classs\", template_=template_)\n","print(f'Test dataset length: {X_test.shape[0]}\\n')\n","for value in zip(data_series.values, data_series.index):\n","    print(\"%s: %d instances (%.2f%%)\" % (value[1], value[0], (value[0]/y_test.shape[0])*100))\n","print()\n","\n","if config_dict['GENERAL']['SHOW_METHOD'] == 0:\n","  fig.show()\n","elif config_dict['GENERAL']['SHOW_METHOD'] == 1:\n","  py.iplot(fig, filename = 'bar_plot_test')\n","elif config_dict['GENERAL']['SHOW_METHOD'] == 2:\n","  fig.show(renderer='svg')"],"metadata":{"id":"6ZZRv3Cp9CM6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###2.1 Statistical quantitative description of features<a class=\"anchor\" id=\"stat_features_descr\"></a>\n","\n","Generate descriptive statistics.\n","For numeric data, the resultâ€™s index will include count, mean, std, min, max as well as lower, 50 and upper percentiles. By default the lower percentile is 25 and the upper percentile is 75. The 50 percentile is the same as the median."],"metadata":{"id":"gSTlRGtH9P9e"}},{"cell_type":"code","source":["print(display(X_train[config_dict['GENERAL']['NUMERIC_FEATURES']].describe()))"],"metadata":{"id":"-tKWSrB29OR7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train_class = X_train.copy()\n","X_train_class[config_dict['GENERAL']['TARGET_COLUMN_NAME']] = y_train\n","\n","liver_patients = X_train_class.loc[X_train_class[config_dict['GENERAL']['TARGET_COLUMN_NAME']] == 1].drop(columns=[config_dict['GENERAL']['TARGET_COLUMN_NAME']])\n","no_liver_patients = X_train_class.loc[X_train_class[config_dict['GENERAL']['TARGET_COLUMN_NAME']] == 0].drop(columns=[config_dict['GENERAL']['TARGET_COLUMN_NAME']])\n","print(\"Quantitaive description (class 1)\")\n","print(display(liver_patients.describe())) # per class\n","print(\"Quantitaive description (class 0)\")\n","print(display(no_liver_patients.describe())) # per class"],"metadata":{"id":"hpe4w3wCFzW_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###2.2 Box plots<a class=\"anchor\" id=\"box_plots\"></a>\n","\n","We plot one box plot per numeric feature to visualize whether each feature presents different characteristics depending on the target class."],"metadata":{"id":"AQ8bEMrf-B6c"}},{"cell_type":"code","source":["fig = prepare_box_plot(X_train_class, config_dict['GENERAL']['NUMERIC_FEATURES'], class_names, config_dict['GENERAL'], template_)\n","\n","if config_dict['GENERAL']['SHOW_METHOD'] == 0:\n","  fig.show()\n","elif config_dict['GENERAL']['SHOW_METHOD'] == 1:\n","  py.iplot(fig, filename = 'box_plot')\n","elif config_dict['GENERAL']['SHOW_METHOD'] == 2:\n","  fig.show(renderer='svg')"],"metadata":{"id":"uRIHQz_L-F10"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train_class_scaled = X_train_class.copy()\n","X_train_class_scaled[features_names] = MinMaxScaler().fit_transform(X_train_class_scaled[features_names])\n","fig = prepare_box_plot(X_train_class_scaled, config_dict['GENERAL']['NUMERIC_FEATURES'], class_names, config_dict['GENERAL'], template_)\n","\n","if config_dict['GENERAL']['SHOW_METHOD'] == 0:\n","  fig.show()\n","elif config_dict['GENERAL']['SHOW_METHOD'] == 1:\n","  py.iplot(fig, filename = 'bo_plot_scaled')\n","elif config_dict['GENERAL']['SHOW_METHOD'] == 2:\n","  fig.show(renderer='svg')"],"metadata":{"id":"6KRHA1Z3Bs4D"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###2.3 Correlation analysis<a class=\"anchor\" id=\"corr_analysis\"></a>"],"metadata":{"id":"dYRkUMumIHoM"}},{"cell_type":"code","source":["fig = prepare_heatmap(X_train, template_)\n","\n","if config_dict['GENERAL']['SHOW_METHOD'] == 0:\n","  fig.show()\n","elif config_dict['GENERAL']['SHOW_METHOD'] == 1:\n","  py.iplot(fig, filename = 'heatmap')\n","elif config_dict['GENERAL']['SHOW_METHOD'] == 2:\n","  fig.show(renderer='svg')"],"metadata":{"id":"UXJo_6aZIM3u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig = prepare_dendogram(X_train, title_ = \"Dendrogram of clustering the features according to correlation\", template_=template_)\n","\n","if config_dict['GENERAL']['SHOW_METHOD'] == 0:\n","  fig.show()\n","elif config_dict['GENERAL']['SHOW_METHOD'] == 1:\n","  py.iplot(fig, filename = 'dendogram')\n","elif config_dict['GENERAL']['SHOW_METHOD'] == 2:\n","  fig.show(renderer='svg')"],"metadata":{"id":"V5R7CakwI8eL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sns.pairplot(X_train, corner=True)\n","plt.show()"],"metadata":{"id":"x-f1IJQDKLc1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["combinations = list(itertools.combinations(range(len(features_names)), 2))\n","fig = prepare_pairplot(X_train_class, config_dict['GENERAL'], combinations, features_names, template_)\n","\n","if config_dict['GENERAL']['SHOW_METHOD'] == 0:\n","  fig.show()\n","elif config_dict['GENERAL']['SHOW_METHOD'] == 1:\n","  py.iplot(fig, filename = 'pair_plot1')\n","elif config_dict['GENERAL']['SHOW_METHOD'] == 2:\n","  fig.show(renderer='svg')"],"metadata":{"id":"XSAPT5AGKTdb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Preprocessing steps "],"metadata":{"id":"hyKccHFUQPW5"}},{"cell_type":"markdown","source":["####Rebalancing"],"metadata":{"id":"FnoGqiCGQTvj"}},{"cell_type":"markdown","source":["###Dimensionality reduction methods"],"metadata":{"id":"kPp9EL9uRIXu"}},{"cell_type":"markdown","source":["#### Principal component analysis"],"metadata":{"id":"6KJANo_xRPBN"}},{"cell_type":"code","source":["X_train_scaled = StandardScaler().fit_transform(X_train)\n","pca = PCA(n_components=len(features_names), random_state=config_dict['GENERAL']['SEED'])\n","X_train_pca_trasformed = pca.fit_transform(X_train_scaled)"],"metadata":{"id":"6bTSVGtNRSPb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig = prepare_PCA_explained_variance_plot(pca, template_)\n","\n","if config_dict['GENERAL']['SHOW_METHOD'] == 0:\n","  fig.show()\n","elif config_dict['GENERAL']['SHOW_METHOD'] == 1:\n","  py.iplot(fig, filename = 'explaied_variance')\n","elif config_dict['GENERAL']['SHOW_METHOD'] == 2:\n","  fig.show(renderer='svg')"],"metadata":{"id":"m0dIfEEwRVqe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Loadings are visualized by arrows that are under an angle and have a certain length. The angle represents the contribution of a particular feature in the direction of the PCs where it contributes. The length of the arrow depicts the strength of the contribution of the feature in that direction."],"metadata":{"id":"oXXcL7jTRxbk"}},{"cell_type":"code","source":["fig = prepare_biplot(pca, X_train_pca_trasformed, y_train, features_names, template_)\n","\n","if config_dict['GENERAL']['SHOW_METHOD'] == 0:\n","  fig.show()\n","elif config_dict['GENERAL']['SHOW_METHOD'] == 1:\n","  py.iplot(fig, filename = 'bi_plot')\n","elif config_dict['GENERAL']['SHOW_METHOD'] == 2:\n","  fig.show(renderer='svg')"],"metadata":{"id":"KaI0PmInR14i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["loadings = pd.DataFrame(pca.components_.T[:, 0:2], columns=['PC1', 'PC2'], index=features_names)\n","loadings"],"metadata":{"id":"7-IZnhRmU5w4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["loadings = pca.components_.T * np.sqrt(pca.explained_variance_)\n","loading_matrix = pd.DataFrame(loadings[:, 0:2], columns=['PC1', 'PC2'], index=features_names)\n","loading_matrix"],"metadata":{"id":"2NSjVWlRU_OM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["####Empirical feature selection"],"metadata":{"id":"0Us1Y1idXtH8"}},{"cell_type":"markdown","source":["##Classification"],"metadata":{"id":"s7rnYGiXXwI-"}},{"cell_type":"markdown","source":["###Metrics"],"metadata":{"id":"Purr7SrWXxV1"}},{"cell_type":"markdown","source":["###Cross validation"],"metadata":{"id":"Gmza9mI6X4Nj"}},{"cell_type":"code","source":["config_dict['CLASSIFICATION'] = {}\n","\n","config_dict['CLASSIFICATION']['MODELS'] = {\n","        'LinearSVC': svm.SVC(kernel='linear'),\n","        'RbfSVC': svm.SVC(kernel='rbf'),\n","        'KNN': neighbors.KNeighborsClassifier(),\n","        'LogisticRegression': linear_model.LogisticRegression(),\n","        'DecisionTree': tree.DecisionTreeClassifier(),\n","        'RandomForest': ensemble.RandomForestClassifier(),\n","}\n","\n","config_dict['CLASSIFICATION']['GENERAL'] = {\n","    'score_metric': f1_score,\n","    'cv_inner': 5,\n","    'cv_outer': 10,\n","    'seed': config_dict['GENERAL']['SEED']\n","}\n","\n","config_dict['CLASSIFICATION']['PARAMS'] = {\n","    'KNN': {\n","            'KNN__n_neighbors' : list(range(1,35, 4)), \n","            'KNN__weights': ['uniform', 'distance' ],\n","            #'KNN__n_jobs' : [-1],\n","            },\n","    'LinearSVC': {\n","            'LinearSVC__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000], \n","            #'LinearSVC__kernel': ['linear'],  \n","            },\n","    'RbfSVC': {\n","            'RbfSVC__C': [10, 100, 1000],  \n","            'RbfSVC__gamma': [0.001, 0.01, 0.1, 1],    \n","            #'RbfSVC__kernel': ['rbf'],\n","            },\n","    'LogisticRegression': {\n","            'LogisticRegression__penalty': ['l1', 'l2'],\n","            'LogisticRegression__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],   \n","            'LogisticRegression__max_iter': [1000],\n","            'LogisticRegression__solver': ['liblinear', 'lbfgs'],\n","            },\n","    'DecisionTree': {\n","            'DecisionTree__max_depth': list(range(2, 10)),\n","            'DecisionTree__min_samples_split': list(range(2, 10)),\n","            'DecisionTree__criterion' : ['gini', 'entropy'],\n","            },\n","    'RandomForest': {\n","            'RandomForest__n_estimators': [10, 100],\n","            'RandomForest__criterion' : ['gini', 'entropy'],\n","            'RandomForest__max_depth': list(range(2, 10)),\n","            'RandomForest__min_samples_split': [2, 5, 10], \n","            'RandomForest__max_features': ['sqrt'],\n","            #'RandomForest__n_jobs' : [-1],\n","            },\n","}\n","\n","show_dict(config_dict)"],"metadata":{"id":"49SHOF0lX8WX"},"execution_count":null,"outputs":[]}]}